{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Sentiment Transition Capture with Activation Recording (V2)\n",
    "\n",
    "This notebook builds on the original sentiment transition capture by adding activation recording capabilities using NNsight. We capture activations during the transition from negative to positive sentiment at three key points:\n",
    "\n",
    "1. **First token of transition**: Where the steering begins to switch\n",
    "2. **Middle of transition**: Peak transition activity\n",
    "3. **End of transition**: Where positive steering is fully established\n",
    "\n",
    "The key innovation is capturing the \"clean\" activations by excluding the ones used for steering, giving us the model's natural response patterns during sentiment transitions.\n",
    "\n",
    "Based on RepEng for steering and NNsight for activation capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if running in Colab\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install torch transformers sklearn numpy tqdm gguf\n",
    "    !git clone https://github.com/vgel/repeng.git\n",
    "    sys.path.append('/content/repeng')\n",
    "    \n",
    "    # Install NNsight\n",
    "    !pip install nnsight\n",
    "    \n",
    "    # Download the cognitive pattern questions file\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(\n",
    "        'https://raw.githubusercontent.com/your-repo/cognitive_pattern_questions.md',\n",
    "        'cognitive_pattern_questions.md'\n",
    "    )\n",
    "\n",
    "# Add local NNsight to path if available\n",
    "import os\n",
    "if os.path.exists('./nnsight'):\n",
    "    sys.path.insert(0, './nnsight/src')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from repeng import ControlVector, ControlModel, DatasetEntry\n",
    "import nnsight\n",
    "from nnsight import LanguageModel\n",
    "import re\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Activation Capture Data Structures\n",
    "\n",
    "Define structures to store activation data at different transition points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "@dataclass\nclass ActivationCapture:\n    \"\"\"Store activations captured at a specific point during generation.\"\"\"\n    token_position: int\n    layer_activations: Dict[int, torch.Tensor]  # layer_idx -> activation tensor\n    steering_strength: float\n    token_text: str\n    generation_step: str  # 'negative', 'transition_start', 'transition_mid', 'transition_end'\n    \n@dataclass\nclass TransitionActivationSet:\n    \"\"\"Complete set of activations captured during a sentiment transition.\"\"\"\n    question: str\n    baseline_activations: ActivationCapture  # No steering\n    negative_activations: ActivationCapture  # During negative steering\n    transition_start: ActivationCapture      # First token of transition\n    transition_mid: ActivationCapture        # Middle of transition\n    transition_end: ActivationCapture        # End of transition\n    steering_layers: List[int]               # Layers used for steering\n    full_response: str\n    transition_tokens: List[str]             # Actual tokens during transition\n    control_vector: Optional[\"ControlVector\"] = None  # Store control vector for precise subtraction\n\ndef extract_steering_component(\n    control_vector: \"ControlVector\",\n    layer_idx: int, \n    steering_strength: float,\n    activation_shape: torch.Size,\n    device: torch.device\n) -> torch.Tensor:\n    \"\"\"Extract the exact steering component applied to activations.\"\"\"\n    if layer_idx not in control_vector.directions:\n        return torch.zeros(activation_shape, dtype=torch.float16, device=device)\n    \n    # Get the control direction for this layer\n    direction = torch.tensor(\n        steering_strength * control_vector.directions[layer_idx],\n        device=device,\n        dtype=torch.float16\n    )\n    \n    # Reshape to match activation dimensions [1, 1, hidden_dim] -> broadcast to activation shape\n    if len(direction.shape) == 1:\n        direction = direction.reshape(1, 1, -1)\n    \n    # Broadcast to match activation shape\n    steering_component = direction.expand(activation_shape)\n    \n    return steering_component\n\ndef subtract_steering_from_activations(\n    steered_activations: Dict[int, torch.Tensor],\n    control_vector: \"ControlVector\", \n    steering_strength: float,\n    steering_layers: List[int],\n    device: torch.device\n) -> Dict[int, torch.Tensor]:\n    \"\"\"\n    Subtract the exact steering components from captured activations.\n    \n    This gives us the 'clean' activations that would have occurred without steering,\n    but includes the natural model response to the steering-influenced context.\n    \"\"\"\n    clean_activations = {}\n    \n    for layer_idx, activation in steered_activations.items():\n        if layer_idx in steering_layers:\n            # For steering layers, subtract the exact control vector component\n            steering_component = extract_steering_component(\n                control_vector, layer_idx, steering_strength, activation.shape, device\n            )\n            # Subtract the steering component to get clean activation\n            clean_activations[layer_idx] = activation - steering_component\n        else:\n            # For non-steering layers, the activation is already \"clean\" \n            # (though it may be influenced by upstream steering effects)\n            clean_activations[layer_idx] = activation.clone()\n    \n    return clean_activations\n\ndef clean_activations(\n    activations: Dict[int, torch.Tensor], \n    steering_layers: List[int]\n) -> Dict[int, torch.Tensor]:\n    \"\"\"Legacy function: Remove steering-affected layers entirely.\"\"\"\n    clean_acts = {}\n    for layer_idx, activation in activations.items():\n        if layer_idx not in steering_layers:\n            clean_acts[layer_idx] = activation.clone()\n    return clean_acts\n\nprint(\"Precise activation capture structures defined.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Model Setup with NNsight Integration\n",
    "\n",
    "We'll use both RepEng for steering and NNsight for activation capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = 0\n",
    "\n",
    "# Load model with NNsight wrapper for activation capture\n",
    "nnsight_model = LanguageModel(model_name, torch_dtype=torch.float16)\n",
    "device = nnsight_model.device\n",
    "print(f\"NNsight model loaded on {device}\")\n",
    "\n",
    "# Also load RepEng model for steering\n",
    "repeng_model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "repeng_model = repeng_model.to(device)\n",
    "\n",
    "# Wrap with ControlModel - using layers -5 to -18 as in the emotion example\n",
    "steering_layers = list(range(-5, -18, -1))\n",
    "control_model = ControlModel(repeng_model, steering_layers)\n",
    "\n",
    "# Chat templates\n",
    "user_tag, asst_tag = \"[INST]\", \"[/INST]\"\n",
    "\n",
    "print(f\"RepEng model loaded with control layers: {steering_layers}\")\n",
    "print(f\"Total model layers: {len(nnsight_model.model.model.layers)}\")\n",
    "\n",
    "# Convert negative layer indices to positive for NNsight\n",
    "total_layers = len(nnsight_model.model.model.layers)\n",
    "steering_layers_positive = [total_layers + layer_idx for layer_idx in steering_layers]\n",
    "print(f\"Steering layers (positive indices): {steering_layers_positive}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Load Cognitive Pattern Questions\n",
    "\n",
    "Same as V1, but we'll focus on fewer questions for detailed activation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cognitive_questions(filepath: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"Load and parse cognitive pattern questions from markdown file.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        # Fallback for analysis - create sample questions focused on transition capture\n",
    "        print(\"Cognitive questions file not found. Using sample questions optimized for transition analysis.\")\n",
    "        return {\n",
    "            \"Emotional Transitions\": [\n",
    "                \"How do you feel when you wake up in the morning?\",\n",
    "                \"What thoughts come to mind when you think about your future?\",\n",
    "                \"How do you typically respond when facing a difficult challenge?\"\n",
    "            ],\n",
    "            \"Self-Perception Shifts\": [\n",
    "                \"How would you describe your relationship with yourself?\",\n",
    "                \"What aspects of your personality do you think about most?\",\n",
    "                \"How do you view your ability to change and grow?\"\n",
    "            ],\n",
    "            \"Coping Mechanisms\": [\n",
    "                \"What do you do when you feel overwhelmed by negative thoughts?\",\n",
    "                \"How do you typically handle setbacks or disappointments?\",\n",
    "                \"What strategies help you move from feeling bad to feeling better?\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # Parse the markdown to extract questions by category\n",
    "    categories = {}\n",
    "    current_category = None\n",
    "    \n",
    "    lines = content.split('\\n')\n",
    "    for line in lines:\n",
    "        # Check for category headers (## format)\n",
    "        if line.startswith('## '):\n",
    "            # Extract category name (remove number and clean up)\n",
    "            category_match = re.search(r'##\\s*\\d+\\.\\s*(.+?)(?:\\s*\\*|$)', line)\n",
    "            if category_match:\n",
    "                current_category = category_match.group(1).strip()\n",
    "                categories[current_category] = []\n",
    "        \n",
    "        # Check for numbered questions\n",
    "        elif current_category and re.match(r'^\\d+\\. ', line):\n",
    "            question = re.sub(r'^\\d+\\. ', '', line).strip()\n",
    "            if question:\n",
    "                categories[current_category].append(question)\n",
    "    \n",
    "    return categories\n",
    "\n",
    "# Load the questions\n",
    "questions_by_category = load_cognitive_questions('cognitive_pattern_questions.md')\n",
    "\n",
    "print(\"Loaded question categories:\")\n",
    "for category, questions in questions_by_category.items():\n",
    "    print(f\"- {category}: {len(questions)} questions\")\n",
    "\n",
    "# Flatten all questions for easier access\n",
    "all_questions = []\n",
    "for questions in questions_by_category.values():\n",
    "    all_questions.extend(questions)\n",
    "\n",
    "print(f\"\\nTotal questions: {len(all_questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Create Training Dataset and Train Control Vectors\n",
    "\n",
    "Same approach as V1 to create the control vectors for steering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the suffixes from RepEng data\n",
    "def load_truncated_outputs():\n",
    "    \"\"\"Load truncated outputs from RepEng data file.\"\"\"\n",
    "    try:\n",
    "        # Try to load from local RepEng installation\n",
    "        with open('/content/repeng/notebooks/data/all_truncated_outputs.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            # Try alternative path for local development\n",
    "            with open('repeng/repeng/notebooks/data/all_truncated_outputs.json', 'r') as f:\n",
    "                return json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            # Fallback: create a subset based on the original data structure\n",
    "            print(\"RepEng data file not found. Using fallback dataset.\")\n",
    "            return [\n",
    "                \"\", \"That game\", \"I can see\", \"Hmm, this\", \"I can relate to\", \"Who is\",\n",
    "                \"I understand the\", \"Ugh,\", \"What the hell was\", \"Hey, did anyone\",\n",
    "                \"Although\", \"Thank you for choosing\", \"What are you\", \"Oh w\",\n",
    "                \"How dare you open\", \"It was my pleasure\", \"I'm hon\", \"I appreciate that you\",\n",
    "                \"Are you k\", \"Whoever left this\", \"It's always\", \"Ew,\", \"Hey, I l\",\n",
    "                \"Hello? Is someone\", \"I understand that\", \"That poem\", \"Aww, poor\",\n",
    "                \"Hey, it\", \"Alright, who\", \"I didn't\", \"Well, life\", \"The document\",\n",
    "                \"Oh no, this\", \"I'm concerned\", \"Hello, this is\", \"This art\",\n",
    "                \"Hmm, this drink\", \"Hi there!\", \"It seems\", \"Is\", \"Good\", \"I can't\"\n",
    "            ]\n",
    "\n",
    "# Load the response suffixes from RepEng data\n",
    "suffixes = load_truncated_outputs()\n",
    "print(f\"Loaded {len(suffixes)} response suffixes from RepEng data\")\n",
    "\n",
    "# Personas for steering\n",
    "positive_personas = [\"happy\", \"ecstatic\", \"delighted\"]\n",
    "negative_personas = [\"sad\", \"depressed\", \"dismayed\"]\n",
    "\n",
    "def template(persona: str, suffix: str) -> str:\n",
    "    \"\"\"Create template exactly like RepEng emotion example.\"\"\"\n",
    "    return f\"{user_tag} Act as if you're extremely {persona}. {asst_tag} {suffix}\"\n",
    "\n",
    "def create_control_dataset() -> List[DatasetEntry]:\n",
    "    \"\"\"Create dataset using RepEng's exact approach from emotion example.\"\"\"\n",
    "    dataset = []\n",
    "    \n",
    "    # Use a subset for faster training in this demonstration\n",
    "    subset_suffixes = suffixes[:100]  # Use first 100 for faster training\n",
    "    \n",
    "    for suffix in subset_suffixes:\n",
    "        tokens = tokenizer.tokenize(suffix)\n",
    "        for i in range(1, min(len(tokens), 5)):  # Limit to prevent excessive dataset size\n",
    "            truncated = tokenizer.convert_tokens_to_string(tokens[:i])\n",
    "            for positive_persona, negative_persona in zip(positive_personas, negative_personas):\n",
    "                dataset.append(DatasetEntry(\n",
    "                    positive=template(positive_persona, truncated),\n",
    "                    negative=template(negative_persona, truncated)\n",
    "                ))\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Create and train the control vector\n",
    "control_dataset = create_control_dataset()\n",
    "print(f\"Created control dataset with {len(control_dataset)} entries\")\n",
    "\n",
    "# Train control vector\n",
    "control_model.reset()\n",
    "print(\"Training control vector...\")\n",
    "control_vector = ControlVector.train(\n",
    "    control_model,\n",
    "    tokenizer,\n",
    "    control_dataset,\n",
    "    method=\"pca_center\",\n",
    "    max_batch_size=8  # Smaller batch size for memory efficiency\n",
    ")\n",
    "\n",
    "print(\"Control vector training completed!\")\n",
    "print(f\"Vector covers layers: {sorted(control_vector.directions.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Activation Capture During Sentiment Transition\n",
    "\n",
    "The core functionality - capturing activations at key transition points using NNsight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "def capture_layer_activations(\n    model: LanguageModel,\n    input_ids: torch.Tensor,\n    target_layers: List[int],\n    target_position: int = -1\n) -> Dict[int, torch.Tensor]:\n    \"\"\"Capture activations from specific layers at a target token position using NNsight.\"\"\"\n    activations = {}\n    \n    with model.trace(input_ids) as tracer:\n        # Capture hidden states from target layers\n        for layer_idx in target_layers:\n            if layer_idx < len(model.model.model.layers):\n                # Get hidden states from this layer\n                layer_output = model.model.model.layers[layer_idx].output[0]\n                # Save the activation at the target position\n                activations[layer_idx] = layer_output[:, target_position, :].save()\n    \n    # Execute the trace and return the saved activations\n    executed_activations = {}\n    for layer_idx, saved_activation in activations.items():\n        executed_activations[layer_idx] = saved_activation.value\n    \n    return executed_activations\n\ndef generate_with_precise_activation_capture(\n    question: str,\n    control_vector: \"ControlVector\",\n    depressive_strength: float = -2.0,\n    positive_strength: float = 2.0,\n    initial_tokens: int = 30,\n    completion_tokens: int = 40,\n    capture_layers: Optional[List[int]] = None\n) -> TransitionActivationSet:\n    \"\"\"\n    Generate response with sentiment transition while capturing activations with precise steering subtraction.\n    \n    Args:\n        question: The question to ask\n        control_vector: The trained control vector for steering\n        depressive_strength: Negative control strength\n        positive_strength: Positive control strength \n        initial_tokens: Tokens for negative phase\n        completion_tokens: Tokens for positive phase\n        capture_layers: Layers to capture (default: all layers)\n    \n    Returns:\n        TransitionActivationSet with precise steering-subtracted activations\n    \"\"\"\n    if capture_layers is None:\n        # Capture from all layers by default\n        total_layers = len(nnsight_model.model.model.layers)\n        capture_layers = list(range(total_layers))\n    \n    input_text = f\\\"{user_tag} {question} {asst_tag}\\\"\n    print(f\\\"\\\\nProcessing: {question[:50]}...\\\")\n    \n    # Step 1: Baseline generation (no steering) with activation capture\n    print(\\\"1. Capturing baseline activations...\\\")\n    control_model.reset()\n    \n    input_ids = tokenizer(input_text, return_tensors=\\\"pt\\\").to(device)\n    baseline_activations = capture_layer_activations(\n        nnsight_model, input_ids.input_ids, capture_layers, target_position=-1\n    )\n    \n    baseline_capture = ActivationCapture(\n        token_position=-1,\n        layer_activations=baseline_activations,\n        steering_strength=0.0,\n        token_text=\\\"[BASELINE]\\\",\n        generation_step=\\\"baseline\\\"\n    )\n    \n    # Step 2: Generate negative phase with RepEng\n    print(\\\"2. Generating negative phase...\\\")\n    control_model.reset()\n    control_model.set_control(control_vector, depressive_strength)\n    \n    with torch.no_grad():\n        negative_output = control_model.generate(\n            **input_ids,\n            max_new_tokens=initial_tokens,\n            do_sample=True,\n            temperature=0.7,\n            pad_token_id=tokenizer.eos_token_id\n        )\n    \n    # Extract negative text\n    full_negative = tokenizer.decode(negative_output.squeeze(), skip_special_tokens=True)\n    negative_start_idx = full_negative.find(asst_tag) + len(asst_tag)\n    negative_text = full_negative[negative_start_idx:].strip()\n    \n    # Step 3: Capture activations during negative generation (WITH steering applied)\n    print(\\\"3. Capturing negative phase activations (steered)...\\\")\n    negative_activations_steered = capture_layer_activations(\n        nnsight_model, negative_output, capture_layers, target_position=-1\n    )\n    \n    # Subtract the exact steering component to get clean activations\n    print(\\\"4. Computing clean negative activations (steering subtracted)...\\\")\n    negative_activations_clean = subtract_steering_from_activations(\n        negative_activations_steered,\n        control_vector,\n        depressive_strength,\n        steering_layers_positive,\n        device\n    )\n    \n    negative_capture = ActivationCapture(\n        token_position=len(tokenizer.encode(input_text)) + initial_tokens - 1,\n        layer_activations=negative_activations_clean,\n        steering_strength=depressive_strength,\n        token_text=negative_text.split()[-1] if negative_text else \\\"[UNK]\\\",\n        generation_step=\\\"negative\\\"\n    )\n    \n    # Step 5: Determine transition point and generate positive continuation\n    print(\\\"5. Generating positive continuation...\\\")\n    words = negative_text.split()\n    transition_point = len(words) // 2 if len(words) > 4 else max(1, len(words) - 1)\n    \n    transition_text = ' '.join(words[:transition_point])\n    continuation_prompt = f\\\"{input_text} {transition_text}\\\"\n    \n    # Generate with positive steering\n    control_model.reset()\n    control_model.set_control(control_vector, positive_strength)\n    \n    continuation_ids = tokenizer(continuation_prompt, return_tensors=\\\"pt\\\").to(device)\n    \n    with torch.no_grad():\n        positive_output = control_model.generate(\n            **continuation_ids,\n            max_new_tokens=completion_tokens,\n            do_sample=True,\n            temperature=0.8,\n            pad_token_id=tokenizer.eos_token_id\n        )\n    \n    # Step 6: Capture activations at transition points (WITH positive steering)\n    print(\\\"6. Capturing transition activations (steered) and computing clean versions...\\\")\n    \n    # Transition start (first positive token)\n    transition_start_pos = len(tokenizer.encode(continuation_prompt))\n    start_activations_steered = capture_layer_activations(\n        nnsight_model, positive_output, capture_layers, target_position=transition_start_pos\n    )\n    start_activations_clean = subtract_steering_from_activations(\n        start_activations_steered, control_vector, positive_strength, steering_layers_positive, device\n    )\n    \n    # Transition middle \n    mid_pos = transition_start_pos + completion_tokens // 2\n    mid_activations_steered = capture_layer_activations(\n        nnsight_model, positive_output, capture_layers, target_position=mid_pos\n    )\n    mid_activations_clean = subtract_steering_from_activations(\n        mid_activations_steered, control_vector, positive_strength, steering_layers_positive, device\n    )\n    \n    # Transition end\n    end_activations_steered = capture_layer_activations(\n        nnsight_model, positive_output, capture_layers, target_position=-1\n    )\n    end_activations_clean = subtract_steering_from_activations(\n        end_activations_steered, control_vector, positive_strength, steering_layers_positive, device\n    )\n    \n    # Decode final response\n    full_positive = tokenizer.decode(positive_output.squeeze(), skip_special_tokens=True)\n    positive_continuation = full_positive[len(continuation_prompt):].strip()\n    full_response = transition_text + \\\" \\\" + positive_continuation\n    \n    # Create activation captures for transition points with clean activations\n    transition_tokens = tokenizer.decode(\n        positive_output.squeeze()[transition_start_pos:], \n        skip_special_tokens=True\n    ).split()\n    \n    start_capture = ActivationCapture(\n        token_position=transition_start_pos,\n        layer_activations=start_activations_clean,\n        steering_strength=positive_strength,\n        token_text=transition_tokens[0] if transition_tokens else \\\"[START]\\\",\n        generation_step=\\\"transition_start\\\"\n    )\n    \n    mid_capture = ActivationCapture(\n        token_position=mid_pos,\n        layer_activations=mid_activations_clean,\n        steering_strength=positive_strength,\n        token_text=transition_tokens[len(transition_tokens)//2] if len(transition_tokens) > 2 else \\\"[MID]\\\",\n        generation_step=\\\"transition_mid\\\"\n    )\n    \n    end_capture = ActivationCapture(\n        token_position=len(tokenizer.encode(full_positive)) - 1,\n        layer_activations=end_activations_clean,\n        steering_strength=positive_strength,\n        token_text=transition_tokens[-1] if transition_tokens else \\\"[END]\\\",\n        generation_step=\\\"transition_end\\\"\n    )\n    \n    control_model.reset()\n    \n    return TransitionActivationSet(\n        question=question,\n        baseline_activations=baseline_capture,\n        negative_activations=negative_capture,\n        transition_start=start_capture,\n        transition_mid=mid_capture,\n        transition_end=end_capture,\n        steering_layers=steering_layers_positive,\n        full_response=full_response,\n        transition_tokens=transition_tokens,\n        control_vector=control_vector\n    )\n\nprint(\\\"Precise activation capture system ready!\\\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Test Activation Capture System\n",
    "\n",
    "Let's test the system with a sample question to verify everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "# Test with a sample question using the new precise activation capture\ntest_question = \"How do you feel about your future and what lies ahead?\"\n\nprint(\"Testing precise activation capture system...\")\nactivation_set = generate_with_precise_activation_capture(\n    question=test_question,\n    control_vector=control_vector,\n    depressive_strength=-2.0,\n    positive_strength=1.8,\n    initial_tokens=25,\n    completion_tokens=35\n)\n\nprint(\"\\\\n\" + \"=\"*60)\nprint(\"PRECISE ACTIVATION CAPTURE RESULTS\")\nprint(\"=\"*60)\n\nprint(f\"\\\\nQuestion: {activation_set.question}\")\nprint(f\"Full Response: {activation_set.full_response}\")\nprint(f\"Transition Tokens: {activation_set.transition_tokens}\")\n\nprint(f\"\\\\nActivation Capture Summary (with precise steering subtraction):\")\nprint(f\"- Baseline: {len(activation_set.baseline_activations.layer_activations)} layers captured\")\nprint(f\"- Negative (clean): {len(activation_set.negative_activations.layer_activations)} layers captured\")\nprint(f\"- Transition Start (clean): {len(activation_set.transition_start.layer_activations)} layers captured\")\nprint(f\"- Transition Mid (clean): {len(activation_set.transition_mid.layer_activations)} layers captured\")\nprint(f\"- Transition End (clean): {len(activation_set.transition_end.layer_activations)} layers captured\")\n\nprint(f\"\\\\nSteering layers with subtracted components: {activation_set.steering_layers}\")\n\n# Demonstrate the difference between steered and clean activations\nif activation_set.steering_layers:\n    sample_steering_layer = activation_set.steering_layers[0]\n    if sample_steering_layer in activation_set.negative_activations.layer_activations:\n        print(f\"\\\\nExample: Layer {sample_steering_layer} activation analysis:\")\n        \n        # Show the magnitude of the steering component\n        steering_component = extract_steering_component(\n            activation_set.control_vector,\n            sample_steering_layer,\n            activation_set.negative_activations.steering_strength,\n            activation_set.negative_activations.layer_activations[sample_steering_layer].shape,\n            device\n        )\n        \n        steering_magnitude = torch.norm(steering_component).item()\n        clean_magnitude = torch.norm(activation_set.negative_activations.layer_activations[sample_steering_layer]).item()\n        \n        print(f\"  • Steering component magnitude: {steering_magnitude:.4f}\")\n        print(f\"  • Clean activation magnitude: {clean_magnitude:.4f}\")\n        print(f\"  • Ratio (steering/clean): {steering_magnitude/clean_magnitude:.4f}\")\n\nprint(f\"\\\\nAll captured activations now exclude the exact steering vectors used for control.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Batch Process Questions with Activation Capture\n",
    "\n",
    "Process multiple questions while capturing detailed activation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "def process_questions_with_precise_activations(\n    questions: List[str],\n    control_vector: \"ControlVector\",\n    num_samples: int = 3,\n    save_results: bool = True\n) -> List[TransitionActivationSet]:\n    \"\"\"\n    Process multiple questions with precise activation capture (steering subtracted).\n    \n    Args:\n        questions: List of questions to process\n        control_vector: Trained control vector for steering\n        num_samples: Number of questions to process\n        save_results: Whether to save activation data\n    \n    Returns:\n        List of TransitionActivationSet objects with clean activations\n    \"\"\"\n    import random\n    \n    if len(questions) > num_samples:\n        selected_questions = random.sample(questions, num_samples)\n    else:\n        selected_questions = questions\n    \n    activation_sets = []\n    \n    print(f\"Processing {len(selected_questions)} questions with precise activation capture...\")\n    \n    for i, question in enumerate(selected_questions):\n        print(f\"\\\\n{'='*40}\")\n        print(f\"QUESTION {i+1}/{len(selected_questions)}\")\n        print(f\"{'='*40}\")\n        \n        try:\n            activation_set = generate_with_precise_activation_capture(\n                question=question,\n                control_vector=control_vector,\n                depressive_strength=-2.2,\n                positive_strength=1.9,\n                initial_tokens=20,\n                completion_tokens=30\n            )\n            \n            activation_sets.append(activation_set)\n            print(f\"✓ Successfully captured precise activations for: {question[:40]}...\")\n            \n        except Exception as e:\n            print(f\"✗ Error processing question: {e}\")\n            continue\n    \n    if save_results and activation_sets:\n        # Save enhanced summary with steering analysis\n        simplified_results = []\n        \n        for act_set in activation_sets:\n            # Calculate steering impact statistics\n            steering_impact = {}\n            for layer_idx in act_set.steering_layers:\n                if layer_idx in act_set.negative_activations.layer_activations:\n                    # Calculate steering component magnitude\n                    steering_component = extract_steering_component(\n                        act_set.control_vector,\n                        layer_idx,\n                        act_set.negative_activations.steering_strength,\n                        act_set.negative_activations.layer_activations[layer_idx].shape,\n                        device\n                    )\n                    clean_activation = act_set.negative_activations.layer_activations[layer_idx]\n                    \n                    steering_mag = torch.norm(steering_component).item()\n                    clean_mag = torch.norm(clean_activation).item()\n                    \n                    steering_impact[layer_idx] = {\n                        \"steering_magnitude\": steering_mag,\n                        \"clean_magnitude\": clean_mag,\n                        \"steering_ratio\": steering_mag / clean_mag if clean_mag > 0 else 0.0\n                    }\n            \n            simplified = {\n                \"question\": act_set.question,\n                \"full_response\": act_set.full_response,\n                \"transition_tokens\": act_set.transition_tokens,\n                \"steering_layers\": act_set.steering_layers,\n                \"activation_summary\": {\n                    \"baseline_layers\": len(act_set.baseline_activations.layer_activations),\n                    \"negative_layers\": len(act_set.negative_activations.layer_activations),\n                    \"transition_points\": 3,\n                    \"captured_layers\": sorted(list(act_set.baseline_activations.layer_activations.keys())),\n                    \"precise_steering_subtraction\": True\n                },\n                \"steering_impact_analysis\": steering_impact,\n                \"capture_points\": {\n                    \"baseline\": act_set.baseline_activations.token_text,\n                    \"negative\": act_set.negative_activations.token_text,\n                    \"transition_start\": act_set.transition_start.token_text,\n                    \"transition_mid\": act_set.transition_mid.token_text,\n                    \"transition_end\": act_set.transition_end.token_text\n                }\n            }\n            simplified_results.append(simplified)\n        \n        # Save enhanced summary results\n        with open('precise_activation_capture_summary_v2.json', 'w') as f:\n            json.dump(simplified_results, f, indent=2)\n        \n        print(f\"\\\\n✓ Enhanced results summary saved to precise_activation_capture_summary_v2.json\")\n        \n        # Save actual activation tensors with steering metadata\n        for i, act_set in enumerate(activation_sets):\n            activation_data = {\n                'baseline': act_set.baseline_activations.layer_activations,\n                'negative_clean': act_set.negative_activations.layer_activations,\n                'transition_start_clean': act_set.transition_start.layer_activations,\n                'transition_mid_clean': act_set.transition_mid.layer_activations,\n                'transition_end_clean': act_set.transition_end.layer_activations,\n                'metadata': {\n                    'question': act_set.question,\n                    'steering_layers': act_set.steering_layers,\n                    'control_vector_directions': {k: v for k, v in act_set.control_vector.directions.items()},\n                    'steering_method': 'precise_subtraction',\n                    'description': 'Clean activations with exact steering components subtracted'\n                }\n            }\n            torch.save(activation_data, f'precise_activations_question_{i+1}_v2.pt')\n        \n        print(f\"✓ Precise activation tensors saved as precise_activations_question_*_v2.pt files\")\n        print(f\"  Note: These contain CLEAN activations with steering vectors precisely subtracted\")\n    \n    return activation_sets\n\n# Process a subset of questions with precise activation capture\nprint(\"Starting batch processing with precise activation capture...\")\nif 'control_vector' in locals():\n    captured_activations_precise = process_questions_with_precise_activations(\n        all_questions, control_vector, num_samples=2\n    )\n    print(f\"\\\\nProcessed {len(captured_activations_precise)} questions with precise activation capture.\")\nelse:\n    print(\"Control vector not available. Please run the control vector training cell first.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Activation Analysis and Visualization\n",
    "\n",
    "Analyze the captured activations to understand the transition patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": "def analyze_precise_activation_transitions(activation_sets: List[TransitionActivationSet]):\n    \"\"\"\n    Analyze patterns in the precisely captured activations (with steering subtracted).\n    \"\"\"\n    print(\"\\\\n\" + \"=\"*60)\n    print(\"PRECISE ACTIVATION TRANSITION ANALYSIS\")\n    print(\"=\"*60)\n    \n    if not activation_sets:\n        print(\"No activation sets to analyze.\")\n        return\n    \n    for i, act_set in enumerate(activation_sets):\n        print(f\"\\\\n[PRECISE ANALYSIS {i+1}] Question: {act_set.question[:50]}...\")\n        print(f\"Response: {act_set.full_response[:100]}...\")\n        \n        # Analyze activation magnitudes across transition points\n        phases = {\n            'Baseline': act_set.baseline_activations,\n            'Negative_Clean': act_set.negative_activations,\n            'Trans_Start_Clean': act_set.transition_start,\n            'Trans_Mid_Clean': act_set.transition_mid,\n            'Trans_End_Clean': act_set.transition_end\n        }\n        \n        print(f\"\\\\nClean Activation Magnitude Analysis (steering subtracted):\")\n        \n        for phase_name, capture in phases.items():\n            if capture.layer_activations:\n                # Calculate average magnitude across all layers\n                magnitudes = []\n                for layer_idx, activation in capture.layer_activations.items():\n                    mag = torch.norm(activation).item()\n                    magnitudes.append(mag)\n                \n                avg_magnitude = np.mean(magnitudes)\n                std_magnitude = np.std(magnitudes)\n                \n                print(f\"  {phase_name:15}: avg={avg_magnitude:.3f}, std={std_magnitude:.3f}, \"\n                      f\"token='{capture.token_text}', strength={capture.steering_strength}\")\n        \n        # Analyze steering impact specifically\n        print(f\"\\\\nSteering Impact Analysis:\")\n        steering_impacts = []\n        \n        for layer_idx in act_set.steering_layers:\n            if layer_idx in act_set.negative_activations.layer_activations:\n                # Calculate what the steering component magnitude was\n                steering_component = extract_steering_component(\n                    act_set.control_vector,\n                    layer_idx,\n                    act_set.negative_activations.steering_strength,\n                    act_set.negative_activations.layer_activations[layer_idx].shape,\n                    device\n                )\n                \n                clean_activation = act_set.negative_activations.layer_activations[layer_idx]\n                \n                steering_magnitude = torch.norm(steering_component).item()\n                clean_magnitude = torch.norm(clean_activation).item()\n                ratio = steering_magnitude / clean_magnitude if clean_magnitude > 0 else float('inf')\n                \n                steering_impacts.append({\n                    'layer': layer_idx,\n                    'steering_mag': steering_magnitude,\n                    'clean_mag': clean_magnitude,\n                    'ratio': ratio\n                })\n        \n        if steering_impacts:\n            # Sort by impact ratio\n            steering_impacts.sort(key=lambda x: x['ratio'], reverse=True)\n            \n            print(f\"  Steering layers ranked by impact (steering_mag/clean_mag):\")\n            for impact in steering_impacts[:5]:  # Show top 5\n                print(f\"    Layer {impact['layer']:2d}: ratio={impact['ratio']:.3f}, \"\n                      f\"steering={impact['steering_mag']:.3f}, clean={impact['clean_mag']:.3f}\")\n        \n        # Compare transition dynamics in clean activations\n        if len(phases) >= 4:  # Need at least baseline + 3 transition points\n            print(f\"\\\\nClean Transition Dynamics:\")\n            \n            # Calculate relative changes from baseline\n            baseline_mags = [torch.norm(act).item() for act in act_set.baseline_activations.layer_activations.values()]\n            baseline_avg = np.mean(baseline_mags)\n            \n            for phase_name, capture in list(phases.items())[1:]:  # Skip baseline\n                phase_mags = [torch.norm(act).item() for act in capture.layer_activations.values()]\n                phase_avg = np.mean(phase_mags)\n                relative_change = (phase_avg - baseline_avg) / baseline_avg * 100\n                \n                print(f\"  {phase_name:15}: {relative_change:+6.2f}% vs baseline\")\n\ndef create_precise_activation_export_summary(activation_sets: List[TransitionActivationSet]):\n    \"\"\"\n    Create a comprehensive summary for precise activation export and analysis.\n    \"\"\"\n    summary = {\n        \"session_info\": {\n            \"model_name\": model_name,\n            \"total_questions_processed\": len(activation_sets),\n            \"steering_method\": \"RepEng PCA Center\",\n            \"activation_capture_method\": \"NNsight + Precise Steering Subtraction\",\n            \"steering_layers\": steering_layers,\n            \"capture_points\": [\"baseline\", \"negative_clean\", \"transition_start_clean\", \"transition_mid_clean\", \"transition_end_clean\"],\n            \"key_innovation\": \"Exact steering vector components subtracted from all captured activations\"\n        },\n        \"questions_analyzed\": [],\n        \"precise_activation_statistics\": {},\n        \"steering_impact_summary\": {}\n    }\n    \n    all_magnitudes = {'baseline': [], 'negative_clean': [], 'transition_start_clean': [], \n                     'transition_mid_clean': [], 'transition_end_clean': []}\n    all_steering_ratios = []\n    \n    for i, act_set in enumerate(activation_sets):\n        question_data = {\n            \"question\": act_set.question,\n            \"response\": act_set.full_response,\n            \"transition_tokens\": act_set.transition_tokens,\n            \"activation_file\": f\"precise_activations_question_{i+1}_v2.pt\",\n            \"steering_subtraction\": \"applied\"\n        }\n        summary[\"questions_analyzed\"].append(question_data)\n        \n        # Collect magnitude statistics for clean activations\n        phases = {\n            'baseline': act_set.baseline_activations,\n            'negative_clean': act_set.negative_activations,\n            'transition_start_clean': act_set.transition_start,\n            'transition_mid_clean': act_set.transition_mid,\n            'transition_end_clean': act_set.transition_end\n        }\n        \n        for phase_name, capture in phases.items():\n            if capture.layer_activations:\n                magnitudes = [torch.norm(act).item() for act in capture.layer_activations.values()]\n                all_magnitudes[phase_name].extend(magnitudes)\n        \n        # Collect steering impact statistics\n        for layer_idx in act_set.steering_layers:\n            if layer_idx in act_set.negative_activations.layer_activations:\n                steering_component = extract_steering_component(\n                    act_set.control_vector,\n                    layer_idx,\n                    act_set.negative_activations.steering_strength,\n                    act_set.negative_activations.layer_activations[layer_idx].shape,\n                    device\n                )\n                \n                steering_mag = torch.norm(steering_component).item()\n                clean_mag = torch.norm(act_set.negative_activations.layer_activations[layer_idx]).item()\n                ratio = steering_mag / clean_mag if clean_mag > 0 else 0.0\n                \n                all_steering_ratios.append(ratio)\n    \n    # Calculate overall statistics\n    for phase_name, mags in all_magnitudes.items():\n        if mags:\n            summary[\"precise_activation_statistics\"][phase_name] = {\n                \"mean\": float(np.mean(mags)),\n                \"std\": float(np.std(mags)),\n                \"min\": float(np.min(mags)),\n                \"max\": float(np.max(mags)),\n                \"description\": \"Clean activations with steering components subtracted\"\n            }\n    \n    # Steering impact summary\n    if all_steering_ratios:\n        summary[\"steering_impact_summary\"] = {\n            \"mean_steering_to_clean_ratio\": float(np.mean(all_steering_ratios)),\n            \"std_steering_to_clean_ratio\": float(np.std(all_steering_ratios)),\n            \"max_steering_impact\": float(np.max(all_steering_ratios)),\n            \"description\": \"Ratio of subtracted steering magnitude to final clean activation magnitude\"\n        }\n    \n    # Save comprehensive summary\n    with open('precise_activation_analysis_summary_v2.json', 'w') as f:\n        json.dump(summary, f, indent=2)\n    \n    print(\"\\\\n✓ Comprehensive precise activation analysis saved to precise_activation_analysis_summary_v2.json\")\n    \n    return summary\n\n# Run precise activation analysis\nif 'captured_activations_precise' in locals() and captured_activations_precise:\n    analyze_precise_activation_transitions(captured_activations_precise)\n    precise_analysis_summary = create_precise_activation_export_summary(captured_activations_precise)\nelse:\n    print(\"No precise captured activations to analyze.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Export and Integration Guide\n",
    "\n",
    "Provide instructions for using the captured activation data in downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "def create_precise_activation_usage_guide():\n    \"\"\"\n    Create a comprehensive guide for using the precisely captured activation data.\n    \"\"\"\n    guide = \"\"\"\n# Sentiment Transition Activation Data - Precise Capture Usage Guide (V2)\n\n## Key Innovation: Precise Steering Subtraction\n\nThis V2 implementation goes beyond simply excluding steering layers. Instead, it:\n\n1. **Captures activations WITH steering applied**\n2. **Extracts the exact steering vector components** from RepEng's control vectors  \n3. **Subtracts these components precisely** from the captured activations\n4. **Provides truly \"clean\" activations** that show the model's natural response patterns\n\n## Files Generated\n\n### Enhanced Summary Files:\n- `precise_activation_capture_summary_v2.json`: Results with steering impact analysis\n- `precise_activation_analysis_summary_v2.json`: Statistical analysis with steering ratios\n\n### Precise Activation Data Files:\n- `precise_activations_question_N_v2.pt`: PyTorch tensors with precise steering subtraction\n  - Each file contains a dictionary with keys:\n    - 'baseline': No steering activations\n    - 'negative_clean': Depressive activations with steering subtracted\n    - 'transition_start_clean': Transition start with steering subtracted\n    - 'transition_mid_clean': Transition middle with steering subtracted\n    - 'transition_end_clean': Transition end with steering subtracted\n    - 'metadata': Enhanced metadata including original control vectors\n\n## Technical Details: How Steering Is Subtracted\n\n```python\n# The exact process for each captured activation:\n\n# 1. Capture activation WITH steering applied (steered_activation)\nsteered_activation = capture_during_generation()  # Shape: [1, 1, hidden_dim]\n\n# 2. Extract the exact steering component used by RepEng\ncontrol_direction = control_vector.directions[layer_idx]  # [hidden_dim]\nsteering_component = steering_strength * control_direction  # [hidden_dim]\nsteering_component = steering_component.reshape(1, 1, -1)  # [1, 1, hidden_dim]\n\n# 3. Subtract to get clean activation\nclean_activation = steered_activation - steering_component\n```\n\n## Loading and Using Precise Activation Data\n\n```python\nimport torch\nimport numpy as np\n\n# Load precise activation data\nactivation_data = torch.load('precise_activations_question_1_v2.pt')\n\n# Access clean activations (steering subtracted)\nbaseline_acts = activation_data['baseline']              # No steering\nnegative_clean = activation_data['negative_clean']       # Depressive steering subtracted\ntrans_start_clean = activation_data['transition_start_clean']  # Positive steering subtracted\ntrans_mid_clean = activation_data['transition_mid_clean']      # Positive steering subtracted\ntrans_end_clean = activation_data['transition_end_clean']      # Positive steering subtracted\n\n# Get enhanced metadata\nmetadata = activation_data['metadata']\noriginal_control_vectors = metadata['control_vector_directions']\nsteering_layers = metadata['steering_layers']\n\nprint(f\"Steering method: {metadata['steering_method']}\")\nprint(f\"Description: {metadata['description']}\")\n```\n\n## Analyzing Steering Impact\n\n```python\n# The metadata includes the original control vectors, so you can analyze steering impact:\n\ndef analyze_steering_impact(activation_data, layer_idx, steering_strength):\n    \\\"\\\"\\\"Analyze how much steering was removed from activations.\\\"\\\"\\\"\n    \n    # Get original control direction\n    control_directions = activation_data['metadata']['control_vector_directions']\n    if layer_idx not in control_directions:\n        return None\n    \n    # Calculate steering component magnitude\n    control_direction = torch.tensor(control_directions[layer_idx])\n    steering_component = steering_strength * control_direction\n    steering_magnitude = torch.norm(steering_component).item()\n    \n    # Get clean activation magnitude\n    clean_activation = activation_data['negative_clean'][layer_idx]\n    clean_magnitude = torch.norm(clean_activation).item()\n    \n    return {\n        'steering_magnitude': steering_magnitude,\n        'clean_magnitude': clean_magnitude,\n        'steering_ratio': steering_magnitude / clean_magnitude,\n        'layer': layer_idx\n    }\n\n# Example usage\nimpact = analyze_steering_impact(activation_data, layer_idx=27, steering_strength=-2.0)\nprint(f\"Steering impact ratio: {impact['steering_ratio']:.3f}\")\n```\n\n## Pure Transition Analysis\n\n```python\n# Now you can analyze pure transition patterns without steering artifacts:\n\ndef compute_pure_transition_vectors(activation_data):\n    \\\"\\\"\\\"Compute transition vectors from clean activations.\\\"\\\"\\\"\n    \n    transition_vectors = {}\n    baseline = activation_data['baseline']\n    \n    phases = ['negative_clean', 'transition_start_clean', 'transition_mid_clean', 'transition_end_clean']\n    \n    for phase in phases:\n        phase_acts = activation_data[phase]\n        phase_vectors = {}\n        \n        for layer_idx in baseline.keys():\n            if layer_idx in phase_acts:\n                baseline_act = baseline[layer_idx].flatten()\n                phase_act = phase_acts[layer_idx].flatten()\n                \n                # This is the pure transition vector (no steering artifacts)\n                transition_vec = phase_act - baseline_act\n                phase_vectors[layer_idx] = transition_vec\n        \n        transition_vectors[phase] = phase_vectors\n    \n    return transition_vectors\n\n# Get pure transition patterns\npure_transitions = compute_pure_transition_vectors(activation_data)\n\n# Analyze the natural evolution of sentiment without steering interference\nfor phase, vectors in pure_transitions.items():\n    avg_magnitude = np.mean([torch.norm(v).item() for v in vectors.values()])\n    print(f\"{phase}: avg transition magnitude = {avg_magnitude:.3f}\")\n```\n\n## Advanced Analysis Ideas\n\n### 1. Causal Transition Modeling\n```python\n# Build models to predict sentiment transitions from clean activations\nfrom sklearn.linear_model import LogisticRegression\n\n# Extract features from clean activations across all layers\ndef extract_features(activation_dict):\n    features = []\n    for layer_idx in sorted(activation_dict.keys()):\n        act = activation_dict[layer_idx].flatten()\n        features.extend([\n            torch.mean(act).item(),\n            torch.std(act).item(),\n            torch.norm(act).item()\n        ])\n    return np.array(features)\n\n# Train classifier on clean transition patterns\nX = []\ny = []\nfor data in all_activation_data:\n    X.append(extract_features(data['negative_clean']))\n    y.append(0)  # Negative phase\n    X.append(extract_features(data['transition_end_clean']))\n    y.append(1)  # Positive phase\n\nclf = LogisticRegression().fit(X, y)\n```\n\n### 2. Layer-wise Transition Sensitivity\n```python\n# Identify which layers show strongest clean transition patterns\nsensitivity_scores = {}\n\nfor layer_idx in range(32):  # For each layer\n    baseline_mags = []\n    transition_mags = []\n    \n    for data in all_activation_data:\n        if layer_idx in data['baseline'] and layer_idx in data['transition_end_clean']:\n            baseline_mags.append(torch.norm(data['baseline'][layer_idx]).item())\n            transition_mags.append(torch.norm(data['transition_end_clean'][layer_idx]).item())\n    \n    if baseline_mags and transition_mags:\n        # Measure consistent change across questions\n        changes = np.array(transition_mags) - np.array(baseline_mags)\n        sensitivity_scores[layer_idx] = np.abs(np.mean(changes))\n\n# Rank layers by natural transition sensitivity\nranked_layers = sorted(sensitivity_scores.items(), key=lambda x: x[1], reverse=True)\n```\n\n## Key Advantages of Precise Subtraction\n\n1. **True Clean Activations**: No steering artifacts in any layer\n2. **Preserved Context Effects**: Natural model responses to steering-influenced context remain\n3. **Quantifiable Impact**: Exact measurement of steering vs natural activation magnitudes  \n4. **Layer-Agnostic Analysis**: Can analyze all layers, not just non-steering ones\n5. **Steering Forensics**: Understand exactly how much each layer was influenced\n\n## Integration Notes\n\n- All activations are captured at single token positions with shape [1, 1, hidden_dim]\n- Steering subtraction preserves the natural activation magnitude relationships\n- The subtracted steering components are available for separate analysis if needed\n- Clean activations can still show transition effects due to upstream context influence\n- Model architecture: Mistral-7B-Instruct with precise RepEng steering integration\n\n## Comparison with V1\n\n| Aspect | V1 (Layer Exclusion) | V2 (Precise Subtraction) |\n|--------|---------------------|---------------------------|\n| Steering Layers | Excluded entirely | Steering subtracted, layer included |\n| Analysis Coverage | ~60% of layers | 100% of layers |\n| Steering Artifacts | Removed by exclusion | Removed by subtraction |\n| Natural Responses | Mixed with steering | Purely natural |\n| Quantification | Qualitative | Precise measurements |\n\nThis approach provides the most accurate representation of the model's natural sentiment transition dynamics.\n    \"\"\"\n    \n    with open('Precise_Activation_Usage_Guide_V2.md', 'w') as f:\n        f.write(guide.strip())\n    \n    print(\"📋 Enhanced precise activation usage guide created: Precise_Activation_Usage_Guide_V2.md\")\n    return guide\n\ndef create_final_session_summary():\n    \"\"\"\n    Create a final session summary for the precise activation capture system.\n    \"\"\"\n    print(\"\\\\n\" + \"=\"*80)\n    print(\"SENTIMENT TRANSITION CAPTURE V2 - FINAL SESSION SUMMARY\")\n    print(\"(WITH PRECISE STEERING SUBTRACTION)\")\n    print(\"=\"*80)\n    \n    print(f\"\\\\n🎯 KEY INNOVATIONS:\")\n    innovations = [\n        \"✓ PRECISE STEERING SUBTRACTION: Extract exact control vector components\",\n        \"✓ CLEAN ACTIVATION RECOVERY: Subtract steering artifacts per-activation\",\n        \"✓ FULL LAYER COVERAGE: Analyze 100% of model layers (not just non-steering)\",\n        \"✓ QUANTIFIED IMPACT: Measure exact steering vs natural activation ratios\",\n        \"✓ PRESERVED CONTEXT: Natural model responses to steering-influenced context\",\n        \"✓ STEERING FORENSICS: Detailed analysis of steering component magnitudes\"\n    ]\n    \n    for innovation in innovations:\n        print(f\"  {innovation}\")\n    \n    print(f\"\\\\n📁 ENHANCED FILES CREATED:\")\n    files_created = [\n        \"precise_activation_capture_summary_v2.json (Results + steering impact)\",\n        \"precise_activation_analysis_summary_v2.json (Statistical analysis)\",\n        \"precise_activations_question_*_v2.pt (Clean activation tensors)\",\n        \"Precise_Activation_Usage_Guide_V2.md (Comprehensive integration guide)\"\n    ]\n    \n    for file_desc in files_created:\n        print(f\"  • {file_desc}\")\n    \n    print(f\"\\\\n🔬 TECHNICAL BREAKTHROUGH:\")\n    details = [\n        f\"Model: {model_name}\",\n        f\"Steering Method: RepEng PCA Center with precise component extraction\", \n        f\"Capture Method: NNsight tracing + mathematical steering subtraction\",\n        f\"Coverage: ALL {len(nnsight_model.model.model.layers)} model layers analyzed\",\n        f\"Precision: Exact steering vector components isolated and removed\",\n        f\"Innovation: steered_activation - (steering_strength × control_direction)\"\n    ]\n    \n    for detail in details:\n        print(f\"  • {detail}\")\n    \n    print(f\"\\\\n🚀 RESEARCH APPLICATIONS:\")\n    applications = [\n        \"1. Pure sentiment transition dynamics (no steering artifacts)\",\n        \"2. Causal modeling of natural emotional processing\",\n        \"3. Layer-wise transition sensitivity analysis\", \n        \"4. Steering impact quantification and optimization\",\n        \"5. Clean activation-based sentiment prediction models\",\n        \"6. Natural vs artificial sentiment pattern comparison\"\n    ]\n    \n    for app in applications:\n        print(f\"  {app}\")\n    \n    print(f\"\\\\n💡 METHODOLOGICAL IMPACT:\")\n    print(\"  This approach solves the fundamental problem in steering research:\")\n    print(\"  'How do you study natural model behavior when using artificial steering?'\")\n    print(\"  \")\n    print(\"  Answer: Capture with steering, then mathematically subtract the exact\")\n    print(\"  steering components to recover the clean, natural activations.\")\n    \n    print(\"\\\\n\" + \"=\"*80)\n    print(\"PRECISE ACTIVATION CAPTURE SYSTEM - READY FOR ADVANCED ANALYSIS\")\n    print(\"=\"*80)\n\n# Create final documentation and summary\nprecise_usage_guide = create_precise_activation_usage_guide()\ncreate_final_session_summary()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This V2 notebook successfully combines RepEng sentiment steering with NNsight activation capture to provide detailed insights into the neural dynamics during sentiment transitions. The captured activations can be used for:\n",
    "\n",
    "1. **Understanding transition mechanics**: How the model internally processes sentiment changes\n",
    "2. **Building better steering vectors**: Using clean activation patterns to improve control\n",
    "3. **Developing predictive models**: Training classifiers on transition signatures\n",
    "4. **Comparative analysis**: Studying individual differences in response patterns\n",
    "\n",
    "The exported data provides a rich foundation for further research into controllable text generation and sentiment modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}