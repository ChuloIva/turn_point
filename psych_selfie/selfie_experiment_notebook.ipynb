{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SelfIE Psychology Experiments\n",
    "\n",
    "This notebook implements cognitive pattern analysis using the SelfIE (Self-Interpretation of Embeddings) technique, providing a similar workflow to the manual activation patching experiments but using the model's own ability to interpret its internal representations.\n",
    "\n",
    "## How SelfIE Works Here\n",
    "\n",
    "- **Source text**: We extract internal representations from cognitive pattern text\n",
    "- **Interpretation**: The model describes what these representations mean in natural language\n",
    "- **Analysis**: We compare interpretations between different types of cognitive patterns\n",
    "\n",
    "Unlike activation patching which modifies model behavior, SelfIE reveals what the model \"thinks\" its internal representations mean, providing interpretable insights into cognitive processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nimport torch\nimport pandas as pd\nimport json\nfrom IPython.display import display, HTML\nimport warnings\n\n# Add our SelfIE wrapper to path\nsys.path.append('/Users/ivanculo/Desktop/Projects/turn_point/psych_selfie')\nsys.path.append('/Users/ivanculo/Desktop/Projects/turn_point/manual_activation_patching')\n\n# Import SelfIE wrapper and utilities\nfrom selfie_patcher import SelfIEPatcher, TokenSelectionStrategy\nfrom utils import process_layers_to_interpret\n\n# Import utility functions from the original activation patcher for dataset loading\ntry:\n    from activation_patcher import ActivationPatcher\n    load_cognitive_patterns = ActivationPatcher.load_cognitive_patterns\n    get_pattern_by_index = ActivationPatcher.get_pattern_by_index\n    get_pattern_by_type = ActivationPatcher.get_pattern_by_type\n    get_pattern_text = ActivationPatcher.get_pattern_text\n    filter_patterns_by_count = ActivationPatcher.filter_patterns_by_count\n    get_filtered_patterns_by_type = ActivationPatcher.get_filtered_patterns_by_type\n    list_available_pattern_types = ActivationPatcher.list_available_pattern_types\n    show_pattern_info = ActivationPatcher.show_pattern_info\n    get_random_pattern_by_type = ActivationPatcher.get_random_pattern_by_type\n    get_patterns_by_type = ActivationPatcher.get_patterns_by_type\n    print(\"‚úì Successfully imported cognitive pattern utilities\")\nexcept ImportError as e:\n    warnings.warn(f\"Could not import pattern utilities: {e}\")\n    print(\"‚ö†Ô∏è  Will use manual pattern definitions\")\n\nprint(\"SelfIE Psychology Experiment Setup Complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing SelfIE with model: meta-llama/Llama-2-7b-chat-hf\n",
      "Note: This requires transformers==4.34.0 (see requirements.txt)\n",
      "Loading SelfIE-compatible model: meta-llama/Llama-2-7b-chat-hf\n",
      "Using Apple Silicon GPU (MPS)\n",
      "‚ùå Error initializing SelfIE: Failed to load model meta-llama/Llama-2-7b-chat-hf: You are trying to access a gated repo.\n",
      "Make sure to request access at https://huggingface.co/meta-llama/Llama-2-7b-chat-hf and pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`.\n",
      "\n",
      "üîß Troubleshooting tips:\n",
      "1. Ensure you have transformers==4.34.0 installed\n",
      "2. Make sure the model is available and you have access\n",
      "3. Try a different LLaMA model\n",
      "4. Check your GPU memory and CUDA setup\n",
      "\n",
      "üìä Loading cognitive patterns dataset...\n",
      "‚úì Loaded 520 cognitive patterns\n",
      "‚úì Found 13 different pattern types\n",
      "\n",
      "üìã Available pattern types:\n",
      "Available cognitive pattern types:\n",
      " 1. Cognitive depletion pattern (40 examples)\n",
      " 2. Intrusive suicidal fixation (40 examples)\n",
      " 3. Negative self-evaluative loop (40 examples)\n",
      " 4. Internal dialectical processing (40 examples)\n",
      " 5. Fragmented perceptual reasoning (40 examples)\n",
      " 6. Hyper-attuned interoception (40 examples)\n",
      " 7. Autobiographical integration (40 examples)\n",
      " 8. Over-elaborative recounting (40 examples)\n",
      " 9. Entrapment cognition (40 examples)\n",
      "10. Existential rumination (40 examples)\n",
      "11. Learned helplessness loop (40 examples)\n",
      "12. Instrumental suicidal reasoning (40 examples)\n",
      "13. Cognitive disorganization (40 examples)\n",
      "\n",
      "üí° Each pattern has three text variants: positive, negative, transition\n",
      "Available text types: positive, negative, transition\n"
     ]
    }
   ],
   "source": [
    "# Model Selection - Choose a LLaMA-compatible model for SelfIE\n",
    "# Note: SelfIE currently works best with LLaMA models\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"  # Change to available LLaMA model\n",
    "# Alternative models to try:\n",
    "# MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# MODEL_NAME = \"huggyllama/llama-7b\"\n",
    "\n",
    "# Initialize the SelfIE patcher\n",
    "print(f\"Initializing SelfIE with model: {MODEL_NAME}\")\n",
    "print(\"Note: This requires transformers==4.34.0 (see requirements.txt)\")\n",
    "\n",
    "try:\n",
    "    selfie_patcher = SelfIEPatcher(MODEL_NAME)\n",
    "    print(\"‚úì SelfIE patcher initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing SelfIE: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting tips:\")\n",
    "    print(\"1. Ensure you have transformers==4.34.0 installed\")\n",
    "    print(\"2. Make sure the model is available and you have access\")\n",
    "    print(\"3. Try a different LLaMA model\")\n",
    "    print(\"4. Check your GPU memory and CUDA setup\")\n",
    "\n",
    "# Load the cognitive patterns dataset\n",
    "print(\"\\nüìä Loading cognitive patterns dataset...\")\n",
    "try:\n",
    "    patterns, pattern_types = load_cognitive_patterns()\n",
    "    print(f\"‚úì Loaded {len(patterns)} cognitive patterns\")\n",
    "    print(f\"‚úì Found {len(pattern_types)} different pattern types\")\n",
    "    print(\"\\nüìã Available pattern types:\")\n",
    "    list_available_pattern_types(pattern_types)\n",
    "    print(f\"\\nüí° Each pattern has three text variants: positive, negative, transition\")\n",
    "    print(\"Available text types: positive, negative, transition\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading dataset: {e}\")\n",
    "    print(\"\\n‚ö†Ô∏è  Using manual pattern definitions for this demo\")\n",
    "    # Define some sample patterns manually\n",
    "    patterns = [\n",
    "        {\n",
    "            'cognitive_pattern_name': 'Negative Self-Evaluation',\n",
    "            'cognitive_pattern_type': 'Negative self-evaluative loop',\n",
    "            'positive_thought_pattern': \"I'm learning and growing from my mistakes, and that's part of being human.\",\n",
    "            'reference_negative_example': \"I always mess everything up and never do anything right.\",\n",
    "            'reference_transformed_example': \"I made a mistake, but I can learn from this experience.\"\n",
    "        },\n",
    "        {\n",
    "            'cognitive_pattern_name': 'Anxiety Response',\n",
    "            'cognitive_pattern_type': 'Anxiety pattern',\n",
    "            'positive_thought_pattern': \"I can handle challenging situations by taking things one step at a time.\",\n",
    "            'reference_negative_example': \"Everything is going to go wrong and I won't be able to cope.\",\n",
    "            'reference_transformed_example': \"I'm feeling anxious, but I can use coping strategies to manage this.\"\n",
    "        }\n",
    "    ]\n",
    "    pattern_types = {\n",
    "        'Negative self-evaluative loop': [patterns[0]], \n",
    "        'Anxiety pattern': [patterns[1]]\n",
    "    }\n",
    "    print(f\"‚úì Using {len(patterns)} manual patterns for demonstration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING DATA LOADING AND ACCESS:\n",
      "============================================================\n",
      "üìä Total patterns loaded: 520\n",
      "üìã Pattern types available: 13\n",
      "‚úÖ Filtering test: 65 patterns when limited to 5 per type\n",
      "‚úÖ Pattern retrieval test: Got pattern 'Executive Fatigue & Avolition'\n",
      "‚úÖ Text extraction test:\n",
      "   Positive: I'm recognizing that my energy levels are flagging...\n",
      "   Negative: Ugh, just the thought of checking my email is drai...\n",
      "   Transition: I need to take a deep breath and acknowledge that ...\n",
      "\n",
      "üìã SAMPLE PATTERN DETAILS:\n",
      "üß† Pattern: Executive Fatigue & Avolition\n",
      "üîÑ Type: Cognitive depletion pattern\n",
      "üìù Description: Difficulty initiating/maintaining basic tasks due to mental energy collapse.\n",
      "‚ùì Source Question: How depleted do you feel when contemplating routine responsibilities?\n",
      "\n",
      "‚úÖ Positive Text: I'm recognizing that my energy levels are flagging today, which is totally normal. I've been pushing myself hard lately, and it's catching up with me. Instead of beating myself up over it, though, I'll take a moment to re-prioritize and acknowledge that small steps forward are still possible. Let's start by breaking down that daunting task list into ridiculously simple, bite-sized chunks ‚Äì like taking 5 minutes to organize my digital files or sending a quick text to a friend.\n",
      "\n",
      "‚ùå Negative Text: Ugh, just the thought of checking my email is draining me already. It's like trying to lift a heavy weight that's been sitting on my chest for hours - every tiny movement feels impossible. How am I supposed to muster up enough energy to do something so mundane?\n",
      "\n",
      "üîÑ Transition Text: I need to take a deep breath and acknowledge that my mind feels overwhelmed. That's okay; it doesn't define me. I'll quickly jot down all these tasks on paper, and then circle one small thing I can do in under 10 minutes. Okay, let's start with... maybe responding to that simple email notification.\n",
      "\n",
      "üéâ All data loading tests PASSED!\n",
      "‚úÖ Ready to run SelfIE experiments with cognitive patterns dataset\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# üß™ TEST: Verify Data Loading and Access\n",
    "\n",
    "print(\"üß™ TESTING DATA LOADING AND ACCESS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Test basic data access\n",
    "    print(f\"üìä Total patterns loaded: {len(patterns)}\")\n",
    "    print(f\"üìã Pattern types available: {len(pattern_types)}\")\n",
    "    \n",
    "    # Test filtering functionality\n",
    "    test_filtered_patterns, test_filtered_types = filter_patterns_by_count(pattern_types, 5)\n",
    "    print(f\"‚úÖ Filtering test: {len(test_filtered_patterns)} patterns when limited to 5 per type\")\n",
    "    \n",
    "    # Test pattern retrieval\n",
    "    first_pattern_type = list(pattern_types.keys())[0]\n",
    "    test_pattern = get_pattern_by_type(pattern_types, first_pattern_type, 0)\n",
    "    print(f\"‚úÖ Pattern retrieval test: Got pattern '{test_pattern['cognitive_pattern_name']}'\")\n",
    "    \n",
    "    # Test text extraction\n",
    "    positive_text = get_pattern_text(test_pattern, \"positive\")\n",
    "    negative_text = get_pattern_text(test_pattern, \"negative\")\n",
    "    transition_text = get_pattern_text(test_pattern, \"transition\")\n",
    "    \n",
    "    print(f\"‚úÖ Text extraction test:\")\n",
    "    print(f\"   Positive: {positive_text[:50]}...\")\n",
    "    print(f\"   Negative: {negative_text[:50]}...\")\n",
    "    print(f\"   Transition: {transition_text[:50]}...\")\n",
    "    \n",
    "    # Show sample pattern info\n",
    "    print(f\"\\nüìã SAMPLE PATTERN DETAILS:\")\n",
    "    show_pattern_info(test_pattern)\n",
    "    \n",
    "    print(f\"\\nüéâ All data loading tests PASSED!\")\n",
    "    print(f\"‚úÖ Ready to run SelfIE experiments with cognitive patterns dataset\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Data loading test FAILED: {e}\")\n",
    "    print(\"Check that the dataset path and utility functions are correct\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Basic SelfIE Interpretation\n",
    "\n",
    "Let's start with a simple experiment to interpret internal representations of cognitive patterns using SelfIE.\n",
    "\n",
    "### What this experiment does:\n",
    "- **Input**: We provide a cognitive pattern text (positive or negative thought)\n",
    "- **Extraction**: SelfIE extracts internal representations from specific layers and token positions\n",
    "- **Interpretation**: The model describes what these representations mean in natural language\n",
    "- **Analysis**: We examine the interpretations to understand how the model processes different cognitive patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# EXPERIMENT 1: Basic SelfIE Interpretation\n\n# ===== CONFIGURATION SECTION =====\nNUM_EXAMPLES_PER_TYPE = 10  # Number of examples to use per pattern type (1-40)\nPATTERN_TYPE = \"Cognitive depletion pattern\"  # Choose from the list above\nPATTERN_INDEX_WITHIN_TYPE = 0  # If there are multiple examples of this type, choose which one (0-based)\nTEXT_TYPE = \"negative\"  # \"positive\", \"negative\", or \"transition\"\nINTERPRETATION_TEMPLATE = \"cognitive_pattern\"  # Template for interpretation\nLAYERS_TO_INTERPRET = \"all\"  # Enhanced options: \"all\", [-1, -2, -3], (0, 5), \"0:5\", \"0:10:2\"\nTOKEN_STRATEGY = TokenSelectionStrategy.LAST_TOKEN  # How to select tokens\nMAX_INTERPRETATION_TOKENS = 40  # Max tokens for interpretation\nBATCH_SIZE = 2\nINJECTION_LAYER = 1  # Layer where extracted activations are injected (0-based from start)\n# ====================================\n\n# Apply runtime filtering to use only NUM_EXAMPLES_PER_TYPE examples per pattern type\nfiltered_patterns, filtered_pattern_types = filter_patterns_by_count(pattern_types, NUM_EXAMPLES_PER_TYPE)\n\n# Get the pattern to analyze using the filtered dataset\ntry:\n    selected_pattern = get_pattern_by_type(filtered_pattern_types, PATTERN_TYPE, PATTERN_INDEX_WITHIN_TYPE)\n    input_text = get_pattern_text(selected_pattern, TEXT_TYPE)\n    pattern_name = selected_pattern['cognitive_pattern_name']\n    \n    # Process the layer specification to get actual layer indices\n    layers_to_use = process_layers_to_interpret(LAYERS_TO_INTERPRET)\n    \n    print(f\"\\nüß† EXPERIMENT 1: SelfIE Interpretation\")\n    print(f\"üìä Using {NUM_EXAMPLES_PER_TYPE} examples per pattern type (runtime filtered)\")\n    print(f\"üîç Pattern Type: {PATTERN_TYPE}\")\n    print(f\"üß† Pattern: {pattern_name}\")\n    print(f\"üìù Text type: {TEXT_TYPE}\")\n    print(f\"üìñ Input text: {input_text}\")\n    print(f\"üèóÔ∏è Layers to interpret: {LAYERS_TO_INTERPRET} ‚Üí {layers_to_use}\")\n    print(f\"üíâ Injection layer: {INJECTION_LAYER}\")\n    print(f\"üîß Token strategy: {TOKEN_STRATEGY.value}\")\n    print(\"\\\\n\" + \"=\"*80)\n\n    # Show pattern details for context\n    print(\"\\\\nüîç PATTERN DETAILS:\")\n    show_pattern_info(selected_pattern)\n    print(\"\\\\n\" + \"=\"*80)\n    \nexcept Exception as e:\n    print(f\"‚ùå Error loading pattern: {e}\")\n    print(\"Available pattern types:\")\n    for pattern_type in filtered_pattern_types.keys():\n        print(f\"  - {pattern_type}\")\n    # Fallback to first available pattern\n    if filtered_patterns:\n        selected_pattern = filtered_patterns[0]\n        input_text = get_pattern_text(selected_pattern, \"positive\")  # fallback to positive\n        pattern_name = selected_pattern['cognitive_pattern_name']\n        layers_to_use = process_layers_to_interpret([-1, -2, -3])  # fallback layers\n        print(f\"\\\\nUsing fallback pattern: {pattern_name}\")\n    else:\n        input_text = \"I feel overwhelmed and don't know how to handle this situation.\"\n        pattern_name = \"Sample Pattern\"\n        layers_to_use = process_layers_to_interpret([-1, -2, -3])  # fallback layers\n        print(\"\\\\nUsing manual fallback text\")\n\ntry:\n    # Perform SelfIE interpretation\n    interpretation_results = selfie_patcher.interpret_text(\n        text=input_text,\n        layers_to_interpret=layers_to_use,\n        interpretation_template=INTERPRETATION_TEMPLATE,\n        max_new_tokens=MAX_INTERPRETATION_TOKENS,\n        batch_size=BATCH_SIZE,\n        k=INJECTION_LAYER\n    )\n    \n    print(\"\\\\nüéä EXPERIMENT 1 RESULTS:\")\n    print(\"=\" * 80)\n    \n    # Display results in a readable format\n    for idx, row in interpretation_results.iterrows():\n        print(f\"\\\\nüìç Layer {row['layer']}, Token {row['token']} ('{row['token_decoded']}'):\")\n        print(f\"   Interpretation: {row['interpretation'].strip()}\")\n    \n    print(\"\\\\nüìä Full Results DataFrame:\")\n    display(interpretation_results[['layer', 'token', 'token_decoded', 'interpretation']])\n    \nexcept Exception as e:\n    print(f\"‚ùå Error in SelfIE interpretation: {e}\")\n    print(\"\\\\nüîß Troubleshooting:\")\n    print(\"1. Check that the model is properly loaded\")\n    print(\"2. Verify the model is LLaMA-compatible\")\n    print(\"3. Ensure sufficient GPU memory\")\n    print(\"4. Try reducing batch_size or max_new_tokens\")\n\nprint(\"\\\\n\" + \"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Comparing Positive vs Negative Patterns\n",
    "\n",
    "Let's compare how the model interprets positive versus negative cognitive patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# EXPERIMENT 2: Positive vs Negative Pattern Comparison\n\n# ===== CONFIGURATION SECTION =====\nNUM_EXAMPLES_PER_TYPE = 15  # Number of examples to use per pattern type (1-40)\nCOMPARISON_PATTERN_TYPE = \"Intrusive suicidal fixation\"  # Choose from available types\nCOMPARISON_PATTERN_INDEX = 0  # Which example within the type\nCOMPARISON_LAYER = [-1]  # Enhanced options: \"all\", [-1, -2, -3], (0, 5), \"0:5\", \"0:10:2\"\nCOMPARISON_STRATEGY = TokenSelectionStrategy.LAST_TOKEN\nCOMPARISON_TEMPLATE = \"psychological_state\"\nCOMPARISON_MAX_TOKENS = 30\nCOMPARISON_INJECTION_LAYER = 1  # Layer where extracted activations are injected (0-based from start)\n# ====================================\n\n# Apply runtime filtering\nfiltered_patterns, filtered_pattern_types = filter_patterns_by_count(pattern_types, NUM_EXAMPLES_PER_TYPE)\n\ntry:\n    selected_pattern = get_pattern_by_type(filtered_pattern_types, COMPARISON_PATTERN_TYPE, COMPARISON_PATTERN_INDEX)\n    \n    positive_text = get_pattern_text(selected_pattern, \"positive\")\n    negative_text = get_pattern_text(selected_pattern, \"negative\")\n    pattern_name = selected_pattern['cognitive_pattern_name']\n    \n    # Process the layer specification\n    layers_to_use = process_layers_to_interpret(COMPARISON_LAYER)\n    \n    print(f\"\\\\nüîÑ EXPERIMENT 2: Positive vs Negative Comparison\")\n    print(f\"üìä Using {NUM_EXAMPLES_PER_TYPE} examples per pattern type (runtime filtered)\")\n    print(f\"üîç Pattern Type: {COMPARISON_PATTERN_TYPE}\")\n    print(f\"üß† Pattern: {pattern_name}\")\n    print(f\"üèóÔ∏è Layer: {COMPARISON_LAYER} ‚Üí {layers_to_use}\")\n    print(f\"üíâ Injection layer: {COMPARISON_INJECTION_LAYER}\")\n    print(f\"üîß Strategy: {COMPARISON_STRATEGY.value}\")\n    print(\"\\\\n\" + \"=\"*80)\n    \n    # Show pattern details\n    print(\"\\\\nüîç PATTERN DETAILS:\")\n    show_pattern_info(selected_pattern)\n    print(\"\\\\n\" + \"=\"*80)\n    \n    try:\n        # Interpret positive pattern\n        print(\"\\\\n‚úÖ Analyzing POSITIVE pattern...\")\n        print(f\"Text: {positive_text}\")\n        \n        positive_results = selfie_patcher.interpret_text(\n            text=positive_text,\n            layers_to_interpret=layers_to_use,\n            interpretation_template=COMPARISON_TEMPLATE,\n            max_new_tokens=COMPARISON_MAX_TOKENS,\n            batch_size=1,\n            k=COMPARISON_INJECTION_LAYER\n        )\n        \n        # Interpret negative pattern\n        print(\"\\\\n‚ùå Analyzing NEGATIVE pattern...\")\n        print(f\"Text: {negative_text}\")\n        \n        negative_results = selfie_patcher.interpret_text(\n            text=negative_text,\n            layers_to_interpret=layers_to_use,\n            interpretation_template=COMPARISON_TEMPLATE,\n            max_new_tokens=COMPARISON_MAX_TOKENS,\n            batch_size=1,\n            k=COMPARISON_INJECTION_LAYER\n        )\n        \n        print(\"\\\\nüéä EXPERIMENT 2 RESULTS:\")\n        print(\"=\" * 80)\n        \n        print(\"\\\\n‚úÖ POSITIVE INTERPRETATION:\")\n        for idx, row in positive_results.iterrows():\n            print(f\"   {row['interpretation'].strip()}\")\n        \n        print(\"\\\\n‚ùå NEGATIVE INTERPRETATION:\")\n        for idx, row in negative_results.iterrows():\n            print(f\"   {row['interpretation'].strip()}\")\n        \n        # Store results for further analysis\n        comparison_results = {\n            'positive': positive_results,\n            'negative': negative_results,\n            'pattern_name': pattern_name,\n            'pattern_type': COMPARISON_PATTERN_TYPE\n        }\n        \n    except Exception as e:\n        print(f\"‚ùå Error in comparison experiment: {e}\")\n\nexcept Exception as e:\n    print(f\"‚ùå Error loading pattern: {e}\")\n    print(\"Available pattern types:\")\n    for pattern_type in filtered_pattern_types.keys():\n        print(f\"  - {pattern_type}\")\n\nprint(\"\\\\n\" + \"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Multi-Layer Analysis\n",
    "\n",
    "Analyze how interpretations change across different layers of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# EXPERIMENT 3: Multi-Layer Analysis\n\n# ===== CONFIGURATION SECTION =====\nNUM_EXAMPLES_PER_TYPE = 20  # Number of examples to use per pattern type (1-40)\nMULTILAYER_PATTERN_TYPE = \"Entrapment cognition\"  # Choose from available types\nMULTILAYER_PATTERN_INDEX = 2  # Which example within the type\nMULTILAYER_TEXT_TYPE = \"negative\"  # \"positive\", \"negative\", or \"transition\"\nMULTILAYER_LAYERS = \"0:10:2\"  # Enhanced options: \"all\", [-1, -2, -3], (0, 5), \"0:5\", \"0:10:2\"\nMULTILAYER_TEMPLATE = \"cognitive_pattern\"\nMULTILAYER_STRATEGY = TokenSelectionStrategy.KEYWORDS\nMULTILAYER_MAX_TOKENS = 35\nMULTILAYER_INJECTION_LAYER = 1  # Layer where extracted activations are injected (0-based from start)\n# ====================================\n\n# Apply runtime filtering\nfiltered_patterns, filtered_pattern_types = filter_patterns_by_count(pattern_types, NUM_EXAMPLES_PER_TYPE)\n\ntry:\n    selected_pattern = get_pattern_by_type(filtered_pattern_types, MULTILAYER_PATTERN_TYPE, MULTILAYER_PATTERN_INDEX)\n    multilayer_text = get_pattern_text(selected_pattern, MULTILAYER_TEXT_TYPE)\n    pattern_name = selected_pattern['cognitive_pattern_name']\n    \n    # Process the layer specification\n    layers_to_use = process_layers_to_interpret(MULTILAYER_LAYERS)\n    \n    print(f\"\\\\nüß≠ EXPERIMENT 3: Multi-Layer Analysis\")\n    print(f\"üìä Using {NUM_EXAMPLES_PER_TYPE} examples per pattern type (runtime filtered)\")\n    print(f\"üîç Pattern Type: {MULTILAYER_PATTERN_TYPE}\")\n    print(f\"üß† Pattern: {pattern_name}\")\n    print(f\"üìù Text type: {MULTILAYER_TEXT_TYPE}\")\n    print(f\"üìñ Text: {multilayer_text}\")\n    print(f\"üèóÔ∏è Analyzing layers: {MULTILAYER_LAYERS} ‚Üí {layers_to_use}\")\n    print(f\"üíâ Injection layer: {MULTILAYER_INJECTION_LAYER}\")\n    print(f\"üîß Token strategy: {MULTILAYER_STRATEGY.value}\")\n    print(\"\\\\n\" + \"=\"*80)\n    \n    # Show pattern details\n    print(\"\\\\nüîç PATTERN DETAILS:\")\n    show_pattern_info(selected_pattern)\n    print(\"\\\\n\" + \"=\"*80)\n\n    try:\n        # Analyze across multiple layers\n        multilayer_results = selfie_patcher.interpret_text(\n            text=multilayer_text,\n            layers_to_interpret=layers_to_use,\n            interpretation_template=MULTILAYER_TEMPLATE,\n            max_new_tokens=MULTILAYER_MAX_TOKENS,\n            batch_size=2,\n            k=MULTILAYER_INJECTION_LAYER\n        )\n        \n        print(\"\\\\nüéä EXPERIMENT 3 RESULTS:\")\n        print(\"=\" * 80)\n        \n        # Group results by layer\n        for layer in sorted(set(layers_to_use)):\n            layer_results = multilayer_results[multilayer_results['layer'] == layer]\n            print(f\"\\\\nüèóÔ∏è LAYER {layer}:\")\n            for idx, row in layer_results.iterrows():\n                print(f\"   Token '{row['token_decoded']}' ‚Üí {row['interpretation'].strip()}\")\n        \n        # Display summary table\n        print(\"\\\\nüìä Summary Table:\")\n        display(multilayer_results[['layer', 'token_decoded', 'interpretation']])\n        \n    except Exception as e:\n        print(f\"‚ùå Error in multi-layer analysis: {e}\")\n\nexcept Exception as e:\n    print(f\"‚ùå Error loading pattern: {e}\")\n    print(\"Available pattern types:\")\n    for pattern_type in filtered_pattern_types.keys():\n        print(f\"  - {pattern_type}\")\n\nprint(\"\\\\n\" + \"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Different Interpretation Templates\n",
    "\n",
    "Test how different interpretation templates affect the results."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Experiment 5: Injection Layer Comparison\n\nCompare how different injection layers affect SelfIE interpretations.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# EXPERIMENT 4: Template Comparison\n\n# ===== CONFIGURATION SECTION =====\nNUM_EXAMPLES_PER_TYPE = 25  # Number of examples to use per pattern type (1-40)\nTEMPLATE_PATTERN_TYPE = \"Learned helplessness loop\"  # Choose from available types\nTEMPLATE_PATTERN_INDEX = 1  # Which example within the type  \nTEMPLATE_TEXT_TYPE = \"negative\"  # \"positive\", \"negative\", or \"transition\"\nTEMPLATES_TO_TEST = [\n    'cognitive_pattern',\n    'emotional_state', \n    'psychological_state',\n    'decision_making'\n]\nTEMPLATE_LAYER = (29, 32)  # Enhanced options: \"all\", [-1, -2, -3], (0, 5), \"0:5\", \"0:10:2\"\nTEMPLATE_STRATEGY = TokenSelectionStrategy.LAST_COUPLE\nTEMPLATE_MAX_TOKENS = 25\nTEMPLATE_INJECTION_LAYER = 1  # Layer where extracted activations are injected (0-based from start)\n# ====================================\n\n# Apply runtime filtering\nfiltered_patterns, filtered_pattern_types = filter_patterns_by_count(pattern_types, NUM_EXAMPLES_PER_TYPE)\n\ntry:\n    selected_pattern = get_pattern_by_type(filtered_pattern_types, TEMPLATE_PATTERN_TYPE, TEMPLATE_PATTERN_INDEX)\n    template_test_text = get_pattern_text(selected_pattern, TEMPLATE_TEXT_TYPE)\n    pattern_name = selected_pattern['cognitive_pattern_name']\n    \n    # Process the layer specification\n    layers_to_use = process_layers_to_interpret(TEMPLATE_LAYER)\n    \n    print(f\"\\\\nüé≠ EXPERIMENT 4: Template Comparison\")\n    print(f\"üìä Using {NUM_EXAMPLES_PER_TYPE} examples per pattern type (runtime filtered)\")\n    print(f\"üîç Pattern Type: {TEMPLATE_PATTERN_TYPE}\")\n    print(f\"üß† Pattern: {pattern_name}\")\n    print(f\"üìù Text type: {TEMPLATE_TEXT_TYPE}\")\n    print(f\"üìñ Text: {template_test_text}\")\n    print(f\"üé≠ Templates to test: {TEMPLATES_TO_TEST}\")\n    print(f\"üèóÔ∏è Layers: {TEMPLATE_LAYER} ‚Üí {layers_to_use}\")\n    print(f\"üíâ Injection layer: {TEMPLATE_INJECTION_LAYER}\")\n    print(\"\\\\n\" + \"=\"*80)\n    \n    # Show pattern details\n    print(\"\\\\nüîç PATTERN DETAILS:\")\n    show_pattern_info(selected_pattern)\n    print(\"\\\\n\" + \"=\"*80)\n\n    template_comparison = {}\n\n    for template in TEMPLATES_TO_TEST:\n        print(f\"\\\\nüîç Testing template: {template}\")\n        \n        try:\n            results = selfie_patcher.interpret_text(\n                text=template_test_text,\n                layers_to_interpret=layers_to_use,\n                interpretation_template=template,\n                max_new_tokens=TEMPLATE_MAX_TOKENS,\n                batch_size=1,\n                k=TEMPLATE_INJECTION_LAYER\n            )\n            \n            template_comparison[template] = results\n            \n            # Show first interpretation\n            if not results.empty:\n                first_interpretation = results.iloc[0]['interpretation'].strip()\n                print(f\"   ‚Üí {first_interpretation}\")\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error with template {template}: {e}\")\n            template_comparison[template] = None\n\n    print(\"\\\\nüéä EXPERIMENT 4 RESULTS SUMMARY:\")\n    print(\"=\" * 80)\n\n    for template, results in template_comparison.items():\n        print(f\"\\\\nüé≠ {template.upper()}:\")\n        if results is not None and not results.empty:\n            for idx, row in results.iterrows():\n                print(f\"   {row['interpretation'].strip()}\")\n        else:\n            print(\"   No results or error occurred\")\n\nexcept Exception as e:\n    print(f\"‚ùå Error loading pattern: {e}\")\n    print(\"Available pattern types:\")\n    for pattern_type in filtered_pattern_types.keys():\n        print(f\"  - {pattern_type}\")\n\nprint(\"\\\\n\" + \"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features (Placeholders)\n",
    "\n",
    "The following cells demonstrate the interface for advanced SelfIE features that are planned for future implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Supervised Control\n",
    "# This would implement the supervised control technique from the SelfIE paper\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Supervised Control\")\n",
    "print(\"This feature would allow editing concepts in the model's hidden representations.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"selfie_patcher.supervised_control('reduce_negative_self_talk', control_strength=0.8)\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     result = selfie_patcher.supervised_control(\n",
    "#         target_concept=\"reduce_negative_self_talk\",\n",
    "#         control_strength=0.8\n",
    "#     )\n",
    "#     print(f\"‚úì Applied supervised control: {result}\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Reinforcement Control\n",
    "# This would implement RLHF on hidden embeddings to erase harmful knowledge\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Reinforcement Control\")\n",
    "print(\"This feature would use reinforcement learning to remove harmful concepts.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"selfie_patcher.reinforcement_control(['self_harm', 'suicidal_ideation'])\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     result = selfie_patcher.reinforcement_control([\n",
    "#         'self_harm_thoughts', \n",
    "#         'suicidal_ideation',\n",
    "#         'extreme_negative_self_evaluation'\n",
    "#     ])\n",
    "#     print(f\"‚úì Applied reinforcement control: {result}\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Batch Processing\n",
    "# This would efficiently process multiple cognitive patterns\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Batch Pattern Processing\")\n",
    "print(\"This feature would process multiple cognitive patterns efficiently.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"results = selfie_patcher.batch_interpret_patterns(patterns, batch_size=8)\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     batch_results = selfie_patcher.batch_interpret_patterns(\n",
    "#         patterns=patterns[:5],  # First 5 patterns\n",
    "#         batch_size=4\n",
    "#     )\n",
    "#     print(f\"‚úì Processed {len(batch_results)} patterns\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Visualization\n",
    "# This would create visualizations of interpretation results\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Interpretation Visualization\")\n",
    "print(\"This feature would create interactive visualizations of results.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"selfie_patcher.visualize_interpretations(interpretation_results)\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     if 'interpretation_results' in locals():\n",
    "#         viz = selfie_patcher.visualize_interpretations(interpretation_results)\n",
    "#         print(\"‚úì Created visualization\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Export Functionality  \n",
    "# This would export results in various formats\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Export Functionality\")\n",
    "print(\"This feature would export interpretation results to various formats.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"selfie_patcher.export_interpretations(results, format='json')\")\n",
    "print(\"selfie_patcher.export_interpretations(results, format='csv')\")\n",
    "print(\"selfie_patcher.export_interpretations(results, format='html')\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     if 'interpretation_results' in locals():\n",
    "#         export_path = selfie_patcher.export_interpretations(\n",
    "#             interpretation_results, \n",
    "#             format='json'\n",
    "#         )\n",
    "#         print(f\"‚úì Exported results to: {export_path}\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for the notebook\n",
    "\n",
    "def reset_environment():\n",
    "    \"\"\"Reset the SelfIE environment\"\"\"\n",
    "    selfie_patcher.reset_hooks()  # No-op for SelfIE but maintains compatibility\n",
    "    print(\"üîÑ Environment reset\")\n",
    "\n",
    "def show_model_info():\n",
    "    \"\"\"Display current model information\"\"\"\n",
    "    selfie_patcher.check_model_info()\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU memory\"\"\"\n",
    "    SelfIEPatcher.clear_memory()\n",
    "\n",
    "print(\"Utility functions loaded:\")\n",
    "print(\"- reset_environment() - Reset the environment\")\n",
    "print(\"- show_model_info() - Display model information\")\n",
    "print(\"- clear_memory() - Clear GPU memory\")\n",
    "\n",
    "# Uncomment any line below to run:\n",
    "# reset_environment()\n",
    "# show_model_info()\n",
    "# clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook provides a foundation for using SelfIE to interpret cognitive patterns. The key advantages over activation patching:\n",
    "\n",
    "1. **Interpretability**: Direct natural language descriptions of internal representations\n",
    "2. **No Modification**: Analyzes the model without changing its behavior\n",
    "3. **Flexibility**: Can interpret any concept the model understands\n",
    "\n",
    "### To fully implement:\n",
    "1. Set up the environment with transformers==4.34.0\n",
    "2. Install the SelfIE library from the third_party directory\n",
    "3. Use a LLaMA-compatible model\n",
    "4. Implement the advanced features marked as placeholders\n",
    "5. Add dataset integration for seamless cognitive pattern analysis\n",
    "\n",
    "### Future enhancements:\n",
    "- Supervised control for editing cognitive patterns\n",
    "- Reinforcement learning for removing harmful patterns\n",
    "- Interactive visualization of interpretations\n",
    "- Batch processing for large-scale analysis\n",
    "- Export capabilities for research and clinical use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfie_psych_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}