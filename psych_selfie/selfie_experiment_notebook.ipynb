{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SelfIE Psychology Experiments\n",
    "\n",
    "This notebook implements cognitive pattern analysis using the SelfIE (Self-Interpretation of Embeddings) technique, providing a similar workflow to the manual activation patching experiments but using the model's own ability to interpret its internal representations.\n",
    "\n",
    "## How SelfIE Works Here\n",
    "\n",
    "- **Source text**: We extract internal representations from cognitive pattern text\n",
    "- **Interpretation**: The model describes what these representations mean in natural language\n",
    "- **Analysis**: We compare interpretations between different types of cognitive patterns\n",
    "\n",
    "Unlike activation patching which modifies model behavior, SelfIE reveals what the model \"thinks\" its internal representations mean, providing interpretable insights into cognitive processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Will use manual pattern definitions\n",
      "SelfIE Psychology Experiment Setup Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/7dtls20x09b3wbrz991y78tw0000gn/T/ipykernel_15215/1098097379.py:31: UserWarning: Could not import pattern utilities: No module named 'jaxtyping'\n",
      "  warnings.warn(f\"Could not import pattern utilities: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "\n",
    "# Add our SelfIE wrapper to path\n",
    "sys.path.append('/Users/ivanculo/Desktop/Projects/turn_point/psych_selfie')\n",
    "sys.path.append('/Users/ivanculo/Desktop/Projects/turn_point/manual_activation_patching')\n",
    "\n",
    "# Import SelfIE wrapper\n",
    "from selfie_patcher import SelfIEPatcher, TokenSelectionStrategy\n",
    "\n",
    "# Import utility functions from the original activation patcher for dataset loading\n",
    "try:\n",
    "    from activation_patcher import ActivationPatcher\n",
    "    load_cognitive_patterns = ActivationPatcher.load_cognitive_patterns\n",
    "    get_pattern_by_index = ActivationPatcher.get_pattern_by_index\n",
    "    get_pattern_by_type = ActivationPatcher.get_pattern_by_type\n",
    "    get_pattern_text = ActivationPatcher.get_pattern_text\n",
    "    filter_patterns_by_count = ActivationPatcher.filter_patterns_by_count\n",
    "    get_filtered_patterns_by_type = ActivationPatcher.get_filtered_patterns_by_type\n",
    "    list_available_pattern_types = ActivationPatcher.list_available_pattern_types\n",
    "    show_pattern_info = ActivationPatcher.show_pattern_info\n",
    "    get_random_pattern_by_type = ActivationPatcher.get_random_pattern_by_type\n",
    "    get_patterns_by_type = ActivationPatcher.get_patterns_by_type\n",
    "    print(\"‚úì Successfully imported cognitive pattern utilities\")\n",
    "except ImportError as e:\n",
    "    warnings.warn(f\"Could not import pattern utilities: {e}\")\n",
    "    print(\"‚ö†Ô∏è  Will use manual pattern definitions\")\n",
    "\n",
    "print(\"SelfIE Psychology Experiment Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requriements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection - Choose a LLaMA-compatible model for SelfIE\n",
    "# Note: SelfIE currently works best with LLaMA models\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"  # Change to available LLaMA model\n",
    "# Alternative models to try:\n",
    "# MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# MODEL_NAME = \"huggyllama/llama-7b\"\n",
    "\n",
    "# Initialize the SelfIE patcher\n",
    "print(f\"Initializing SelfIE with model: {MODEL_NAME}\")\n",
    "print(\"Note: This requires transformers==4.34.0 (see requirements.txt)\")\n",
    "\n",
    "try:\n",
    "    selfie_patcher = SelfIEPatcher(MODEL_NAME)\n",
    "    print(\"‚úì SelfIE patcher initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing SelfIE: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting tips:\")\n",
    "    print(\"1. Ensure you have transformers==4.34.0 installed\")\n",
    "    print(\"2. Make sure the model is available and you have access\")\n",
    "    print(\"3. Try a different LLaMA model\")\n",
    "    print(\"4. Check your GPU memory and CUDA setup\")\n",
    "\n",
    "# Load the cognitive patterns dataset\n",
    "print(\"\\nüìä Loading cognitive patterns dataset...\")\n",
    "try:\n",
    "    patterns, pattern_types = load_cognitive_patterns()\n",
    "    print(f\"‚úì Loaded {len(patterns)} cognitive patterns\")\n",
    "    print(f\"‚úì Found {len(pattern_types)} different pattern types\")\n",
    "    print(\"\\nüìã Available pattern types:\")\n",
    "    list_available_pattern_types(pattern_types)\n",
    "    print(f\"\\nüí° Each pattern has three text variants: positive, negative, transition\")\n",
    "    print(\"Available text types: positive, negative, transition\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading dataset: {e}\")\n",
    "    print(\"\\n‚ö†Ô∏è  Using manual pattern definitions for this demo\")\n",
    "    # Define some sample patterns manually\n",
    "    patterns = [\n",
    "        {\n",
    "            'cognitive_pattern_name': 'Negative Self-Evaluation',\n",
    "            'cognitive_pattern_type': 'Negative self-evaluative loop',\n",
    "            'positive_thought_pattern': \"I'm learning and growing from my mistakes, and that's part of being human.\",\n",
    "            'reference_negative_example': \"I always mess everything up and never do anything right.\",\n",
    "            'reference_transformed_example': \"I made a mistake, but I can learn from this experience.\"\n",
    "        },\n",
    "        {\n",
    "            'cognitive_pattern_name': 'Anxiety Response',\n",
    "            'cognitive_pattern_type': 'Anxiety pattern',\n",
    "            'positive_thought_pattern': \"I can handle challenging situations by taking things one step at a time.\",\n",
    "            'reference_negative_example': \"Everything is going to go wrong and I won't be able to cope.\",\n",
    "            'reference_transformed_example': \"I'm feeling anxious, but I can use coping strategies to manage this.\"\n",
    "        }\n",
    "    ]\n",
    "    pattern_types = {\n",
    "        'Negative self-evaluative loop': [patterns[0]], \n",
    "        'Anxiety pattern': [patterns[1]]\n",
    "    }\n",
    "    print(f\"‚úì Using {len(patterns)} manual patterns for demonstration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ TEST: Verify Data Loading and Access\n",
    "\n",
    "print(\"üß™ TESTING DATA LOADING AND ACCESS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Test basic data access\n",
    "    print(f\"üìä Total patterns loaded: {len(patterns)}\")\n",
    "    print(f\"üìã Pattern types available: {len(pattern_types)}\")\n",
    "    \n",
    "    # Test filtering functionality\n",
    "    test_filtered_patterns, test_filtered_types = filter_patterns_by_count(pattern_types, 5)\n",
    "    print(f\"‚úÖ Filtering test: {len(test_filtered_patterns)} patterns when limited to 5 per type\")\n",
    "    \n",
    "    # Test pattern retrieval\n",
    "    first_pattern_type = list(pattern_types.keys())[0]\n",
    "    test_pattern = get_pattern_by_type(pattern_types, first_pattern_type, 0)\n",
    "    print(f\"‚úÖ Pattern retrieval test: Got pattern '{test_pattern['cognitive_pattern_name']}'\")\n",
    "    \n",
    "    # Test text extraction\n",
    "    positive_text = get_pattern_text(test_pattern, \"positive\")\n",
    "    negative_text = get_pattern_text(test_pattern, \"negative\")\n",
    "    transition_text = get_pattern_text(test_pattern, \"transition\")\n",
    "    \n",
    "    print(f\"‚úÖ Text extraction test:\")\n",
    "    print(f\"   Positive: {positive_text[:50]}...\")\n",
    "    print(f\"   Negative: {negative_text[:50]}...\")\n",
    "    print(f\"   Transition: {transition_text[:50]}...\")\n",
    "    \n",
    "    # Show sample pattern info\n",
    "    print(f\"\\nüìã SAMPLE PATTERN DETAILS:\")\n",
    "    show_pattern_info(test_pattern)\n",
    "    \n",
    "    print(f\"\\nüéâ All data loading tests PASSED!\")\n",
    "    print(f\"‚úÖ Ready to run SelfIE experiments with cognitive patterns dataset\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Data loading test FAILED: {e}\")\n",
    "    print(\"Check that the dataset path and utility functions are correct\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Basic SelfIE Interpretation\n",
    "\n",
    "Let's start with a simple experiment to interpret internal representations of cognitive patterns using SelfIE.\n",
    "\n",
    "### What this experiment does:\n",
    "- **Input**: We provide a cognitive pattern text (positive or negative thought)\n",
    "- **Extraction**: SelfIE extracts internal representations from specific layers and token positions\n",
    "- **Interpretation**: The model describes what these representations mean in natural language\n",
    "- **Analysis**: We examine the interpretations to understand how the model processes different cognitive patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 1: Basic SelfIE Interpretation\n",
    "\n",
    "# ===== CONFIGURATION SECTION =====\n",
    "NUM_EXAMPLES_PER_TYPE = 10  # Number of examples to use per pattern type (1-40)\n",
    "PATTERN_TYPE = \"Cognitive depletion pattern\"  # Choose from the list above\n",
    "PATTERN_INDEX_WITHIN_TYPE = 0  # If there are multiple examples of this type, choose which one (0-based)\n",
    "TEXT_TYPE = \"negative\"  # \"positive\", \"negative\", or \"transition\"\n",
    "INTERPRETATION_TEMPLATE = \"cognitive_pattern\"  # Template for interpretation\n",
    "LAYERS_TO_INTERPRET = [-1, -2, -3]  # Which layers to extract representations from (negative = from end)\n",
    "TOKEN_STRATEGY = TokenSelectionStrategy.LAST_TOKEN  # How to select tokens\n",
    "MAX_INTERPRETATION_TOKENS = 40  # Max tokens for interpretation\n",
    "BATCH_SIZE = 2\n",
    "# ====================================\n",
    "\n",
    "# Apply runtime filtering to use only NUM_EXAMPLES_PER_TYPE examples per pattern type\n",
    "filtered_patterns, filtered_pattern_types = filter_patterns_by_count(pattern_types, NUM_EXAMPLES_PER_TYPE)\n",
    "\n",
    "# Get the pattern to analyze using the filtered dataset\n",
    "try:\n",
    "    selected_pattern = get_pattern_by_type(filtered_pattern_types, PATTERN_TYPE, PATTERN_INDEX_WITHIN_TYPE)\n",
    "    input_text = get_pattern_text(selected_pattern, TEXT_TYPE)\n",
    "    pattern_name = selected_pattern['cognitive_pattern_name']\n",
    "    \n",
    "    print(f\"\\nüß† EXPERIMENT 1: SelfIE Interpretation\")\n",
    "    print(f\"üìä Using {NUM_EXAMPLES_PER_TYPE} examples per pattern type (runtime filtered)\")\n",
    "    print(f\"üîç Pattern Type: {PATTERN_TYPE}\")\n",
    "    print(f\"üß† Pattern: {pattern_name}\")\n",
    "    print(f\"üìù Text type: {TEXT_TYPE}\")\n",
    "    print(f\"üìñ Input text: {input_text}\")\n",
    "    print(f\"üèóÔ∏è Layers to interpret: {LAYERS_TO_INTERPRET}\")\n",
    "    print(f\"üîß Token strategy: {TOKEN_STRATEGY.value}\")\n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "\n",
    "    # Show pattern details for context\n",
    "    print(\"\\\\nüîç PATTERN DETAILS:\")\n",
    "    show_pattern_info(selected_pattern)\n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading pattern: {e}\")\n",
    "    print(\"Available pattern types:\")\n",
    "    for pattern_type in filtered_pattern_types.keys():\n",
    "        print(f\"  - {pattern_type}\")\n",
    "    # Fallback to first available pattern\n",
    "    if filtered_patterns:\n",
    "        selected_pattern = filtered_patterns[0]\n",
    "        input_text = get_pattern_text(selected_pattern, \"positive\")  # fallback to positive\n",
    "        pattern_name = selected_pattern['cognitive_pattern_name']\n",
    "        print(f\"\\\\nUsing fallback pattern: {pattern_name}\")\n",
    "    else:\n",
    "        input_text = \"I feel overwhelmed and don't know how to handle this situation.\"\n",
    "        pattern_name = \"Sample Pattern\"\n",
    "        print(\"\\\\nUsing manual fallback text\")\n",
    "\n",
    "try:\n",
    "    # Perform SelfIE interpretation\n",
    "    interpretation_results = selfie_patcher.interpret_text(\n",
    "        text=input_text,\n",
    "        layers_to_interpret=LAYERS_TO_INTERPRET,\n",
    "        interpretation_template=INTERPRETATION_TEMPLATE,\n",
    "        max_new_tokens=MAX_INTERPRETATION_TOKENS,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    print(\"\\\\nüéä EXPERIMENT 1 RESULTS:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Display results in a readable format\n",
    "    for idx, row in interpretation_results.iterrows():\n",
    "        print(f\"\\\\nüìç Layer {row['layer']}, Token {row['token']} ('{row['token_decoded']}'):\")\n",
    "        print(f\"   Interpretation: {row['interpretation'].strip()}\")\n",
    "    \n",
    "    print(\"\\\\nüìä Full Results DataFrame:\")\n",
    "    display(interpretation_results[['layer', 'token', 'token_decoded', 'interpretation']])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in SelfIE interpretation: {e}\")\n",
    "    print(\"\\\\nüîß Troubleshooting:\")\n",
    "    print(\"1. Check that the model is properly loaded\")\n",
    "    print(\"2. Verify the model is LLaMA-compatible\")\n",
    "    print(\"3. Ensure sufficient GPU memory\")\n",
    "    print(\"4. Try reducing batch_size or max_new_tokens\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Comparing Positive vs Negative Patterns\n",
    "\n",
    "Let's compare how the model interprets positive versus negative cognitive patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 2: Positive vs Negative Pattern Comparison\n",
    "\n",
    "# ===== CONFIGURATION SECTION =====\n",
    "NUM_EXAMPLES_PER_TYPE = 15  # Number of examples to use per pattern type (1-40)\n",
    "COMPARISON_PATTERN_TYPE = \"Intrusive suicidal fixation\"  # Choose from available types\n",
    "COMPARISON_PATTERN_INDEX = 0  # Which example within the type\n",
    "COMPARISON_LAYER = -1  # Focus on final layer\n",
    "COMPARISON_STRATEGY = TokenSelectionStrategy.LAST_TOKEN\n",
    "COMPARISON_TEMPLATE = \"psychological_state\"\n",
    "COMPARISON_MAX_TOKENS = 30\n",
    "# ====================================\n",
    "\n",
    "# Apply runtime filtering\n",
    "filtered_patterns, filtered_pattern_types = filter_patterns_by_count(pattern_types, NUM_EXAMPLES_PER_TYPE)\n",
    "\n",
    "try:\n",
    "    selected_pattern = get_pattern_by_type(filtered_pattern_types, COMPARISON_PATTERN_TYPE, COMPARISON_PATTERN_INDEX)\n",
    "    \n",
    "    positive_text = get_pattern_text(selected_pattern, \"positive\")\n",
    "    negative_text = get_pattern_text(selected_pattern, \"negative\")\n",
    "    pattern_name = selected_pattern['cognitive_pattern_name']\n",
    "    \n",
    "    print(f\"\\\\nüîÑ EXPERIMENT 2: Positive vs Negative Comparison\")\n",
    "    print(f\"üìä Using {NUM_EXAMPLES_PER_TYPE} examples per pattern type (runtime filtered)\")\n",
    "    print(f\"üîç Pattern Type: {COMPARISON_PATTERN_TYPE}\")\n",
    "    print(f\"üß† Pattern: {pattern_name}\")\n",
    "    print(f\"üèóÔ∏è Layer: {COMPARISON_LAYER}\")\n",
    "    print(f\"üîß Strategy: {COMPARISON_STRATEGY.value}\")\n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Show pattern details\n",
    "    print(\"\\\\nüîç PATTERN DETAILS:\")\n",
    "    show_pattern_info(selected_pattern)\n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Interpret positive pattern\n",
    "        print(\"\\\\n‚úÖ Analyzing POSITIVE pattern...\")\n",
    "        print(f\"Text: {positive_text}\")\n",
    "        \n",
    "        positive_results = selfie_patcher.interpret_text(\n",
    "            text=positive_text,\n",
    "            layers_to_interpret=[COMPARISON_LAYER],\n",
    "            interpretation_template=COMPARISON_TEMPLATE,\n",
    "            max_new_tokens=COMPARISON_MAX_TOKENS,\n",
    "            batch_size=1\n",
    "        )\n",
    "        \n",
    "        # Interpret negative pattern\n",
    "        print(\"\\\\n‚ùå Analyzing NEGATIVE pattern...\")\n",
    "        print(f\"Text: {negative_text}\")\n",
    "        \n",
    "        negative_results = selfie_patcher.interpret_text(\n",
    "            text=negative_text,\n",
    "            layers_to_interpret=[COMPARISON_LAYER],\n",
    "            interpretation_template=COMPARISON_TEMPLATE,\n",
    "            max_new_tokens=COMPARISON_MAX_TOKENS,\n",
    "            batch_size=1\n",
    "        )\n",
    "        \n",
    "        print(\"\\\\nüéä EXPERIMENT 2 RESULTS:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(\"\\\\n‚úÖ POSITIVE INTERPRETATION:\")\n",
    "        for idx, row in positive_results.iterrows():\n",
    "            print(f\"   {row['interpretation'].strip()}\")\n",
    "        \n",
    "        print(\"\\\\n‚ùå NEGATIVE INTERPRETATION:\")\n",
    "        for idx, row in negative_results.iterrows():\n",
    "            print(f\"   {row['interpretation'].strip()}\")\n",
    "        \n",
    "        # Store results for further analysis\n",
    "        comparison_results = {\n",
    "            'positive': positive_results,\n",
    "            'negative': negative_results,\n",
    "            'pattern_name': pattern_name,\n",
    "            'pattern_type': COMPARISON_PATTERN_TYPE\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in comparison experiment: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading pattern: {e}\")\n",
    "    print(\"Available pattern types:\")\n",
    "    for pattern_type in filtered_pattern_types.keys():\n",
    "        print(f\"  - {pattern_type}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Multi-Layer Analysis\n",
    "\n",
    "Analyze how interpretations change across different layers of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 3: Multi-Layer Analysis\n",
    "\n",
    "# ===== CONFIGURATION SECTION =====\n",
    "NUM_EXAMPLES_PER_TYPE = 20  # Number of examples to use per pattern type (1-40)\n",
    "MULTILAYER_PATTERN_TYPE = \"Entrapment cognition\"  # Choose from available types\n",
    "MULTILAYER_PATTERN_INDEX = 2  # Which example within the type\n",
    "MULTILAYER_TEXT_TYPE = \"negative\"  # \"positive\", \"negative\", or \"transition\"\n",
    "MULTILAYER_LAYERS = [-5, -3, -1]  # Early, middle, and final layers\n",
    "MULTILAYER_TEMPLATE = \"cognitive_pattern\"\n",
    "MULTILAYER_STRATEGY = TokenSelectionStrategy.KEYWORDS\n",
    "MULTILAYER_MAX_TOKENS = 35\n",
    "# ====================================\n",
    "\n",
    "# Apply runtime filtering\n",
    "filtered_patterns, filtered_pattern_types = filter_patterns_by_count(pattern_types, NUM_EXAMPLES_PER_TYPE)\n",
    "\n",
    "try:\n",
    "    selected_pattern = get_pattern_by_type(filtered_pattern_types, MULTILAYER_PATTERN_TYPE, MULTILAYER_PATTERN_INDEX)\n",
    "    multilayer_text = get_pattern_text(selected_pattern, MULTILAYER_TEXT_TYPE)\n",
    "    pattern_name = selected_pattern['cognitive_pattern_name']\n",
    "    \n",
    "    print(f\"\\\\nüß≠ EXPERIMENT 3: Multi-Layer Analysis\")\n",
    "    print(f\"üìä Using {NUM_EXAMPLES_PER_TYPE} examples per pattern type (runtime filtered)\")\n",
    "    print(f\"üîç Pattern Type: {MULTILAYER_PATTERN_TYPE}\")\n",
    "    print(f\"üß† Pattern: {pattern_name}\")\n",
    "    print(f\"üìù Text type: {MULTILAYER_TEXT_TYPE}\")\n",
    "    print(f\"üìñ Text: {multilayer_text}\")\n",
    "    print(f\"üèóÔ∏è Analyzing layers: {MULTILAYER_LAYERS}\")\n",
    "    print(f\"üîß Token strategy: {MULTILAYER_STRATEGY.value}\")\n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Show pattern details\n",
    "    print(\"\\\\nüîç PATTERN DETAILS:\")\n",
    "    show_pattern_info(selected_pattern)\n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "\n",
    "    try:\n",
    "        # Analyze across multiple layers\n",
    "        multilayer_results = selfie_patcher.interpret_text(\n",
    "            text=multilayer_text,\n",
    "            layers_to_interpret=MULTILAYER_LAYERS,\n",
    "            interpretation_template=MULTILAYER_TEMPLATE,\n",
    "            max_new_tokens=MULTILAYER_MAX_TOKENS,\n",
    "            batch_size=2\n",
    "        )\n",
    "        \n",
    "        print(\"\\\\nüéä EXPERIMENT 3 RESULTS:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Group results by layer\n",
    "        for layer in MULTILAYER_LAYERS:\n",
    "            layer_results = multilayer_results[multilayer_results['layer'] == layer]\n",
    "            print(f\"\\\\nüèóÔ∏è LAYER {layer}:\")\n",
    "            for idx, row in layer_results.iterrows():\n",
    "                print(f\"   Token '{row['token_decoded']}' ‚Üí {row['interpretation'].strip()}\")\n",
    "        \n",
    "        # Display summary table\n",
    "        print(\"\\\\nüìä Summary Table:\")\n",
    "        display(multilayer_results[['layer', 'token_decoded', 'interpretation']])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in multi-layer analysis: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading pattern: {e}\")\n",
    "    print(\"Available pattern types:\")\n",
    "    for pattern_type in filtered_pattern_types.keys():\n",
    "        print(f\"  - {pattern_type}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Different Interpretation Templates\n",
    "\n",
    "Test how different interpretation templates affect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 4: Template Comparison\n",
    "\n",
    "# ===== CONFIGURATION SECTION =====\n",
    "NUM_EXAMPLES_PER_TYPE = 25  # Number of examples to use per pattern type (1-40)\n",
    "TEMPLATE_PATTERN_TYPE = \"Learned helplessness loop\"  # Choose from available types\n",
    "TEMPLATE_PATTERN_INDEX = 1  # Which example within the type  \n",
    "TEMPLATE_TEXT_TYPE = \"negative\"  # \"positive\", \"negative\", or \"transition\"\n",
    "TEMPLATES_TO_TEST = [\n",
    "    'cognitive_pattern',\n",
    "    'emotional_state', \n",
    "    'psychological_state',\n",
    "    'decision_making'\n",
    "]\n",
    "TEMPLATE_LAYER = -1\n",
    "TEMPLATE_STRATEGY = TokenSelectionStrategy.LAST_COUPLE\n",
    "TEMPLATE_MAX_TOKENS = 25\n",
    "# ====================================\n",
    "\n",
    "# Apply runtime filtering\n",
    "filtered_patterns, filtered_pattern_types = filter_patterns_by_count(pattern_types, NUM_EXAMPLES_PER_TYPE)\n",
    "\n",
    "try:\n",
    "    selected_pattern = get_pattern_by_type(filtered_pattern_types, TEMPLATE_PATTERN_TYPE, TEMPLATE_PATTERN_INDEX)\n",
    "    template_test_text = get_pattern_text(selected_pattern, TEMPLATE_TEXT_TYPE)\n",
    "    pattern_name = selected_pattern['cognitive_pattern_name']\n",
    "    \n",
    "    print(f\"\\\\nüé≠ EXPERIMENT 4: Template Comparison\")\n",
    "    print(f\"üìä Using {NUM_EXAMPLES_PER_TYPE} examples per pattern type (runtime filtered)\")\n",
    "    print(f\"üîç Pattern Type: {TEMPLATE_PATTERN_TYPE}\")\n",
    "    print(f\"üß† Pattern: {pattern_name}\")\n",
    "    print(f\"üìù Text type: {TEMPLATE_TEXT_TYPE}\")\n",
    "    print(f\"üìñ Text: {template_test_text}\")\n",
    "    print(f\"üé≠ Templates to test: {TEMPLATES_TO_TEST}\")\n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Show pattern details\n",
    "    print(\"\\\\nüîç PATTERN DETAILS:\")\n",
    "    show_pattern_info(selected_pattern)\n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "\n",
    "    template_comparison = {}\n",
    "\n",
    "    for template in TEMPLATES_TO_TEST:\n",
    "        print(f\"\\\\nüîç Testing template: {template}\")\n",
    "        \n",
    "        try:\n",
    "            results = selfie_patcher.interpret_text(\n",
    "                text=template_test_text,\n",
    "                layers_to_interpret=[TEMPLATE_LAYER],\n",
    "                interpretation_template=template,\n",
    "                max_new_tokens=TEMPLATE_MAX_TOKENS,\n",
    "                batch_size=1\n",
    "            )\n",
    "            \n",
    "            template_comparison[template] = results\n",
    "            \n",
    "            # Show first interpretation\n",
    "            if not results.empty:\n",
    "                first_interpretation = results.iloc[0]['interpretation'].strip()\n",
    "                print(f\"   ‚Üí {first_interpretation}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error with template {template}: {e}\")\n",
    "            template_comparison[template] = None\n",
    "\n",
    "    print(\"\\\\nüéä EXPERIMENT 4 RESULTS SUMMARY:\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for template, results in template_comparison.items():\n",
    "        print(f\"\\\\nüé≠ {template.upper()}:\")\n",
    "        if results is not None and not results.empty:\n",
    "            for idx, row in results.iterrows():\n",
    "                print(f\"   {row['interpretation'].strip()}\")\n",
    "        else:\n",
    "            print(\"   No results or error occurred\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading pattern: {e}\")\n",
    "    print(\"Available pattern types:\")\n",
    "    for pattern_type in filtered_pattern_types.keys():\n",
    "        print(f\"  - {pattern_type}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features (Placeholders)\n",
    "\n",
    "The following cells demonstrate the interface for advanced SelfIE features that are planned for future implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Supervised Control\n",
    "# This would implement the supervised control technique from the SelfIE paper\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Supervised Control\")\n",
    "print(\"This feature would allow editing concepts in the model's hidden representations.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"selfie_patcher.supervised_control('reduce_negative_self_talk', control_strength=0.8)\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     result = selfie_patcher.supervised_control(\n",
    "#         target_concept=\"reduce_negative_self_talk\",\n",
    "#         control_strength=0.8\n",
    "#     )\n",
    "#     print(f\"‚úì Applied supervised control: {result}\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Reinforcement Control\n",
    "# This would implement RLHF on hidden embeddings to erase harmful knowledge\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Reinforcement Control\")\n",
    "print(\"This feature would use reinforcement learning to remove harmful concepts.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"selfie_patcher.reinforcement_control(['self_harm', 'suicidal_ideation'])\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     result = selfie_patcher.reinforcement_control([\n",
    "#         'self_harm_thoughts', \n",
    "#         'suicidal_ideation',\n",
    "#         'extreme_negative_self_evaluation'\n",
    "#     ])\n",
    "#     print(f\"‚úì Applied reinforcement control: {result}\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Batch Processing\n",
    "# This would efficiently process multiple cognitive patterns\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Batch Pattern Processing\")\n",
    "print(\"This feature would process multiple cognitive patterns efficiently.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"results = selfie_patcher.batch_interpret_patterns(patterns, batch_size=8)\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     batch_results = selfie_patcher.batch_interpret_patterns(\n",
    "#         patterns=patterns[:5],  # First 5 patterns\n",
    "#         batch_size=4\n",
    "#     )\n",
    "#     print(f\"‚úì Processed {len(batch_results)} patterns\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Visualization\n",
    "# This would create visualizations of interpretation results\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Interpretation Visualization\")\n",
    "print(\"This feature would create interactive visualizations of results.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"selfie_patcher.visualize_interpretations(interpretation_results)\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     if 'interpretation_results' in locals():\n",
    "#         viz = selfie_patcher.visualize_interpretations(interpretation_results)\n",
    "#         print(\"‚úì Created visualization\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Export Functionality  \n",
    "# This would export results in various formats\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Export Functionality\")\n",
    "print(\"This feature would export interpretation results to various formats.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"selfie_patcher.export_interpretations(results, format='json')\")\n",
    "print(\"selfie_patcher.export_interpretations(results, format='csv')\")\n",
    "print(\"selfie_patcher.export_interpretations(results, format='html')\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     if 'interpretation_results' in locals():\n",
    "#         export_path = selfie_patcher.export_interpretations(\n",
    "#             interpretation_results, \n",
    "#             format='json'\n",
    "#         )\n",
    "#         print(f\"‚úì Exported results to: {export_path}\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for the notebook\n",
    "\n",
    "def reset_environment():\n",
    "    \"\"\"Reset the SelfIE environment\"\"\"\n",
    "    selfie_patcher.reset_hooks()  # No-op for SelfIE but maintains compatibility\n",
    "    print(\"üîÑ Environment reset\")\n",
    "\n",
    "def show_model_info():\n",
    "    \"\"\"Display current model information\"\"\"\n",
    "    selfie_patcher.check_model_info()\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU memory\"\"\"\n",
    "    SelfIEPatcher.clear_memory()\n",
    "\n",
    "print(\"Utility functions loaded:\")\n",
    "print(\"- reset_environment() - Reset the environment\")\n",
    "print(\"- show_model_info() - Display model information\")\n",
    "print(\"- clear_memory() - Clear GPU memory\")\n",
    "\n",
    "# Uncomment any line below to run:\n",
    "# reset_environment()\n",
    "# show_model_info()\n",
    "# clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook provides a foundation for using SelfIE to interpret cognitive patterns. The key advantages over activation patching:\n",
    "\n",
    "1. **Interpretability**: Direct natural language descriptions of internal representations\n",
    "2. **No Modification**: Analyzes the model without changing its behavior\n",
    "3. **Flexibility**: Can interpret any concept the model understands\n",
    "\n",
    "### To fully implement:\n",
    "1. Set up the environment with transformers==4.34.0\n",
    "2. Install the SelfIE library from the third_party directory\n",
    "3. Use a LLaMA-compatible model\n",
    "4. Implement the advanced features marked as placeholders\n",
    "5. Add dataset integration for seamless cognitive pattern analysis\n",
    "\n",
    "### Future enhancements:\n",
    "- Supervised control for editing cognitive patterns\n",
    "- Reinforcement learning for removing harmful patterns\n",
    "- Interactive visualization of interpretations\n",
    "- Batch processing for large-scale analysis\n",
    "- Export capabilities for research and clinical use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SelfIE Psychology",
   "language": "python",
   "name": "selfie_psych"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
