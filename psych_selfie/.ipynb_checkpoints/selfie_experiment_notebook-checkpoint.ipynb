{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SelfIE Psychology Experiments\n",
    "\n",
    "This notebook implements cognitive pattern analysis using the SelfIE (Self-Interpretation of Embeddings) technique, providing a similar workflow to the manual activation patching experiments but using the model's own ability to interpret its internal representations.\n",
    "\n",
    "## How SelfIE Works Here\n",
    "\n",
    "- **Source text**: We extract internal representations from cognitive pattern text\n",
    "- **Interpretation**: The model describes what these representations mean in natural language\n",
    "- **Analysis**: We compare interpretations between different types of cognitive patterns\n",
    "\n",
    "Unlike activation patching which modifies model behavior, SelfIE reveals what the model \"thinks\" its internal representations mean, providing interpretable insights into cognitive processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "\n",
    "# Add our SelfIE wrapper to path\n",
    "sys.path.append('/Users/ivanculo/Desktop/Projects/turn_point/psych_selfie')\n",
    "sys.path.append('/Users/ivanculo/Desktop/Projects/turn_point/manual_activation_patching')\n",
    "\n",
    "# Import SelfIE wrapper\n",
    "from selfie_patcher import SelfIEPatcher, TokenSelectionStrategy\n",
    "\n",
    "# Import utility functions from the original activation patcher for dataset loading\n",
    "try:\n",
    "    from activation_patcher import ActivationPatcher\n",
    "    load_cognitive_patterns = ActivationPatcher.load_cognitive_patterns\n",
    "    get_pattern_by_index = ActivationPatcher.get_pattern_by_index\n",
    "    get_pattern_by_type = ActivationPatcher.get_pattern_by_type\n",
    "    get_pattern_text = ActivationPatcher.get_pattern_text\n",
    "    filter_patterns_by_count = ActivationPatcher.filter_patterns_by_count\n",
    "    list_available_pattern_types = ActivationPatcher.list_available_pattern_types\n",
    "    print(\"‚úì Successfully imported cognitive pattern utilities\")\n",
    "except ImportError as e:\n",
    "    warnings.warn(f\"Could not import pattern utilities: {e}\")\n",
    "    print(\"‚ö†Ô∏è  Will use manual pattern definitions\")\n",
    "\n",
    "print(\"SelfIE Psychology Experiment Setup Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection - Choose a LLaMA-compatible model for SelfIE\n",
    "# Note: SelfIE currently works best with LLaMA models\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"  # Change to available LLaMA model\n",
    "# Alternative models to try:\n",
    "# MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# MODEL_NAME = \"huggyllama/llama-7b\"\n",
    "\n",
    "# Initialize the SelfIE patcher\n",
    "print(f\"Initializing SelfIE with model: {MODEL_NAME}\")\n",
    "print(\"Note: This requires transformers==4.34.0 (see requirements.txt)\")\n",
    "\n",
    "try:\n",
    "    selfie_patcher = SelfIEPatcher(MODEL_NAME)\n",
    "    print(\"‚úì SelfIE patcher initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing SelfIE: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting tips:\")\n",
    "    print(\"1. Ensure you have transformers==4.34.0 installed\")\n",
    "    print(\"2. Make sure the model is available and you have access\")\n",
    "    print(\"3. Try a different LLaMA model\")\n",
    "    print(\"4. Check your GPU memory and CUDA setup\")\n",
    "\n",
    "# Load the cognitive patterns dataset (if available)\n",
    "try:\n",
    "    patterns, pattern_types = load_cognitive_patterns()\n",
    "    print(f\"\\n‚úì Loaded {len(patterns)} cognitive patterns\")\n",
    "    list_available_pattern_types(pattern_types)\n",
    "except:\n",
    "    print(\"\\n‚ö†Ô∏è  Using manual pattern definitions for this demo\")\n",
    "    # Define some sample patterns manually\n",
    "    patterns = [\n",
    "        {\n",
    "            'cognitive_pattern_name': 'Negative Self-Evaluation',\n",
    "            'positive_thought_pattern': \"I'm learning and growing from my mistakes, and that's part of being human.\",\n",
    "            'negative_thought_pattern': \"I always mess everything up and never do anything right.\",\n",
    "            'transition_thought_pattern': \"I made a mistake, but I can learn from this experience.\"\n",
    "        },\n",
    "        {\n",
    "            'cognitive_pattern_name': 'Anxiety Response',\n",
    "            'positive_thought_pattern': \"I can handle challenging situations by taking things one step at a time.\",\n",
    "            'negative_thought_pattern': \"Everything is going to go wrong and I won't be able to cope.\",\n",
    "            'transition_thought_pattern': \"I'm feeling anxious, but I can use coping strategies to manage this.\"\n",
    "        }\n",
    "    ]\n",
    "    pattern_types = {'Negative Self-Evaluation': [0], 'Anxiety Response': [1]}\n",
    "    print(f\"‚úì Using {len(patterns)} manual patterns for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Basic SelfIE Interpretation\n",
    "\n",
    "Let's start with a simple experiment to interpret internal representations of cognitive patterns using SelfIE.\n",
    "\n",
    "### What this experiment does:\n",
    "- **Input**: We provide a cognitive pattern text (positive or negative thought)\n",
    "- **Extraction**: SelfIE extracts internal representations from specific layers and token positions\n",
    "- **Interpretation**: The model describes what these representations mean in natural language\n",
    "- **Analysis**: We examine the interpretations to understand how the model processes different cognitive patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 1: Basic SelfIE Interpretation\n",
    "\n",
    "# ===== CONFIGURATION SECTION =====\n",
    "PATTERN_INDEX = 0  # Which pattern to analyze\n",
    "TEXT_TYPE = \"negative_thought_pattern\"  # \"positive_thought_pattern\", \"negative_thought_pattern\", \"transition_thought_pattern\"\n",
    "INTERPRETATION_TEMPLATE = \"cognitive_pattern\"  # Template for interpretation\n",
    "LAYERS_TO_INTERPRET = [-1, -2, -3]  # Which layers to extract representations from (negative = from end)\n",
    "TOKEN_STRATEGY = TokenSelectionStrategy.LAST_TOKEN  # How to select tokens\n",
    "MAX_INTERPRETATION_TOKENS = 40  # Max tokens for interpretation\n",
    "BATCH_SIZE = 2\n",
    "# ====================================\n",
    "\n",
    "# Get the pattern to analyze\n",
    "if PATTERN_INDEX < len(patterns):\n",
    "    selected_pattern = patterns[PATTERN_INDEX]\n",
    "    input_text = selected_pattern[TEXT_TYPE]\n",
    "    pattern_name = selected_pattern['cognitive_pattern_name']\n",
    "else:\n",
    "    print(\"‚ùå Pattern index out of range\")\n",
    "    input_text = \"I feel overwhelmed and don't know how to handle this situation.\"\n",
    "    pattern_name = \"Sample Pattern\"\n",
    "\n",
    "print(f\"\\nüß† EXPERIMENT 1: SelfIE Interpretation\")\n",
    "print(f\"Pattern: {pattern_name}\")\n",
    "print(f\"Text type: {TEXT_TYPE}\")\n",
    "print(f\"Input text: {input_text}\")\n",
    "print(f\"Layers to interpret: {LAYERS_TO_INTERPRET}\")\n",
    "print(f\"Token strategy: {TOKEN_STRATEGY.value}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Perform SelfIE interpretation\n",
    "    interpretation_results = selfie_patcher.interpret_text(\n",
    "        text=input_text,\n",
    "        layers_to_interpret=LAYERS_TO_INTERPRET,\n",
    "        interpretation_template=INTERPRETATION_TEMPLATE,\n",
    "        max_new_tokens=MAX_INTERPRETATION_TOKENS,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéä EXPERIMENT 1 RESULTS:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Display results in a readable format\n",
    "    for idx, row in interpretation_results.iterrows():\n",
    "        print(f\"\\nüìç Layer {row['layer']}, Token {row['token']} ('{row['token_decoded']}'):\")\n",
    "        print(f\"   Interpretation: {row['interpretation'].strip()}\")\n",
    "    \n",
    "    print(\"\\nüìä Full Results DataFrame:\")\n",
    "    display(interpretation_results[['layer', 'token', 'token_decoded', 'interpretation']])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in SelfIE interpretation: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(\"1. Check that the model is properly loaded\")\n",
    "    print(\"2. Verify the model is LLaMA-compatible\")\n",
    "    print(\"3. Ensure sufficient GPU memory\")\n",
    "    print(\"4. Try reducing batch_size or max_new_tokens\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Comparing Positive vs Negative Patterns\n",
    "\n",
    "Let's compare how the model interprets positive versus negative cognitive patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 2: Positive vs Negative Pattern Comparison\n",
    "\n",
    "# ===== CONFIGURATION SECTION =====\n",
    "COMPARISON_PATTERN_INDEX = 0\n",
    "COMPARISON_LAYER = -1  # Focus on final layer\n",
    "COMPARISON_STRATEGY = TokenSelectionStrategy.LAST_TOKEN\n",
    "COMPARISON_TEMPLATE = \"psychological_state\"\n",
    "COMPARISON_MAX_TOKENS = 30\n",
    "# ====================================\n",
    "\n",
    "if COMPARISON_PATTERN_INDEX < len(patterns):\n",
    "    selected_pattern = patterns[COMPARISON_PATTERN_INDEX]\n",
    "    \n",
    "    positive_text = selected_pattern['positive_thought_pattern']\n",
    "    negative_text = selected_pattern['negative_thought_pattern']\n",
    "    pattern_name = selected_pattern['cognitive_pattern_name']\n",
    "    \n",
    "    print(f\"\\nüîÑ EXPERIMENT 2: Positive vs Negative Comparison\")\n",
    "    print(f\"Pattern: {pattern_name}\")\n",
    "    print(f\"Layer: {COMPARISON_LAYER}\")\n",
    "    print(f\"Strategy: {COMPARISON_STRATEGY.value}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Interpret positive pattern\n",
    "        print(\"\\n‚úÖ Analyzing POSITIVE pattern...\")\n",
    "        print(f\"Text: {positive_text}\")\n",
    "        \n",
    "        positive_results = selfie_patcher.interpret_text(\n",
    "            text=positive_text,\n",
    "            layers_to_interpret=[COMPARISON_LAYER],\n",
    "            interpretation_template=COMPARISON_TEMPLATE,\n",
    "            max_new_tokens=COMPARISON_MAX_TOKENS,\n",
    "            batch_size=1\n",
    "        )\n",
    "        \n",
    "        # Interpret negative pattern\n",
    "        print(\"\\n‚ùå Analyzing NEGATIVE pattern...\")\n",
    "        print(f\"Text: {negative_text}\")\n",
    "        \n",
    "        negative_results = selfie_patcher.interpret_text(\n",
    "            text=negative_text,\n",
    "            layers_to_interpret=[COMPARISON_LAYER],\n",
    "            interpretation_template=COMPARISON_TEMPLATE,\n",
    "            max_new_tokens=COMPARISON_MAX_TOKENS,\n",
    "            batch_size=1\n",
    "        )\n",
    "        \n",
    "        print(\"\\nüéä EXPERIMENT 2 RESULTS:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(\"\\n‚úÖ POSITIVE INTERPRETATION:\")\n",
    "        for idx, row in positive_results.iterrows():\n",
    "            print(f\"   {row['interpretation'].strip()}\")\n",
    "        \n",
    "        print(\"\\n‚ùå NEGATIVE INTERPRETATION:\")\n",
    "        for idx, row in negative_results.iterrows():\n",
    "            print(f\"   {row['interpretation'].strip()}\")\n",
    "        \n",
    "        # Store results for further analysis\n",
    "        comparison_results = {\n",
    "            'positive': positive_results,\n",
    "            'negative': negative_results,\n",
    "            'pattern_name': pattern_name\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in comparison experiment: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Pattern index out of range for comparison\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Multi-Layer Analysis\n",
    "\n",
    "Analyze how interpretations change across different layers of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 3: Multi-Layer Analysis\n",
    "\n",
    "# ===== CONFIGURATION SECTION =====\n",
    "MULTILAYER_TEXT = \"I keep telling myself I'm not good enough and will never succeed.\"\n",
    "MULTILAYER_LAYERS = [-5, -3, -1]  # Early, middle, and final layers\n",
    "MULTILAYER_TEMPLATE = \"cognitive_pattern\"\n",
    "MULTILAYER_STRATEGY = TokenSelectionStrategy.KEYWORDS\n",
    "MULTILAYER_MAX_TOKENS = 35\n",
    "# ====================================\n",
    "\n",
    "print(f\"\\nüß≠ EXPERIMENT 3: Multi-Layer Analysis\")\n",
    "print(f\"Text: {MULTILAYER_TEXT}\")\n",
    "print(f\"Analyzing layers: {MULTILAYER_LAYERS}\")\n",
    "print(f\"Token strategy: {MULTILAYER_STRATEGY.value}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Analyze across multiple layers\n",
    "    multilayer_results = selfie_patcher.interpret_text(\n",
    "        text=MULTILAYER_TEXT,\n",
    "        layers_to_interpret=MULTILAYER_LAYERS,\n",
    "        interpretation_template=MULTILAYER_TEMPLATE,\n",
    "        max_new_tokens=MULTILAYER_MAX_TOKENS,\n",
    "        batch_size=2\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéä EXPERIMENT 3 RESULTS:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Group results by layer\n",
    "    for layer in MULTILAYER_LAYERS:\n",
    "        layer_results = multilayer_results[multilayer_results['layer'] == layer]\n",
    "        print(f\"\\nüèóÔ∏è LAYER {layer}:\")\n",
    "        for idx, row in layer_results.iterrows():\n",
    "            print(f\"   Token '{row['token_decoded']}' ‚Üí {row['interpretation'].strip()}\")\n",
    "    \n",
    "    # Display summary table\n",
    "    print(\"\\nüìä Summary Table:\")\n",
    "    display(multilayer_results[['layer', 'token_decoded', 'interpretation']])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in multi-layer analysis: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Different Interpretation Templates\n",
    "\n",
    "Test how different interpretation templates affect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 4: Template Comparison\n",
    "\n",
    "# ===== CONFIGURATION SECTION =====\n",
    "TEMPLATE_TEST_TEXT = \"I'm overwhelmed by everything I need to do and feel like giving up.\"\n",
    "TEMPLATES_TO_TEST = [\n",
    "    'cognitive_pattern',\n",
    "    'emotional_state', \n",
    "    'psychological_state',\n",
    "    'decision_making'\n",
    "]\n",
    "TEMPLATE_LAYER = -1\n",
    "TEMPLATE_STRATEGY = TokenSelectionStrategy.LAST_COUPLE\n",
    "TEMPLATE_MAX_TOKENS = 25\n",
    "# ====================================\n",
    "\n",
    "print(f\"\\nüé≠ EXPERIMENT 4: Template Comparison\")\n",
    "print(f\"Text: {TEMPLATE_TEST_TEXT}\")\n",
    "print(f\"Templates to test: {TEMPLATES_TO_TEST}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "template_comparison = {}\n",
    "\n",
    "for template in TEMPLATES_TO_TEST:\n",
    "    print(f\"\\nüîç Testing template: {template}\")\n",
    "    \n",
    "    try:\n",
    "        results = selfie_patcher.interpret_text(\n",
    "            text=TEMPLATE_TEST_TEXT,\n",
    "            layers_to_interpret=[TEMPLATE_LAYER],\n",
    "            interpretation_template=template,\n",
    "            max_new_tokens=TEMPLATE_MAX_TOKENS,\n",
    "            batch_size=1\n",
    "        )\n",
    "        \n",
    "        template_comparison[template] = results\n",
    "        \n",
    "        # Show first interpretation\n",
    "        if not results.empty:\n",
    "            first_interpretation = results.iloc[0]['interpretation'].strip()\n",
    "            print(f\"   ‚Üí {first_interpretation}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error with template {template}: {e}\")\n",
    "        template_comparison[template] = None\n",
    "\n",
    "print(\"\\nüéä EXPERIMENT 4 RESULTS SUMMARY:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for template, results in template_comparison.items():\n",
    "    print(f\"\\nüé≠ {template.upper()}:\")\n",
    "    if results is not None and not results.empty:\n",
    "        for idx, row in results.iterrows():\n",
    "            print(f\"   {row['interpretation'].strip()}\")\n",
    "    else:\n",
    "        print(\"   No results or error occurred\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features (Placeholders)\n",
    "\n",
    "The following cells demonstrate the interface for advanced SelfIE features that are planned for future implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Supervised Control\n",
    "# This would implement the supervised control technique from the SelfIE paper\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Supervised Control\")\n",
    "print(\"This feature would allow editing concepts in the model's hidden representations.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"selfie_patcher.supervised_control('reduce_negative_self_talk', control_strength=0.8)\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     result = selfie_patcher.supervised_control(\n",
    "#         target_concept=\"reduce_negative_self_talk\",\n",
    "#         control_strength=0.8\n",
    "#     )\n",
    "#     print(f\"‚úì Applied supervised control: {result}\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Reinforcement Control\n",
    "# This would implement RLHF on hidden embeddings to erase harmful knowledge\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Reinforcement Control\")\n",
    "print(\"This feature would use reinforcement learning to remove harmful concepts.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"selfie_patcher.reinforcement_control(['self_harm', 'suicidal_ideation'])\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     result = selfie_patcher.reinforcement_control([\n",
    "#         'self_harm_thoughts', \n",
    "#         'suicidal_ideation',\n",
    "#         'extreme_negative_self_evaluation'\n",
    "#     ])\n",
    "#     print(f\"‚úì Applied reinforcement control: {result}\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Batch Processing\n",
    "# This would efficiently process multiple cognitive patterns\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Batch Pattern Processing\")\n",
    "print(\"This feature would process multiple cognitive patterns efficiently.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"results = selfie_patcher.batch_interpret_patterns(patterns, batch_size=8)\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     batch_results = selfie_patcher.batch_interpret_patterns(\n",
    "#         patterns=patterns[:5],  # First 5 patterns\n",
    "#         batch_size=4\n",
    "#     )\n",
    "#     print(f\"‚úì Processed {len(batch_results)} patterns\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Visualization\n",
    "# This would create visualizations of interpretation results\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Interpretation Visualization\")\n",
    "print(\"This feature would create interactive visualizations of results.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"selfie_patcher.visualize_interpretations(interpretation_results)\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     if 'interpretation_results' in locals():\n",
    "#         viz = selfie_patcher.visualize_interpretations(interpretation_results)\n",
    "#         print(\"‚úì Created visualization\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: Export Functionality  \n",
    "# This would export results in various formats\n",
    "\n",
    "print(\"üöß PLACEHOLDER: Export Functionality\")\n",
    "print(\"This feature would export interpretation results to various formats.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"selfie_patcher.export_interpretations(results, format='json')\")\n",
    "print(\"selfie_patcher.export_interpretations(results, format='csv')\")\n",
    "print(\"selfie_patcher.export_interpretations(results, format='html')\")\n",
    "\n",
    "# Uncomment when implemented:\n",
    "# try:\n",
    "#     if 'interpretation_results' in locals():\n",
    "#         export_path = selfie_patcher.export_interpretations(\n",
    "#             interpretation_results, \n",
    "#             format='json'\n",
    "#         )\n",
    "#         print(f\"‚úì Exported results to: {export_path}\")\n",
    "# except NotImplementedError:\n",
    "#     print(\"‚ö†Ô∏è  Feature not yet implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for the notebook\n",
    "\n",
    "def reset_environment():\n",
    "    \"\"\"Reset the SelfIE environment\"\"\"\n",
    "    selfie_patcher.reset_hooks()  # No-op for SelfIE but maintains compatibility\n",
    "    print(\"üîÑ Environment reset\")\n",
    "\n",
    "def show_model_info():\n",
    "    \"\"\"Display current model information\"\"\"\n",
    "    selfie_patcher.check_model_info()\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU memory\"\"\"\n",
    "    SelfIEPatcher.clear_memory()\n",
    "\n",
    "print(\"Utility functions loaded:\")\n",
    "print(\"- reset_environment() - Reset the environment\")\n",
    "print(\"- show_model_info() - Display model information\")\n",
    "print(\"- clear_memory() - Clear GPU memory\")\n",
    "\n",
    "# Uncomment any line below to run:\n",
    "# reset_environment()\n",
    "# show_model_info()\n",
    "# clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook provides a foundation for using SelfIE to interpret cognitive patterns. The key advantages over activation patching:\n",
    "\n",
    "1. **Interpretability**: Direct natural language descriptions of internal representations\n",
    "2. **No Modification**: Analyzes the model without changing its behavior\n",
    "3. **Flexibility**: Can interpret any concept the model understands\n",
    "\n",
    "### To fully implement:\n",
    "1. Set up the environment with transformers==4.34.0\n",
    "2. Install the SelfIE library from the third_party directory\n",
    "3. Use a LLaMA-compatible model\n",
    "4. Implement the advanced features marked as placeholders\n",
    "5. Add dataset integration for seamless cognitive pattern analysis\n",
    "\n",
    "### Future enhancements:\n",
    "- Supervised control for editing cognitive patterns\n",
    "- Reinforcement learning for removing harmful patterns\n",
    "- Interactive visualization of interpretations\n",
    "- Batch processing for large-scale analysis\n",
    "- Export capabilities for research and clinical use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
