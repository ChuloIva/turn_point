{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test and Activation Capture with NNsight\n",
    "\n",
    "This notebook downloads Mistral-7B-Instruct, saves it locally, and demonstrates proper residual stream activation capture using NNsight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ torch already installed\n",
      "✓ transformers already installed\n",
      "✓ numpy already installed\n",
      "✓ tqdm already installed\n",
      "✓ nnsight already installed\n",
      "Installing python-dotenv...\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.13/site-packages (1.1.1)\n",
      "\n",
      "✓ All dependencies installed\n"
     ]
    }
   ],
   "source": [
    "# 1. Install dependencies\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package.split('==')[0])\n",
    "        print(f\"✓ {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "packages = [\"torch\", \"transformers\", \"numpy\", \"tqdm\", \"nnsight\", \"python-dotenv\"]\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\n✓ All dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using Apple Silicon MPS\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# 2. Import libraries and setup device\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from nnsight import LanguageModel\n",
    "from typing import Dict, List, Optional\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check device capabilities\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"✓ Using Apple Silicon MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"✓ Using CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚠️ Using CPU (will be slow)\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: ./model\n"
     ]
    }
   ],
   "source": [
    "# 3. Model configuration and directory setup\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "model_dir = \"./model\"\n",
    "\n",
    "# Create model directory\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "print(f\"Model directory: {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer...\n",
      "✓ Tokenizer saved to ./model/tokenizer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 4. Download and save tokenizer\n",
    "print(\"Downloading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = 0\n",
    "\n",
    "# Save tokenizer locally\n",
    "tokenizer_dir = os.path.join(model_dir, \"tokenizer\")\n",
    "tokenizer.save_pretrained(tokenizer_dir)\n",
    "print(f\"✓ Tokenizer saved to {tokenizer_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model (this may take several minutes)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d31007086242a6aedcb9fe4b8f9a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Download and save model\n",
    "print(\"Downloading model (this may take several minutes)...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\" if device.type != \"mps\" else None\n",
    ")\n",
    "\n",
    "# Move to device if using MPS\n",
    "if device.type == \"mps\":\n",
    "    model = model.to(device)\n",
    "\n",
    "# Save model locally\n",
    "model_dir_path = os.path.join(model_dir, \"model\")\n",
    "model.save_pretrained(model_dir_path)\n",
    "print(f\"✓ Model saved to {model_dir_path}\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing basic inference...\n",
      "Input prompt: [INST] Hello, how are you today? [/INST]\n",
      "Input shape: torch.Size([1, 15])\n",
      "Input tokens: [1, 733, 16289, 28793, 22557, 28725, 910, 460, 368, 3154]...\n",
      "\n",
      "Generated response: I'm an AI language model, so I don't have feelings or physical sensations. But thank you for asking! How can I help you today?\n",
      "Full generation shape: torch.Size([1, 49])\n",
      "✅ Basic inference working!\n"
     ]
    }
   ],
   "source": [
    "# 6. Test basic inference\n",
    "print(\"Testing basic inference...\")\n",
    "\n",
    "test_prompt = \"[INST] Hello, how are you today? [/INST]\"\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "print(f\"Input prompt: {test_prompt}\")\n",
    "print(f\"Input shape: {inputs.input_ids.shape}\")\n",
    "print(f\"Input tokens: {inputs.input_ids[0].tolist()[:10]}...\")  # Show first 10 tokens\n",
    "\n",
    "# Generate response\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=50,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # Decode response\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response_only = generated_text[len(test_prompt):].strip()\n",
    "\n",
    "    print(f\"\\nGenerated response: {response_only}\")\n",
    "    print(f\"Full generation shape: {outputs.shape}\")\n",
    "    print(\"✅ Basic inference working!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Inference error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model with NNsight for activation capture...\n",
      "✓ Loaded model with NNsight\n",
      "NNsight model device: meta\n",
      "Total layers: 32\n"
     ]
    }
   ],
   "source": [
    "# 7. Load model with NNsight\n",
    "print(\"Loading model with NNsight for activation capture...\")\n",
    "\n",
    "# Load from HuggingFace (local loading has tokenizer issues)\n",
    "nnsight_model = LanguageModel(model_name, torch_dtype=torch.float16)\n",
    "print(\"✓ Loaded model with NNsight\")\n",
    "print(f\"NNsight model device: {nnsight_model.device}\")\n",
    "print(f\"Total layers: {len(nnsight_model.model.layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fixed activation capture functions with dynamic tensor dimension handling\n"
     ]
    }
   ],
   "source": [
    "# 8. Define activation capture functions\n",
    "def capture_residual_activations(\n",
    "    model: LanguageModel,\n",
    "    prompt: str,\n",
    "    layer_idx: int,\n",
    "    token_position: int = -1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Capture residual stream activations from a specific layer.\n",
    "    \n",
    "    Args:\n",
    "        model: NNsight LanguageModel\n",
    "        prompt: Raw text prompt (nnsight handles tokenization)\n",
    "        layer_idx: Which transformer layer to capture from (0-indexed)\n",
    "        token_position: Which token position to capture (-1 for last)\n",
    "    \n",
    "    Returns:\n",
    "        Activation tensor from the residual stream\n",
    "    \"\"\"\n",
    "    with model.trace(prompt) as tracer:\n",
    "        # IMPORTANT: layer.output returns a tuple of length two:\n",
    "        # - [0] = positional arguments (the actual hidden states tensor)\n",
    "        # - [1] = keyword arguments\n",
    "        # This is a recent change in nnsight to fix output access issues\n",
    "        \n",
    "        # Get the hidden states tensor (first element of output tuple)\n",
    "        hidden_states = model.model.layers[layer_idx].output[0]\n",
    "        \n",
    "        # Debug: Check the actual shape of hidden_states\n",
    "        print(f\"Debug: hidden_states shape = {hidden_states.shape}\")\n",
    "        \n",
    "        # Handle different tensor dimensions\n",
    "        if len(hidden_states.shape) == 3:\n",
    "            # Standard 3D case: [batch_size, seq_len, hidden_dim]\n",
    "            if token_position == -1:\n",
    "                activation = hidden_states[:, -1, :].save()\n",
    "            else:\n",
    "                activation = hidden_states[:, token_position, :].save()\n",
    "        elif len(hidden_states.shape) == 2:\n",
    "            # 2D case: [seq_len, hidden_dim] - batch size of 1 was squeezed\n",
    "            if token_position == -1:\n",
    "                activation = hidden_states[-1, :].save()\n",
    "            else:\n",
    "                activation = hidden_states[token_position, :].save()\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected hidden_states shape: {hidden_states.shape}\")\n",
    "    \n",
    "    return activation\n",
    "\n",
    "def test_activation_capture(\n",
    "    model: LanguageModel,\n",
    "    prompt: str,\n",
    "    test_layers: List[int] = None\n",
    ") -> Dict[int, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Test activation capture from multiple layers.\n",
    "    \"\"\"\n",
    "    if test_layers is None:\n",
    "        total_layers = len(model.model.layers)\n",
    "        test_layers = [0, total_layers//4, total_layers//2, 3*total_layers//4, total_layers-1]\n",
    "    \n",
    "    print(f\"Testing activation capture from layers: {test_layers}\")\n",
    "    print(f\"Prompt: '{prompt}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    activations = {}\n",
    "    \n",
    "    for layer_idx in test_layers:\n",
    "        try:\n",
    "            activation = capture_residual_activations(\n",
    "                model, prompt, layer_idx, token_position=-1\n",
    "            )\n",
    "            activations[layer_idx] = activation\n",
    "            \n",
    "            # Print activation info\n",
    "            magnitude = torch.norm(activation).item()\n",
    "            mean_val = torch.mean(activation).item()\n",
    "            std_val = torch.std(activation).item()\n",
    "            print(f\"✅ Layer {layer_idx:2d}: shape={activation.shape}, \"\n",
    "                  f\"magnitude={magnitude:.4f}, mean={mean_val:.4f}, std={std_val:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to capture layer {layer_idx}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    return activations\n",
    "\n",
    "def debug_layer_structure(\n",
    "    model: LanguageModel,\n",
    "    prompt: str,\n",
    "    layer_idx: int = 0\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Debug function to understand layer output structure.\n",
    "    \"\"\"\n",
    "    print(f\"Debugging layer {layer_idx} structure...\")\n",
    "    \n",
    "    # Initialize variables OUTSIDE the trace context\n",
    "    output_tuple = None\n",
    "    pos_args = None\n",
    "    kw_args = None\n",
    "    \n",
    "    with model.trace(prompt) as tracer:\n",
    "        layer = model.model.layers[layer_idx]\n",
    "        \n",
    "        # The output is a tuple: (positional_args, keyword_args)\n",
    "        output_tuple = layer.output.save()\n",
    "        \n",
    "        # Access the positional args (hidden states)\n",
    "        pos_args = layer.output[0].save()\n",
    "        \n",
    "        # Try to access keyword args (may not exist for all layers)\n",
    "        try:\n",
    "            kw_args = layer.output[1].save()\n",
    "            print(\"✅ Successfully accessed keyword args\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ No keyword args available: {e}\")\n",
    "            kw_args = None\n",
    "        \n",
    "    # Print information about the structures (outside trace context)\n",
    "    print(f\"\\nLayer output analysis:\")\n",
    "    print(f\"Full output type: {type(output_tuple)}\")\n",
    "    \n",
    "    if hasattr(output_tuple, '__len__'):\n",
    "        try:\n",
    "            print(f\"Output tuple length: {len(output_tuple)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not determine output tuple length: {e}\")\n",
    "    \n",
    "    print(f\"Positional args [0]: type={type(pos_args)}, shape={getattr(pos_args, 'shape', 'No shape')}\")\n",
    "    \n",
    "    if kw_args is not None:\n",
    "        print(f\"Keyword args [1]: type={type(kw_args)}\")\n",
    "    else:\n",
    "        print(\"Keyword args [1]: None\")\n",
    "\n",
    "print(\"✓ Fixed activation capture functions with dynamic tensor dimension handling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing activation capture with corrected tuple structure...\n",
      "======================================================================\n",
      "🔍 Debugging layer structure first...\n",
      "Debugging layer 0 structure...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037133b6fe7c4fb997af821cb7e4713f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ No keyword args available: index 1 is out of bounds for dimension 0 with size 1\n",
      "\n",
      "Layer output analysis:\n",
      "Full output type: <class 'torch.Tensor'>\n",
      "Output tuple length: 1\n",
      "Positional args [0]: type=<class 'torch.Tensor'>, shape=torch.Size([15, 4096])\n",
      "Keyword args [1]: None\n",
      "\n",
      "========================================\n",
      "\n",
      "Testing activation capture from layers: [0, 8, 16, 24, 31]\n",
      "Prompt: '[INST] What is the capital of France? [/INST]'\n",
      "------------------------------------------------------------\n",
      "Debug: hidden_states shape = torch.Size([15, 4096])\n",
      "✅ Layer  0: shape=torch.Size([4096]), magnitude=0.3250, mean=-0.0001, std=0.0051\n",
      "Debug: hidden_states shape = torch.Size([15, 4096])\n",
      "✅ Layer  8: shape=torch.Size([4096]), magnitude=3.7188, mean=-0.0006, std=0.0581\n",
      "Debug: hidden_states shape = torch.Size([15, 4096])\n",
      "✅ Layer 16: shape=torch.Size([4096]), magnitude=10.6875, mean=-0.0023, std=0.1670\n",
      "Debug: hidden_states shape = torch.Size([15, 4096])\n",
      "✅ Layer 24: shape=torch.Size([4096]), magnitude=24.6719, mean=0.0040, std=0.3855\n",
      "Debug: hidden_states shape = torch.Size([15, 4096])\n",
      "✅ Layer 31: shape=torch.Size([4096]), magnitude=41.4062, mean=0.0090, std=0.6470\n",
      "\n",
      "🎉 SUCCESS! Captured activations from 5 layers\n",
      "\n",
      "Activation Summary:\n",
      "--------------------------------------------------\n",
      "Total activation parameters captured: 20,480\n",
      "\n",
      "Testing different token positions on layer 16...\n",
      "Debug: hidden_states shape = torch.Size([15, 4096])\n",
      "  Position -1: shape=torch.Size([4096]), magnitude=10.6875, mean=-0.0023\n",
      "Debug: hidden_states shape = torch.Size([15, 4096])\n",
      "  Position  0: shape=torch.Size([4096]), magnitude=252.1250, mean=-0.0668\n",
      "Debug: hidden_states shape = torch.Size([15, 4096])\n",
      "  Position  5: shape=torch.Size([4096]), magnitude=10.3750, mean=-0.0011\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 9. Test activation capture with proper tuple structure\n",
    "print(\"Testing activation capture with corrected tuple structure...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_prompt = \"[INST] What is the capital of France? [/INST]\"\n",
    "\n",
    "try:\n",
    "    # First, debug the layer structure to confirm our understanding\n",
    "    print(\"🔍 Debugging layer structure first...\")\n",
    "    debug_layer_structure(nnsight_model, test_prompt, layer_idx=0)\n",
    "    print(\"\\n\" + \"=\" * 40 + \"\\n\")\n",
    "    \n",
    "    # Test activation capture from sample layers\n",
    "    captured_activations = test_activation_capture(nnsight_model, test_prompt)\n",
    "\n",
    "    if captured_activations:\n",
    "        print(f\"\\n🎉 SUCCESS! Captured activations from {len(captured_activations)} layers\")\n",
    "        print(\"\\nActivation Summary:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        total_params = sum(torch.numel(act) for act in captured_activations.values())\n",
    "        print(f\"Total activation parameters captured: {total_params:,}\")\n",
    "        \n",
    "        # Test different token positions on middle layer\n",
    "        middle_layer = len(nnsight_model.model.layers) // 2\n",
    "        if middle_layer in captured_activations:\n",
    "            print(f\"\\nTesting different token positions on layer {middle_layer}...\")\n",
    "            for pos in [-1, 0, 5]:  # last, first, middle\n",
    "                try:\n",
    "                    activation = capture_residual_activations(\n",
    "                        nnsight_model, test_prompt, middle_layer, token_position=pos\n",
    "                    )\n",
    "                    magnitude = torch.norm(activation).item()\n",
    "                    mean_val = torch.mean(activation).item()\n",
    "                    print(f\"  Position {pos:2d}: shape={activation.shape}, magnitude={magnitude:.4f}, mean={mean_val:.4f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Position {pos:2d}: ❌ Error: {e}\")\n",
    "    else:\n",
    "        print(\"❌ No activations captured\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during activation capture: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: tensor([-0.0003, -0.0024,  0.0074,  ...,  0.0048, -0.0008,  0.0100],\n",
      "       dtype=torch.float16, grad_fn=<SliceBackward0>), 8: tensor([-0.0224, -0.0137, -0.0555,  ..., -0.0221,  0.0429,  0.0952],\n",
      "       dtype=torch.float16, grad_fn=<SliceBackward0>), 16: tensor([-0.2195, -0.4102, -0.1387,  ..., -0.1802, -0.3159, -0.0692],\n",
      "       dtype=torch.float16, grad_fn=<SliceBackward0>), 24: tensor([-0.1135, -0.1949, -0.7153,  ..., -0.5386,  0.4922, -1.0566],\n",
      "       dtype=torch.float16, grad_fn=<SliceBackward0>), 31: tensor([ 0.0294,  0.0435, -0.7559,  ..., -0.5977,  0.6938, -0.9199],\n",
      "       dtype=torch.float16, grad_fn=<SliceBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "print(captured_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running final working example...\n",
      "Debug: hidden_states shape = torch.Size([13, 4096])\n",
      "✅ SUCCESS: Captured activation from layer 16\n",
      "   Shape: torch.Size([4096])\n",
      "   Magnitude: 9.6250\n",
      "   Data type: torch.float16\n",
      "   Device: cpu\n",
      "\n",
      "Testing with different prompts...\n",
      "Debug: hidden_states shape = torch.Size([11, 4096])\n",
      "  '[INST] Hello world! ...': magnitude=10.5469\n",
      "Debug: hidden_states shape = torch.Size([15, 4096])\n",
      "  '[INST] What is 2+2? ...': magnitude=11.3672\n",
      "\n",
      "==================================================\n",
      "🎉 Activation capture is now working correctly!\n",
      "   Ready for SAE training and other experiments.\n"
     ]
    }
   ],
   "source": [
    "# 10. Final working example\n",
    "print(\"Running final working example...\")\n",
    "\n",
    "# Simple single-layer activation capture\n",
    "try:\n",
    "    activation = capture_residual_activations(\n",
    "        nnsight_model, \n",
    "        \"[INST] The capital of France is [/INST]\", \n",
    "        layer_idx=16, \n",
    "        token_position=-1\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ SUCCESS: Captured activation from layer 16\")\n",
    "    print(f\"   Shape: {activation.shape}\")\n",
    "    print(f\"   Magnitude: {torch.norm(activation).item():.4f}\")\n",
    "    print(f\"   Data type: {activation.dtype}\")\n",
    "    print(f\"   Device: {activation.device}\")\n",
    "    \n",
    "    # Test with different prompts to verify consistency\n",
    "    print(f\"\\nTesting with different prompts...\")\n",
    "    for prompt in [\"[INST] Hello world! [/INST]\", \"[INST] What is 2+2? [/INST]\"]:\n",
    "        act = capture_residual_activations(nnsight_model, prompt, 16, -1)\n",
    "        mag = torch.norm(act).item()\n",
    "        print(f\"  '{prompt[:20]}...': magnitude={mag:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🎉 Activation capture is now working correctly!\")\n",
    "print(\"   Ready for SAE training and other experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1765, -0.0891, -0.1075,  ...,  0.0314, -0.3169,  0.0094],\n",
      "       dtype=torch.float16, grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎯 Summary\n",
    "\n",
    "## What This Notebook Accomplishes:\n",
    "\n",
    "1. ✅ **Downloads and saves** Mistral-7B-Instruct locally\n",
    "2. ✅ **Tests basic inference** to verify model functionality \n",
    "3. ✅ **Loads model with NNsight** for activation capture\n",
    "4. ✅ **Captures residual stream activations** from any layer and token position\n",
    "5. ✅ **Validates activation capture** across multiple layers and prompts\n",
    "\n",
    "## Key Function:\n",
    "\n",
    "```python\n",
    "# Capture activation from layer 16, last token\n",
    "activation = capture_residual_activations(\n",
    "    nnsight_model, \n",
    "    \"[INST] Your prompt here [/INST]\", \n",
    "    layer_idx=16, \n",
    "    token_position=-1\n",
    ")\n",
    "```\n",
    "\n",
    "## Ready for Advanced Experiments:\n",
    "\n",
    "- **Sparse Autoencoders (SAE)** training on residual stream\n",
    "- **Activation patching** experiments  \n",
    "- **Feature visualization** and analysis\n",
    "- **Intervention studies** on model behavior\n",
    "- **Mechanistic interpretability** research\n",
    "\n",
    "The activation capture now works reliably and can be used as a foundation for interpretability research."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
