{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Arithmetic Lab üßÆ\n",
    "**Compact notebook for vector arithmetic experiments. Each experiment is self-contained with its own config.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR AMD GPU\n",
    "import os\n",
    "os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = \"11.0.0\"\n",
    "os.environ[\"HIP_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"AMD_SERIALIZE_KERNEL\"] = \"3\"\n",
    "os.environ[\"TORCH_USE_HIP_DSA\"] = \"1\"\n",
    "\n",
    "\n",
    "\n",
    "# SETUP\n",
    "import sys, warnings, torch, numpy as np\n",
    "from typing import List, Dict, Any, Tuple\n",
    "sys.path.insert(0, '..')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from nnsight_selfie import ModelAgnosticSelfie, InterpretationPrompt, get_optimal_device\n",
    "\n",
    "# LOAD MODEL\n",
    "MODEL_NAME = \"google/gemma-3-4b-it\"  # Change as needed\n",
    "selfie = ModelAgnosticSelfie(MODEL_NAME, dtype=torch.bfloat16, load_in_8bit=False)\n",
    "print(f\"‚úÖ {MODEL_NAME} loaded on {selfie.device} ({len(selfie.layer_paths)} layers)\")\n",
    "\n",
    "# HELPER FUNCTIONS\n",
    "def show_tokens(text):\n",
    "    tokens = selfie.model.tokenizer.encode(text)\n",
    "    for i, token_id in enumerate(tokens):\n",
    "        token_str = selfie.model.tokenizer.decode([token_id])\n",
    "        print(f\"  {i:2d}: '{token_str.strip()}'\")\n",
    "    return tokens\n",
    "\n",
    "def get_vector(text, token_pos, layer):\n",
    "    \"\"\"Get activation vector for a specific token position and layer.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text (ALWAYS uses raw text - no chat template for activation capture!)\n",
    "        token_pos: Token position to extract from\n",
    "        layer: Layer index to extract from\n",
    "    \"\"\"\n",
    "    acts = selfie.get_activations(text, layer_indices=[layer], token_indices=[token_pos])\n",
    "    return acts[layer][0]\n",
    "\n",
    "def interpret_vector(vector, prompt, injection_layer=3, max_tokens=30, use_chat_template=False):\n",
    "    \"\"\"Interpret a vector using the selfie interpretation system.\n",
    "    \n",
    "    Args:\n",
    "        vector: Activation vector to interpret\n",
    "        prompt: InterpretationPrompt object\n",
    "        injection_layer: Layer to inject the vector at\n",
    "        max_tokens: Maximum tokens to generate\n",
    "        use_chat_template: Whether to apply chat template formatting to INTERPRETATION (not capture)\n",
    "    \"\"\"\n",
    "    return selfie.interpret_vectors([vector], prompt, injection_layer, max_new_tokens=max_tokens, \n",
    "                                  use_chat_template=use_chat_template)[0].strip()\n",
    "\n",
    "def experiment(base_text, base_pos, sub_text, sub_pos, add_text, add_pos, \n",
    "               extract_layer, inject_layer, interp_prompt, description=\"\", use_chat_template=False):\n",
    "    \"\"\"Run a vector arithmetic experiment.\n",
    "    \n",
    "    Args:\n",
    "        base_text, sub_text, add_text: Raw text for activation capture (no chat template applied)\n",
    "        base_pos, sub_pos, add_pos: Token positions in the RAW text\n",
    "        use_chat_template: Whether to use chat template for INTERPRETATION only\n",
    "    \"\"\"\n",
    "    print(f\"üßÆ {description}\")\n",
    "    print(f\"   Extract: L{extract_layer} | Inject: L{inject_layer}\")\n",
    "    if use_chat_template:\n",
    "        print(f\"   üìù Using chat template for interpretation\")\n",
    "    \n",
    "    # Always capture from raw text (no chat template) - token positions stay consistent\n",
    "    base_vec = get_vector(base_text, base_pos, extract_layer)\n",
    "    sub_vec = get_vector(sub_text, sub_pos, extract_layer) \n",
    "    add_vec = get_vector(add_text, add_pos, extract_layer)\n",
    "    \n",
    "    result_vec = base_vec - sub_vec + add_vec\n",
    "    # Apply chat template only to interpretation\n",
    "    interpretation = interpret_vector(result_vec, interp_prompt, inject_layer, use_chat_template=use_chat_template)\n",
    "    \n",
    "    print(f\"   ü§ñ {interpretation}\")\n",
    "    return result_vec, interpretation\n",
    "def get_multi_string_vectors(strings, token_positions, layer, aggregation=\"mean\"):\n",
    "    \"\"\"Extract and aggregate activation vectors from multiple strings.\n",
    "    \n",
    "    Args:\n",
    "        strings: List of strings to extract activations from\n",
    "        token_positions: List of token positions (one per string) OR single int for all strings\n",
    "        layer: Layer index to extract from\n",
    "        aggregation: How to combine vectors - \"mean\", \"sum\", or \"individual\"\n",
    "    \n",
    "    Returns:\n",
    "        If aggregation=\"individual\": List of vectors (one per string)\n",
    "        If aggregation=\"mean\"/\"sum\": Single aggregated vector\n",
    "    \"\"\"\n",
    "    if isinstance(token_positions, int):\n",
    "        token_positions = [token_positions] * len(strings)\n",
    "    \n",
    "    if len(token_positions) != len(strings):\n",
    "        raise ValueError(f\"Number of token positions ({len(token_positions)}) must match number of strings ({len(strings)})\")\n",
    "    \n",
    "    vectors = []\n",
    "    for text, pos in zip(strings, token_positions):\n",
    "        vector = get_vector(text, pos, layer)\n",
    "        vectors.append(vector)\n",
    "    \n",
    "    if aggregation == \"individual\":\n",
    "        return vectors\n",
    "    elif aggregation == \"mean\":\n",
    "        return torch.stack(vectors).mean(dim=0)\n",
    "    elif aggregation == \"sum\":\n",
    "        return torch.stack(vectors).sum(dim=0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown aggregation method: {aggregation}\")\n",
    "\n",
    "def multi_string_experiment(base_strings, base_positions, sub_strings, sub_positions, \n",
    "                           add_strings, add_positions, extract_layer, inject_layer, \n",
    "                           interp_prompt, description=\"\", aggregation=\"mean\", use_chat_template=False):\n",
    "    \"\"\"Run vector arithmetic experiment with multiple strings for each concept.\n",
    "    \n",
    "    Args:\n",
    "        base_strings, sub_strings, add_strings: Lists of strings for each concept\n",
    "        base_positions, sub_positions, add_positions: Token positions (list or single int)\n",
    "        aggregation: How to combine vectors from multiple strings (\"mean\", \"sum\")\n",
    "        Other args same as regular experiment()\n",
    "    \"\"\"\n",
    "    print(f\"üßÆ {description}\")\n",
    "    print(f\"   Extract: L{extract_layer} | Inject: L{inject_layer} | Aggregation: {aggregation}\")\n",
    "    print(f\"   Base strings: {len(base_strings)} | Sub strings: {len(sub_strings)} | Add strings: {len(add_strings)}\")\n",
    "    if use_chat_template:\n",
    "        print(f\"   üìù Using chat template for interpretation\")\n",
    "    \n",
    "    # Extract and aggregate vectors from multiple strings\n",
    "    base_vec = get_multi_string_vectors(base_strings, base_positions, extract_layer, aggregation)\n",
    "    sub_vec = get_multi_string_vectors(sub_strings, sub_positions, extract_layer, aggregation) \n",
    "    add_vec = get_multi_string_vectors(add_strings, add_positions, extract_layer, aggregation)\n",
    "    \n",
    "    result_vec = base_vec - sub_vec + add_vec\n",
    "    interpretation = interpret_vector(result_vec, interp_prompt, inject_layer, use_chat_template=use_chat_template)\n",
    "    \n",
    "    print(f\"   ü§ñ {interpretation}\")\n",
    "    return result_vec, interpretation\n",
    "\n",
    "# MULTI-STRING VECTOR EXTRACTION UTILITY\n",
    "def get_multi_string_vectors(strings, token_positions, layer, aggregation=\"mean\"):\n",
    "    \"\"\"Extract and aggregate activation vectors from multiple strings.\n",
    "    \n",
    "    Args:\n",
    "        strings: List of strings to extract activations from\n",
    "        token_positions: List of token positions (one per string) OR single int for all strings\n",
    "        layer: Layer index to extract from\n",
    "        aggregation: How to combine vectors - \"mean\", \"sum\", or \"individual\"\n",
    "    \n",
    "    Returns:\n",
    "        If aggregation=\"individual\": List of vectors (one per string)\n",
    "        If aggregation=\"mean\"/\"sum\": Single aggregated vector\n",
    "    \"\"\"\n",
    "    if isinstance(token_positions, int):\n",
    "        token_positions = [token_positions] * len(strings)\n",
    "    \n",
    "    if len(token_positions) != len(strings):\n",
    "        raise ValueError(f\"Number of token positions ({len(token_positions)}) must match number of strings ({len(strings)})\")\n",
    "    \n",
    "    vectors = []\n",
    "    for text, pos in zip(strings, token_positions):\n",
    "        vector = get_vector(text, pos, layer)\n",
    "        vectors.append(vector)\n",
    "    \n",
    "    if aggregation == \"individual\":\n",
    "        return vectors\n",
    "    elif aggregation == \"mean\":\n",
    "        return torch.stack(vectors).mean(dim=0)\n",
    "    elif aggregation == \"sum\":\n",
    "        return torch.stack(vectors).sum(dim=0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown aggregation method: {aggregation}\")\n",
    "\n",
    "def multi_string_experiment(base_strings, base_positions, sub_strings, sub_positions, \n",
    "                           add_strings, add_positions, extract_layer, inject_layer, \n",
    "                           interp_prompt, description=\"\", aggregation=\"mean\", use_chat_template=False):\n",
    "    \"\"\"Run vector arithmetic experiment with multiple strings for each concept.\n",
    "    \n",
    "    Args:\n",
    "        base_strings, sub_strings, add_strings: Lists of strings for each concept\n",
    "        base_positions, sub_positions, add_positions: Token positions (list or single int)\n",
    "        aggregation: How to combine vectors from multiple strings (\"mean\", \"sum\")\n",
    "        Other args same as regular experiment()\n",
    "    \"\"\"\n",
    "    print(f\"üßÆ {description}\")\n",
    "    print(f\"   Extract: L{extract_layer} | Inject: L{inject_layer} | Aggregation: {aggregation}\")\n",
    "    print(f\"   Base strings: {len(base_strings)} | Sub strings: {len(sub_strings)} | Add strings: {len(add_strings)}\")\n",
    "    if use_chat_template:\n",
    "        print(f\"   üìù Using chat template for interpretation\")\n",
    "    \n",
    "    # Extract and aggregate vectors from multiple strings\n",
    "    base_vec = get_multi_string_vectors(base_strings, base_positions, extract_layer, aggregation)\n",
    "    sub_vec = get_multi_string_vectors(sub_strings, sub_positions, extract_layer, aggregation) \n",
    "    add_vec = get_multi_string_vectors(add_strings, add_positions, extract_layer, aggregation)\n",
    "    \n",
    "    result_vec = base_vec - sub_vec + add_vec\n",
    "    interpretation = interpret_vector(result_vec, interp_prompt, inject_layer, use_chat_template=use_chat_template)\n",
    "    \n",
    "    print(f\"   ü§ñ {interpretation}\")\n",
    "    return result_vec, interpretation\n",
    "\n",
    "# VECTOR PROJECTION UTILITIES\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def vector_projection(vector_a, vector_b):\n",
    "    \"\"\"Project vector_a onto vector_b.\n",
    "    \n",
    "    Args:\n",
    "        vector_a: Vector to be projected\n",
    "        vector_b: Vector to project onto\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (projected_vector, projection_magnitude, cosine_similarity)\n",
    "    \"\"\"\n",
    "    # Flatten vectors to 1D if they're 2D\n",
    "    if vector_a.dim() > 1:\n",
    "        vector_a = vector_a.flatten()\n",
    "    if vector_b.dim() > 1:\n",
    "        vector_b = vector_b.flatten()\n",
    "    \n",
    "    # Normalize vector_b to get direction\n",
    "    b_normalized = F.normalize(vector_b.unsqueeze(0), dim=1).squeeze(0)\n",
    "    \n",
    "    # Compute projection magnitude (dot product with normalized b)\n",
    "    projection_magnitude = torch.dot(vector_a, b_normalized).item()\n",
    "    \n",
    "    # Compute projected vector\n",
    "    projected_vector = projection_magnitude * b_normalized\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = F.cosine_similarity(vector_a.unsqueeze(0), vector_b.unsqueeze(0)).item()\n",
    "    \n",
    "    return projected_vector, projection_magnitude, cosine_sim\n",
    "\n",
    "def project_concept_onto_direction(concept_text, concept_pos, direction_text, direction_pos, \n",
    "                                 layer, description=\"\"):\n",
    "    \"\"\"Project one concept vector onto another concept's direction.\n",
    "    \n",
    "    Args:\n",
    "        concept_text: Text containing concept to project\n",
    "        concept_pos: Token position of concept\n",
    "        direction_text: Text containing direction concept\n",
    "        direction_pos: Token position of direction\n",
    "        layer: Layer to extract from\n",
    "        description: Description for output\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (projected_vector, magnitude, cosine_similarity)\n",
    "    \"\"\"\n",
    "    concept_vec = get_vector(concept_text, concept_pos, layer)\n",
    "    direction_vec = get_vector(direction_text, direction_pos, layer)\n",
    "    \n",
    "    projected_vec, magnitude, cosine_sim = vector_projection(concept_vec, direction_vec)\n",
    "    \n",
    "    print(f\"üìê {description}\")\n",
    "    print(f\"   Layer: {layer}\")\n",
    "    print(f\"   Projection magnitude: {magnitude:.3f}\")\n",
    "    print(f\"   Cosine similarity: {cosine_sim:.3f}\")\n",
    "    \n",
    "    return projected_vec, magnitude, cosine_sim\n",
    "\n",
    "def batch_projection_analysis(concept_texts, concept_positions, direction_text, direction_pos, \n",
    "                            layer, concept_names=None):\n",
    "    \"\"\"Analyze projections of multiple concepts onto a single direction.\n",
    "    \n",
    "    Args:\n",
    "        concept_texts: List of texts containing concepts\n",
    "        concept_positions: List of token positions for concepts\n",
    "        direction_text: Text containing direction concept  \n",
    "        direction_pos: Token position of direction\n",
    "        layer: Layer to extract from\n",
    "        concept_names: Optional names for concepts (for display)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Results mapping concept names to (magnitude, cosine_similarity)\n",
    "    \"\"\"\n",
    "    if concept_names is None:\n",
    "        concept_names = [f\"Concept_{i+1}\" for i in range(len(concept_texts))]\n",
    "    \n",
    "    direction_vec = get_vector(direction_text, direction_pos, layer)\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"üìä Batch projection analysis onto direction vector (Layer {layer})\")\n",
    "    print(f\"   Direction: '{direction_text}' (pos {direction_pos})\")\n",
    "    print(\"   Results:\")\n",
    "    \n",
    "    for i, (text, pos, name) in enumerate(zip(concept_texts, concept_positions, concept_names)):\n",
    "        concept_vec = get_vector(text, pos, layer)\n",
    "        _, magnitude, cosine_sim = vector_projection(concept_vec, direction_vec)\n",
    "        results[name] = (magnitude, cosine_sim)\n",
    "        print(f\"     {name:15s}: mag={magnitude:6.3f}, cos_sim={cosine_sim:6.3f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "print(\"\\nüöÄ Ready for experiments!\")\n",
    "print(f\"üí° Chat template available: {selfie._should_use_chat_template()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üî¨ EXPERIMENT 1: King - Man + Woman = ?\n",
    "**The classic vector arithmetic example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 1 CONFIG\n",
    "EXTRACT_LAYER = 12\n",
    "INJECT_LAYER = 3\n",
    "\n",
    "# INTERPRETATION PROMPT\n",
    "interp_prompt = InterpretationPrompt.create_entity_prompt(selfie.model.tokenizer)\n",
    "# Custom: InterpretationPrompt(selfie.model.tokenizer, [\"This refers to \", None])\n",
    "\n",
    "# CONCEPT STRINGS\n",
    "base_text = \"The king ruled the kingdom wisely\"\n",
    "sub_text = \"The man walked down the street\"\n",
    "add_text = \"The woman read an interesting book\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìù Tokenizing concept strings:\")\n",
    "print(\"\\nBASE (king):\")\n",
    "base_tokens = show_tokens(base_text)\n",
    "print(\"\\nSUBTRACT (man):\")\n",
    "sub_tokens = show_tokens(sub_text) \n",
    "print(\"\\nADD (woman):\")\n",
    "add_tokens = show_tokens(add_text)\n",
    "\n",
    "# SELECT TOKEN POSITIONS (modify these after seeing tokenization above)\n",
    "base_pos = 2  # \"king\" \n",
    "sub_pos = 2   # \"man\"\n",
    "add_pos = 2   # \"woman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN EXPERIMENT (with chat template option)\n",
    "result = experiment(base_text, base_pos, sub_text, sub_pos, add_text, add_pos,\n",
    "                   EXTRACT_LAYER, INJECT_LAYER, interp_prompt, \n",
    "                   \"King - Man + Woman (Expected: Queen-like)\", use_chat_template=True)\n",
    "\n",
    "# Without chat template (original behavior):\n",
    "# result = experiment(base_text, base_pos, sub_text, sub_pos, add_text, add_pos,\n",
    "#                    EXTRACT_LAYER, INJECT_LAYER, interp_prompt, \n",
    "#                    \"King - Man + Woman (Expected: Queen-like)\", use_chat_template=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üî¨ EXPERIMENT 2: Doctor - Man + Woman = ?\n",
    "**Professional role gender swap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 2 CONFIG  \n",
    "EXTRACT_LAYER = 15\n",
    "INJECT_LAYER = 5\n",
    "\n",
    "# INTERPRETATION PROMPT\n",
    "interp_prompt = InterpretationPrompt(selfie.model.tokenizer, [\"This person is a \", None])\n",
    "\n",
    "# CONCEPT STRINGS\n",
    "base_text = \"The doctor examined the patient carefully\"\n",
    "sub_text = \"The man walked down the street\"\n",
    "add_text = \"The woman read an interesting book\"\n",
    "\n",
    "print(\"üìù Tokenizing concept strings:\")\n",
    "print(\"\\nBASE (doctor):\")\n",
    "base_tokens = show_tokens(base_text)\n",
    "print(\"\\nSUBTRACT (man):\")\n",
    "sub_tokens = show_tokens(sub_text)\n",
    "print(\"\\nADD (woman):\") \n",
    "add_tokens = show_tokens(add_text)\n",
    "\n",
    "# SELECT TOKEN POSITIONS\n",
    "base_pos = 1  # \"doctor\"\n",
    "sub_pos = 1   # \"man\" \n",
    "add_pos = 1   # \"woman\"\n",
    "\n",
    "# RUN EXPERIMENT\n",
    "result = experiment(base_text, base_pos, sub_text, sub_pos, add_text, add_pos,\n",
    "                   EXTRACT_LAYER, INJECT_LAYER, interp_prompt,\n",
    "                   \"Doctor - Man + Woman (Expected: Nurse-like)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üî¨ EXPERIMENT 3: Custom Experiment\n",
    "**Your own vector arithmetic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 3 CONFIG\n",
    "EXTRACT_LAYER = 10 \n",
    "INJECT_LAYER = 2\n",
    "\n",
    "# INTERPRETATION PROMPT (customize as needed)\n",
    "# interp_prompt = InterpretationPrompt.create_concept_prompt(selfie.model.tokenizer)\n",
    "# interp_prompt = InterpretationPrompt.create_sentiment_prompt(selfie.model.tokenizer)\n",
    "interp_prompt = InterpretationPrompt(selfie.model.tokenizer, [\"This represents \", None, \" in society\"])\n",
    "\n",
    "# CONCEPT STRINGS (modify as needed)\n",
    "base_text = \"The teacher explained the concept clearly\"\n",
    "sub_text = \"The woman read an interesting book\" \n",
    "add_text = \"The man walked down the street\"\n",
    "\n",
    "print(\"üìù Tokenizing concept strings:\")\n",
    "print(\"\\nBASE:\")\n",
    "base_tokens = show_tokens(base_text)\n",
    "print(\"\\nSUBTRACT:\")\n",
    "sub_tokens = show_tokens(sub_text)\n",
    "print(\"\\nADD:\")\n",
    "add_tokens = show_tokens(add_text)\n",
    "\n",
    "# SELECT TOKEN POSITIONS\n",
    "base_pos = 1  # Adjust based on tokenization above\n",
    "sub_pos = 1   # Adjust based on tokenization above\n",
    "add_pos = 1   # Adjust based on tokenization above\n",
    "\n",
    "# RUN EXPERIMENT\n",
    "result = experiment(base_text, base_pos, sub_text, sub_pos, add_text, add_pos,\n",
    "                   EXTRACT_LAYER, INJECT_LAYER, interp_prompt,\n",
    "                   \"Custom: Teacher - Woman + Man\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üî¨ EXPERIMENT 4: Multi-Layer Aggregation\n",
    "**Advanced: Sum vectors from multiple layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 4 CONFIG\n",
    "EXTRACT_LAYERS = [3, 5, 13, 24,]  # Multiple layers to extract from\n",
    "INJECT_LAYER = 3\n",
    "AGGREGATION = \"sum\"  # \"sum\", \"mean\", or \"concat\"\n",
    "\n",
    "# INTERPRETATION PROMPT\n",
    "# interp_prompt = InterpretationPrompt.create_entity_prompt(selfie.model.tokenizer)\n",
    "\n",
    "interp_prompt = InterpretationPrompt(selfie.model.tokenizer, [\" \", None, \" in society\"])\n",
    "\n",
    "# CONCEPT STRINGS\n",
    "base_text = \"The king sat on his throne\"\n",
    "sub_text = \"The man sat on his throne\"\n",
    "add_text = \"The woman sat on her throne\"\n",
    "\n",
    "print(\"üìù Tokenizing concept strings:\")\n",
    "print(\"\\nBASE (scientist):\")\n",
    "show_tokens(base_text)\n",
    "print(\"\\nSUBTRACT (man):\")\n",
    "show_tokens(sub_text)\n",
    "print(\"\\nADD (woman):\")\n",
    "show_tokens(add_text)\n",
    "\n",
    "# SELECT TOKEN POSITIONS\n",
    "base_pos = 2  # \"scientist\"\n",
    "sub_pos = 2   # \"man\"\n",
    "add_pos = 2   # \"woman\"\n",
    "\n",
    "# MULTI-LAYER EXTRACTION FUNCTION\n",
    "def get_multi_layer_vector(text, token_pos, layers, agg_method=\"sum\"):\n",
    "    acts = selfie.get_activations(text, layer_indices=layers, token_indices=[token_pos])\n",
    "    vectors = [acts[layer][0] for layer in layers]\n",
    "    \n",
    "    if agg_method == \"sum\":\n",
    "        return torch.stack(vectors).sum(dim=0)\n",
    "    elif agg_method == \"mean\":\n",
    "        return torch.stack(vectors).mean(dim=0)\n",
    "    elif agg_method == \"concat\":\n",
    "        return torch.cat(vectors, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# RUN MULTI-LAYER EXPERIMENT\n",
    "# print(f\"\\nüßÆ Multi-layer: Scientist - Man + Woman\")\n",
    "print(f\"   Extract: L{EXTRACT_LAYERS} ({AGGREGATION}) | Inject: L{INJECT_LAYER}\")\n",
    "\n",
    "base_vec = get_multi_layer_vector(base_text, base_pos, EXTRACT_LAYERS, AGGREGATION)\n",
    "sub_vec = get_multi_layer_vector(sub_text, sub_pos, EXTRACT_LAYERS, AGGREGATION)\n",
    "add_vec = get_multi_layer_vector(add_text, add_pos, EXTRACT_LAYERS, AGGREGATION)\n",
    "\n",
    "result_vec = base_vec - sub_vec + add_vec\n",
    "interpretation = interpret_vector(result_vec, interp_prompt, INJECT_LAYER)\n",
    "\n",
    "print(f\"   ü§ñ {interpretation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üî¨ EXPERIMENT 5: Emotion/Abstract Concepts\n",
    "**Testing abstract concept arithmetic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 5 CONFIG\n",
    "EXTRACT_LAYER = 13\n",
    "INJECT_LAYER = 3\n",
    "\n",
    "# CUSTOM INTERPRETATION PROMPT FOR EMOTIONS/CONCEPTS\n",
    "interp_prompt = InterpretationPrompt(selfie.model.tokenizer, [\"This emotion or concept is \", None])\n",
    "\n",
    "# CONCEPT STRINGS (abstract/emotional)\n",
    "base_text = \"She felt incredibly happy about the news\"\n",
    "sub_text = \"He was extremely sad about the loss\" \n",
    "add_text = \"They became very angry at the situation\"\n",
    "\n",
    "print(\"üìù Tokenizing concept strings:\")\n",
    "print(\"\\nBASE (happy):\")\n",
    "show_tokens(base_text)\n",
    "print(\"\\nSUBTRACT (sad):\")\n",
    "show_tokens(sub_text)\n",
    "print(\"\\nADD (angry):\")\n",
    "show_tokens(add_text)\n",
    "\n",
    "# SELECT TOKEN POSITIONS (look for emotion words)\n",
    "base_pos = 4  # \"happy\" (adjust based on tokenization)\n",
    "sub_pos = 4   # \"sad\"\n",
    "add_pos = 4   # \"angry\"\n",
    "\n",
    "# RUN EXPERIMENT\n",
    "result = experiment(base_text, base_pos, sub_text, sub_pos, add_text, add_pos,\n",
    "                   EXTRACT_LAYER, INJECT_LAYER, interp_prompt,\n",
    "                   \"Emotion: Happy - Sad + Angry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üî¨ EXPERIMENT 6: Multi-String Vector Arithmetic\n",
    "**Using multiple strings per concept for more robust results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Tokenizing multiple strings:\n",
      "\\nBASE STRINGS (king concept):\n",
      "  String 1: The king ruled the kingdom wisely\n",
      "   0: '<bos>'\n",
      "   1: 'The'\n",
      "   2: 'king'\n",
      "   3: 'ruled'\n",
      "   4: 'the'\n",
      "   5: 'kingdom'\n",
      "   6: 'wisely'\n",
      "  String 2: A king sits on his royal throne\n",
      "   0: '<bos>'\n",
      "   1: 'A'\n",
      "   2: 'king'\n",
      "   3: 'sits'\n",
      "   4: 'on'\n",
      "   5: 'his'\n",
      "   6: 'royal'\n",
      "   7: 'throne'\n",
      "  String 3: The mighty king commanded his army\n",
      "   0: '<bos>'\n",
      "   1: 'The'\n",
      "   2: 'mighty'\n",
      "   3: 'king'\n",
      "   4: 'commanded'\n",
      "   5: 'his'\n",
      "   6: 'army'\n",
      "  String 4: Every king must protect his subjects\n",
      "   0: '<bos>'\n",
      "   1: 'Every'\n",
      "   2: 'king'\n",
      "   3: 'must'\n",
      "   4: 'protect'\n",
      "   5: 'his'\n",
      "   6: 'subjects'\n",
      "\\nSUB STRINGS (man concept):\n",
      "  String 1: The man walked down the street\n",
      "   0: '<bos>'\n",
      "   1: 'The'\n",
      "   2: 'man'\n",
      "   3: 'walked'\n",
      "   4: 'down'\n",
      "   5: 'the'\n",
      "   6: 'street'\n",
      "  String 2: A man stood in the doorway\n",
      "   0: '<bos>'\n",
      "   1: 'A'\n",
      "   2: 'man'\n",
      "   3: 'stood'\n",
      "   4: 'in'\n",
      "   5: 'the'\n",
      "   6: 'doorway'\n",
      "  String 3: The tall man carried a briefcase\n",
      "   0: '<bos>'\n",
      "   1: 'The'\n",
      "   2: 'tall'\n",
      "   3: 'man'\n",
      "   4: 'carried'\n",
      "   5: 'a'\n",
      "   6: 'briefcase'\n",
      "  String 4: Every man has his own story\n",
      "   0: '<bos>'\n",
      "   1: 'Every'\n",
      "   2: 'man'\n",
      "   3: 'has'\n",
      "   4: 'his'\n",
      "   5: 'own'\n",
      "   6: 'story'\n",
      "\\nADD STRINGS (woman concept):\n",
      "  String 1: The woman read an interesting book\n",
      "   0: '<bos>'\n",
      "   1: 'The'\n",
      "   2: 'woman'\n",
      "   3: 'read'\n",
      "   4: 'an'\n",
      "   5: 'interesting'\n",
      "   6: 'book'\n",
      "  String 2: A woman smiled at the children\n",
      "   0: '<bos>'\n",
      "   1: 'A'\n",
      "   2: 'woman'\n",
      "   3: 'smiled'\n",
      "   4: 'at'\n",
      "   5: 'the'\n",
      "   6: 'children'\n",
      "  String 3: The young woman worked at her desk\n",
      "   0: '<bos>'\n",
      "   1: 'The'\n",
      "   2: 'young'\n",
      "   3: 'woman'\n",
      "   4: 'worked'\n",
      "   5: 'at'\n",
      "   6: 'her'\n",
      "   7: 'desk'\n",
      "  String 4: Every woman deserves equal respect\n",
      "   0: '<bos>'\n",
      "   1: 'Every'\n",
      "   2: 'woman'\n",
      "   3: 'deserves'\n",
      "   4: 'equal'\n",
      "   5: 'respect'\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT 6 CONFIG\n",
    "EXTRACT_LAYER = 12\n",
    "INJECT_LAYER = 3\n",
    "\n",
    "# INTERPRETATION PROMPT\n",
    "interp_prompt = InterpretationPrompt.create_entity_prompt(selfie.model.tokenizer)\n",
    "\n",
    "# MULTIPLE STRINGS FOR EACH CONCEPT (for more robust extraction)\n",
    "base_strings = [\n",
    "    \"The king ruled the kingdom wisely\",\n",
    "    \"A king sits on his royal throne\", \n",
    "    \"The mighty king commanded his army\",\n",
    "    \"Every king must protect his subjects\"\n",
    "]\n",
    "\n",
    "sub_strings = [\n",
    "    \"The man walked down the street\",\n",
    "    \"A man stood in the doorway\",\n",
    "    \"The tall man carried a briefcase\", \n",
    "    \"Every man has his own story\"\n",
    "]\n",
    "\n",
    "add_strings = [\n",
    "    \"The woman read an interesting book\",\n",
    "    \"A woman smiled at the children\",\n",
    "    \"The young woman worked at her desk\",\n",
    "    \"Every woman deserves equal respect\"\n",
    "]\n",
    "\n",
    "print(\"üìù Tokenizing multiple strings:\")\n",
    "print(\"\\\\nBASE STRINGS (king concept):\")\n",
    "base_positions = []\n",
    "for i, text in enumerate(base_strings):\n",
    "    print(f\"  String {i+1}: {text}\")\n",
    "    tokens = show_tokens(text)\n",
    "    base_positions.append(2)  # \"king\" position in most strings\n",
    "\n",
    "print(\"\\\\nSUB STRINGS (man concept):\")\n",
    "sub_positions = []\n",
    "for i, text in enumerate(sub_strings):\n",
    "    print(f\"  String {i+1}: {text}\")\n",
    "    tokens = show_tokens(text)\n",
    "    sub_positions.append(2)  # \"man\" position in most strings\n",
    "\n",
    "print(\"\\\\nADD STRINGS (woman concept):\")  \n",
    "add_positions = []\n",
    "for i, text in enumerate(add_strings):\n",
    "    print(f\"  String {i+1}: {text}\")\n",
    "    tokens = show_tokens(text)\n",
    "    add_positions.append(2)  # \"woman\" position in most strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Comparing single-string vs multi-string approaches:\n",
      "\n",
      "--- SINGLE STRING APPROACH ---\n",
      "üßÆ King - Man + Woman (Single)\n",
      "   Extract: L12 | Inject: L3\n",
      "   üìù Using chat template for interpretation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76158228de064083915267fed09706bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have set `compile_config`, but we are unable to meet the criteria for compilation. Compilation will be skipped.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ü§ñ of England.\n",
      "What is the answer?\n",
      "The answer is **Elizabeth**.\n",
      "The phrase is \"This refers to the entity Elizabeth, the queen\n",
      "\n",
      "--- MULTI-STRING (MEAN) APPROACH ---\n",
      "üßÆ King - Man + Woman (Multi-Mean)\n",
      "   Extract: L12 | Inject: L3 | Aggregation: mean\n",
      "   Base strings: 4 | Sub strings: 4 | Add strings: 4\n",
      "   üìù Using chat template for interpretation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ü§ñ of the realm of imagination.\n",
      "The answer is: **Queen**\n",
      "\n",
      "The full phrase is: \"This refers to the entity queen of the realm\n",
      "\n",
      "--- MULTI-STRING (SUM) APPROACH ---\n",
      "üßÆ King - Man + Woman (Multi-Sum)\n",
      "   Extract: L12 | Inject: L3 | Aggregation: sum\n",
      "   Base strings: 4 | Sub strings: 4 | Add strings: 4\n",
      "   üìù Using chat template for interpretation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ü§ñ and her crown, a symbol of her power, was stolen by a sorcerer.\n",
      "\n",
      "What is the answer?\n",
      "\n",
      "The answer is **Queen**.\n",
      "\n",
      "üìä COMPARISON SUMMARY:\n",
      "   Single string: 'of England.\n",
      "What is the answer?\n",
      "The answer is **Elizabeth**....'\n",
      "   Multi (mean):  'of the realm of imagination.\n",
      "The answer is: **Queen**\n",
      "\n",
      "The f...'\n",
      "   Multi (sum):   'and her crown, a symbol of her power, was stolen by a sorcer...'\n",
      "\n",
      "üí° Multi-string extraction can provide more robust concept representations!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN MULTI-STRING EXPERIMENTS\n",
    "\n",
    "print(\"üî¨ Comparing single-string vs multi-string approaches:\")\n",
    "\n",
    "# Single string experiment (using first string from each list)\n",
    "print(\"\\n--- SINGLE STRING APPROACH ---\")\n",
    "single_result = experiment(base_strings[0], base_positions[0], sub_strings[0], sub_positions[0], \n",
    "                          add_strings[0], add_positions[0], EXTRACT_LAYER, INJECT_LAYER, \n",
    "                          interp_prompt, \"King - Man + Woman (Single)\", use_chat_template=True)\n",
    "\n",
    "# Multi-string with mean aggregation\n",
    "print(\"\\n--- MULTI-STRING (MEAN) APPROACH ---\")\n",
    "multi_mean_result = multi_string_experiment(base_strings, base_positions, sub_strings, sub_positions,\n",
    "                                           add_strings, add_positions, EXTRACT_LAYER, INJECT_LAYER,\n",
    "                                           interp_prompt, \"King - Man + Woman (Multi-Mean)\", \n",
    "                                           aggregation=\"mean\", use_chat_template=True)\n",
    "\n",
    "# Multi-string with sum aggregation  \n",
    "print(\"\\n--- MULTI-STRING (SUM) APPROACH ---\")\n",
    "multi_sum_result = multi_string_experiment(base_strings, base_positions, sub_strings, sub_positions,\n",
    "                                          add_strings, add_positions, EXTRACT_LAYER, INJECT_LAYER, \n",
    "                                          interp_prompt, \"King - Man + Woman (Multi-Sum)\",\n",
    "                                          aggregation=\"sum\", use_chat_template=True)\n",
    "\n",
    "print(\"\\nüìä COMPARISON SUMMARY:\")\n",
    "print(f\"   Single string: '{single_result[1][:60]}...'\")\n",
    "print(f\"   Multi (mean):  '{multi_mean_result[1][:60]}...'\") \n",
    "print(f\"   Multi (sum):   '{multi_sum_result[1][:60]}...'\")\n",
    "\n",
    "print(\"\\nüí° Multi-string extraction can provide more robust concept representations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéõÔ∏è Quick Experiment Template\n",
    "**Copy this cell and modify for rapid experimentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUICK TEMPLATE - COPY AND MODIFY\n",
    "EXTRACT_LAYER = 12\n",
    "INJECT_LAYER = 3\n",
    "\n",
    "# Choose interpretation style:\n",
    "# interp_prompt = InterpretationPrompt.create_entity_prompt(selfie.model.tokenizer)\n",
    "# interp_prompt = InterpretationPrompt.create_concept_prompt(selfie.model.tokenizer)\n",
    "# interp_prompt = InterpretationPrompt.create_sentiment_prompt(selfie.model.tokenizer)\n",
    "interp_prompt = InterpretationPrompt(selfie.model.tokenizer, [\"Custom: \", None, \" here\"])\n",
    "\n",
    "# Your strings here:\n",
    "base_text = \"Your base concept sentence\"\n",
    "sub_text = \"Your subtract concept sentence\"\n",
    "add_text = \"Your add concept sentence\"\n",
    "\n",
    "# Tokenize first, then set positions:\n",
    "print(\"BASE:\"); show_tokens(base_text)\n",
    "print(\"SUB:\"); show_tokens(sub_text) \n",
    "print(\"ADD:\"); show_tokens(add_text)\n",
    "\n",
    "# Set positions based on tokenization above:\n",
    "base_pos = 1\n",
    "sub_pos = 1\n",
    "add_pos = 1\n",
    "\n",
    "# Run:\n",
    "# experiment(base_text, base_pos, sub_text, sub_pos, add_text, add_pos,\n",
    "#           EXTRACT_LAYER, INJECT_LAYER, interp_prompt, \"Your description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üÜö CHAT TEMPLATE COMPARISON\n",
    "**Demonstrating the difference between using chat templates vs raw text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARISON EXPERIMENT CONFIG\n",
    "EXTRACT_LAYER = 11\n",
    "INJECT_LAYER = 3\n",
    "\n",
    "# CONCEPT STRINGS\n",
    "base_text = \"The teacher explained the concept clearly\"\n",
    "sub_text = \"The woman read an interesting book\"\n",
    "add_text = \"The man walked down the street\"\n",
    "\n",
    "# TOKEN POSITIONS\n",
    "base_pos = 3  # \"teacher\"\n",
    "sub_pos = 3   # \"woman\" \n",
    "add_pos = 3   # \"man\"\n",
    "\n",
    "# INTERPRETATION PROMPT\n",
    "interp_prompt = InterpretationPrompt.create_entity_prompt(selfie.model.tokenizer)\n",
    "\n",
    "print(\"üî¨ Running the same experiment with and without chat template:\")\n",
    "print(\"\\n--- WITHOUT CHAT TEMPLATE ---\")\n",
    "result_no_template = experiment(base_text, base_pos, sub_text, sub_pos, add_text, add_pos,\n",
    "                               EXTRACT_LAYER, INJECT_LAYER, interp_prompt,\n",
    "                               \"Teacher - Woman + Man\", use_chat_template=False)\n",
    "\n",
    "print(\"\\n--- WITH CHAT TEMPLATE ---\")\n",
    "result_with_template = experiment(base_text, base_pos, sub_text, sub_pos, add_text, add_pos,\n",
    "                                 EXTRACT_LAYER, INJECT_LAYER, interp_prompt,\n",
    "                                 \"Teacher - Woman + Man\", use_chat_template=True)\n",
    "\n",
    "print(f\"\\nüìä RESULTS COMPARISON:\")\n",
    "print(f\"   Without template: '{result_no_template[1]}'\")\n",
    "print(f\"   With template:    '{result_with_template[1]}'\")\n",
    "\n",
    "# if selfie._should_use_chat_template():\n",
    "#     print(f\"\\nüí° This model ({MODEL_NAME}) supports chat templates - using them may improve results!\")\n",
    "# else:\n",
    "#     print(f\"\\nüí° This model ({MODEL_NAME}) doesn't have a chat template - both methods should behave similarly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîß Utilities\n",
    "**Helper functions for advanced use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH LAYER COMPARISON\n",
    "def compare_layers(text, token_pos, layers):\n",
    "    \"\"\"Compare same concept across multiple layers.\"\"\"\n",
    "    print(f\"üîç Layer comparison for token {token_pos} in: '{text}'\")\n",
    "    \n",
    "    vectors = {}\n",
    "    for layer in layers:\n",
    "        vectors[layer] = get_vector(text, token_pos, layer)\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    import torch.nn.functional as F\n",
    "    for i, l1 in enumerate(layers):\n",
    "        for l2 in layers[i+1:]:\n",
    "            sim = F.cosine_similarity(vectors[l1].unsqueeze(0), vectors[l2].unsqueeze(0)).item()\n",
    "            print(f\"   L{l1} ‚Üî L{l2}: {sim:.3f}\")\n",
    "\n",
    "# SAVE EXPERIMENT RESULTS\n",
    "def save_experiment(name, base_text, sub_text, add_text, base_pos, sub_pos, add_pos,\n",
    "                   extract_layer, inject_layer, interpretation, filename=\"results.txt\"):\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(f\"\\n=== {name} ===\\n\")\n",
    "        f.write(f\"Base: '{base_text}' pos {base_pos}\\n\")\n",
    "        f.write(f\"Sub: '{sub_text}' pos {sub_pos}\\n\") \n",
    "        f.write(f\"Add: '{add_text}' pos {add_pos}\\n\")\n",
    "        f.write(f\"Layers: {extract_layer} ‚Üí {inject_layer}\\n\")\n",
    "        f.write(f\"Result: {interpretation}\\n\")\n",
    "    print(f\"üíæ Saved to {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìê EXPERIMENT 7: Vector Projections\n",
    "**Project one concept onto another to measure directional alignment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Tokenizing gender direction texts:\n",
      "\n",
      "MAN:\n",
      "   0: '<bos>'\n",
      "   1: 'The'\n",
      "   2: 'man'\n",
      "   3: 'walked'\n",
      "   4: 'down'\n",
      "   5: 'the'\n",
      "   6: 'street'\n",
      "\n",
      "WOMAN:\n",
      "   0: '<bos>'\n",
      "   1: 'The'\n",
      "   2: 'woman'\n",
      "   3: 'walked'\n",
      "   4: 'down'\n",
      "   5: 'the'\n",
      "   6: 'street'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06150d8e6904cc4b2538e1aa08000a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have set `compile_config`, but we are unable to meet the criteria for compilation. Compilation will be skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß≠ Gender direction vector computed (woman - man)\n",
      "\n",
      "üìê Projecting concepts onto gender direction (Layer 12):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 2D and 2D tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text, pos, name \u001b[38;5;129;01min\u001b[39;00m test_concepts:\n\u001b[32m     38\u001b[39m     concept_vec = get_vector(text, pos, EXTRACT_LAYER)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     _, magnitude, cosine_sim = \u001b[43mvector_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcept_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgender_direction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     results[name] = (magnitude, cosine_sim)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m12s\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: projection=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmagnitude\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m6.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, similarity=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcosine_sim\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m6.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 220\u001b[39m, in \u001b[36mvector_projection\u001b[39m\u001b[34m(vector_a, vector_b)\u001b[39m\n\u001b[32m    217\u001b[39m b_normalized = F.normalize(vector_b.unsqueeze(\u001b[32m0\u001b[39m), dim=\u001b[32m1\u001b[39m).squeeze(\u001b[32m0\u001b[39m)\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m# Compute projection magnitude (dot product with normalized b)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m projection_magnitude = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_normalized\u001b[49m\u001b[43m)\u001b[49m.item()\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# Compute projected vector\u001b[39;00m\n\u001b[32m    223\u001b[39m projected_vector = projection_magnitude * b_normalized\n",
      "\u001b[31mRuntimeError\u001b[39m: 1D tensors expected, but got 2D and 2D tensors"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT 7A: Gender Direction Projection\n",
    "EXTRACT_LAYER = 12\n",
    "\n",
    "# Define gender direction using man -> woman vector\n",
    "man_text = \"The man walked down the street\"\n",
    "woman_text = \"The woman walked down the street\" \n",
    "\n",
    "print(\"üìù Tokenizing gender direction texts:\")\n",
    "print(\"\\nMAN:\")\n",
    "show_tokens(man_text)\n",
    "print(\"\\nWOMAN:\")\n",
    "show_tokens(woman_text)\n",
    "\n",
    "man_pos = 2    # \"man\"\n",
    "woman_pos = 2  # \"woman\"\n",
    "\n",
    "# Calculate gender direction vector (woman - man)\n",
    "man_vec = get_vector(man_text, man_pos, EXTRACT_LAYER)\n",
    "woman_vec = get_vector(woman_text, woman_pos, EXTRACT_LAYER)\n",
    "gender_direction = woman_vec - man_vec\n",
    "\n",
    "print(f\"\\nüß≠ Gender direction vector computed (woman - man)\")\n",
    "\n",
    "# Test concepts to project onto gender direction\n",
    "test_concepts = [\n",
    "    (\"The king ruled wisely\", 2, \"king\"),\n",
    "    (\"The queen ruled wisely\", 2, \"queen\"), \n",
    "    (\"The doctor examined carefully\", 2, \"doctor\"),\n",
    "    (\"The nurse helped patients\", 2, \"nurse\"),\n",
    "    (\"The teacher explained clearly\", 2, \"teacher\"),\n",
    "    (\"The engineer built bridges\", 2, \"engineer\")\n",
    "]\n",
    "\n",
    "print(f\"\\nüìê Projecting concepts onto gender direction (Layer {EXTRACT_LAYER}):\")\n",
    "results = {}\n",
    "\n",
    "for text, pos, name in test_concepts:\n",
    "    concept_vec = get_vector(text, pos, EXTRACT_LAYER)\n",
    "    _, magnitude, cosine_sim = vector_projection(concept_vec, gender_direction)\n",
    "    results[name] = (magnitude, cosine_sim)\n",
    "    print(f\"   {name:12s}: projection={magnitude:6.3f}, similarity={cosine_sim:6.3f}\")\n",
    "\n",
    "print(f\"\\nüí° Higher projection values indicate stronger alignment with 'feminine' direction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 7B: Emotion Direction Projection  \n",
    "EXTRACT_LAYER = 13\n",
    "\n",
    "# Define emotional directions\n",
    "happy_text = \"She felt incredibly happy about the news\"\n",
    "sad_text = \"She felt incredibly sad about the news\"\n",
    "angry_text = \"She felt incredibly angry about the news\"\n",
    "\n",
    "print(\"üìù Tokenizing emotion texts:\")\n",
    "print(\"\\nHAPPY:\"); show_tokens(happy_text)\n",
    "print(\"\\nSAD:\"); show_tokens(sad_text)  \n",
    "print(\"\\nANGRY:\"); show_tokens(angry_text)\n",
    "\n",
    "happy_pos = 4  # \"happy\"\n",
    "sad_pos = 4    # \"sad\"\n",
    "angry_pos = 4  # \"angry\"\n",
    "\n",
    "# Calculate emotion direction vectors\n",
    "happy_vec = get_vector(happy_text, happy_pos, EXTRACT_LAYER)\n",
    "sad_vec = get_vector(sad_text, sad_pos, EXTRACT_LAYER)\n",
    "angry_vec = get_vector(angry_text, angry_pos, EXTRACT_LAYER)\n",
    "\n",
    "# Create positive/negative emotion direction (happy - sad)\n",
    "emotion_direction = happy_vec - sad_vec\n",
    "\n",
    "print(f\"\\nüß≠ Emotion direction vector computed (happy - sad)\")\n",
    "\n",
    "# Test various emotional concepts\n",
    "emotion_concepts = [\n",
    "    (\"He was delighted with the result\", 2, \"delighted\"),\n",
    "    (\"She was devastated by the news\", 2, \"devastated\"),\n",
    "    (\"They were furious about the decision\", 2, \"furious\"),\n",
    "    (\"He felt content with his life\", 2, \"content\"),\n",
    "    (\"She was anxious about the test\", 2, \"anxious\"),\n",
    "    (\"They were excited for the party\", 3, \"excited\")\n",
    "]\n",
    "\n",
    "print(f\"\\nüìê Projecting emotions onto happy-sad direction (Layer {EXTRACT_LAYER}):\")\n",
    "for text, pos, name in emotion_concepts:\n",
    "    concept_vec = get_vector(text, pos, EXTRACT_LAYER)\n",
    "    _, magnitude, cosine_sim = vector_projection(concept_vec, emotion_direction)\n",
    "    print(f\"   {name:12s}: projection={magnitude:6.3f}, similarity={cosine_sim:6.3f}\")\n",
    "\n",
    "print(f\"\\nüí° Positive projections align with 'happy', negative with 'sad'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 7C: Batch Professional Projection Analysis\n",
    "EXTRACT_LAYER = 14\n",
    "\n",
    "# Define multiple professional concepts to analyze\n",
    "professional_texts = [\n",
    "    \"The doctor examined the patient\",\n",
    "    \"The lawyer argued the case\", \n",
    "    \"The teacher explained the lesson\",\n",
    "    \"The engineer designed the bridge\",\n",
    "    \"The artist painted a masterpiece\",\n",
    "    \"The scientist conducted experiments\",\n",
    "    \"The chef prepared the meal\",\n",
    "    \"The pilot flew the airplane\"\n",
    "]\n",
    "\n",
    "professional_names = [\"doctor\", \"lawyer\", \"teacher\", \"engineer\", \"artist\", \"scientist\", \"chef\", \"pilot\"]\n",
    "professional_positions = [2, 2, 2, 2, 2, 2, 2, 2]  # All professionals at position 2\n",
    "\n",
    "# Direction vector: authority/expertise\n",
    "authority_text = \"The expert gave authoritative advice\"\n",
    "authority_pos = 2  # \"expert\"\n",
    "\n",
    "print(\"üìä BATCH PROJECTION ANALYSIS\")\n",
    "print(\"   Projecting professional concepts onto 'authority/expertise' direction\")\n",
    "\n",
    "# Use the batch projection utility\n",
    "results = batch_projection_analysis(\n",
    "    professional_texts, \n",
    "    professional_positions,\n",
    "    authority_text,\n",
    "    authority_pos,\n",
    "    EXTRACT_LAYER,\n",
    "    professional_names\n",
    ")\n",
    "\n",
    "# Sort results by projection magnitude\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1][0], reverse=True)\n",
    "\n",
    "print(f\"\\nüèÜ RANKING BY AUTHORITY PROJECTION:\")\n",
    "for i, (name, (magnitude, cosine_sim)) in enumerate(sorted_results, 1):\n",
    "    print(f\"   {i}. {name:12s}: {magnitude:6.3f} (cos_sim: {cosine_sim:6.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Custom Projection Template\n",
    "**Template for your own vector projection experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM PROJECTION TEMPLATE - COPY AND MODIFY\n",
    "EXTRACT_LAYER = 12\n",
    "\n",
    "# OPTION 1: Simple projection of one concept onto another\n",
    "concept_text = \"Your concept sentence here\"\n",
    "direction_text = \"Your direction sentence here\"\n",
    "\n",
    "print(\"CONCEPT:\"); show_tokens(concept_text)\n",
    "print(\"DIRECTION:\"); show_tokens(direction_text)\n",
    "\n",
    "concept_pos = 1    # Adjust based on tokenization\n",
    "direction_pos = 1  # Adjust based on tokenization\n",
    "\n",
    "# Run projection\n",
    "# projected_vec, magnitude, cosine_sim = project_concept_onto_direction(\n",
    "#     concept_text, concept_pos, direction_text, direction_pos, \n",
    "#     EXTRACT_LAYER, \"Your Description\")\n",
    "\n",
    "# OPTION 2: Batch projection analysis\n",
    "concept_texts = [\n",
    "    \"First concept sentence\",\n",
    "    \"Second concept sentence\", \n",
    "    \"Third concept sentence\"\n",
    "]\n",
    "concept_names = [\"concept1\", \"concept2\", \"concept3\"]\n",
    "concept_positions = [1, 1, 1]  # Adjust based on tokenization\n",
    "\n",
    "direction_text = \"Your direction sentence\"\n",
    "direction_pos = 1\n",
    "\n",
    "# Run batch analysis\n",
    "# results = batch_projection_analysis(\n",
    "#     concept_texts, concept_positions, direction_text, direction_pos,\n",
    "#     EXTRACT_LAYER, concept_names)\n",
    "\n",
    "print(\"üí° Projection Template Ready - Uncomment and modify the sections above!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
