{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Psychiatry Vector Arithmetic Laboratory\n",
    "\n",
    "An interactive laboratory for exploring neural representations in therapeutic contexts using vector arithmetic. This notebook allows you to experiment with positive thought patterns, cognitive transformations, and advanced activation manipulation.\n",
    "\n",
    "## üî¨ Lab Features:\n",
    "- Load and experiment with positive thought patterns from JSONL dataset\n",
    "- Multi-layer activation extraction and injection\n",
    "- Advanced vector arithmetic operations\n",
    "- Modular parameter controls for easy experimentation\n",
    "- Custom interpretation prompts for therapeutic contexts\n",
    "- Interactive visualization of cognitive pattern transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Lab Setup and Initialization\n",
    "\n",
    "Initialize all required components. Run this once, then experiment freely below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Psychiatry Vector Arithmetic Lab initialized!\n",
      "üß† Ready to explore therapeutic neural representations\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install torch transformers nnsight tqdm pandas numpy matplotlib seaborn\n",
    "# !pip install accelerate  # For efficient model loading\n",
    "\n",
    "# FOR AMD GPU\n",
    "# import os\n",
    "# os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = \"11.0.0\"\n",
    "# os.environ[\"HIP_VISIBLE_DEVICES\"] = \"0\"\n",
    "# os.environ[\"AMD_SERIALIZE_KERNEL\"] = \"3\"\n",
    "# os.environ[\"TORCH_USE_HIP_DSA\"] = \"1\"\n",
    "\n",
    "# IMPORTS\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Add current project directory to path to import nnsight_selfie\n",
    "sys.path.insert(0, '..')  # Go up one level from examples/ to the project root\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Import our library\n",
    "from nnsight_selfie import (\n",
    "    ModelAgnosticSelfie, \n",
    "    InterpretationPrompt, \n",
    "    print_device_info, \n",
    "    get_optimal_device\n",
    ")\n",
    "\n",
    "# Standard imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Psychiatry Vector Arithmetic Lab initialized!\")\n",
    "print(\"üß† Ready to explore therapeutic neural representations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Device Detection ===\n",
      "=== Device Information ===\n",
      "Platform: Linux x86_64\n",
      "Python: 3.12.3\n",
      "PyTorch: 2.4.1+rocm6.0\n",
      "Optimal Device: cuda\n",
      "\n",
      "=== MPS Support ===\n",
      "MPS Available: False\n",
      "MPS Built: False\n",
      "\n",
      "=== CUDA Support ===\n",
      "CUDA Available: True\n",
      "CUDA Version: None\n",
      "Device Count: 1\n",
      "Primary Device: AMD Radeon RX 7700 XT\n",
      "\n",
      "üöÄ Optimal device: cuda\n",
      "\n",
      "üì• Loading google/gemma-3-4b-it...\n",
      "This may take a few minutes on first run\n",
      "Initializing model on device: cuda\n",
      "Filtered out vision components for Gemma 3 4B model.\n",
      "Model loaded successfully with 35 layers detected.\n",
      "‚úÖ Model loaded on: cuda\n",
      "üìä Layers: 35\n",
      "üî§ Vocab: 262,145 tokens\n"
     ]
    }
   ],
   "source": [
    "# Show device information and load model\n",
    "print(\"=== Device Detection ===\")\n",
    "print_device_info()\n",
    "\n",
    "optimal_device = get_optimal_device()\n",
    "print(f\"üöÄ Optimal device: {optimal_device}\")\n",
    "\n",
    "# Load model (adjust model name as needed)\n",
    "MODEL_NAME = \"google/gemma-3-4b-it\"  # Change this to experiment with different models\n",
    "\n",
    "print(f\"\\nüì• Loading {MODEL_NAME}...\")\n",
    "print(\"This may take a few minutes on first run\")\n",
    "\n",
    "try:\n",
    "    selfie = ModelAgnosticSelfie(\n",
    "        MODEL_NAME,\n",
    "        dtype=torch.bfloat16,\n",
    "        load_in_8bit=False\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded on: {selfie.device}\")\n",
    "    print(f\"üìä Layers: {len(selfie.layer_paths)}\")\n",
    "    print(f\"üî§ Vocab: {len(selfie.model.tokenizer):,} tokens\")\n",
    "    \n",
    "    # Store model info for experiments\n",
    "    MODEL_INFO = {\n",
    "        'name': MODEL_NAME,\n",
    "        'device': selfie.device,\n",
    "        'total_layers': len(selfie.layer_paths),\n",
    "        'vocab_size': len(selfie.model.tokenizer)\n",
    "    }\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load {MODEL_NAME}: {e}\")\n",
    "    print(\"üîÑ Consider using a smaller model or checking memory\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Hardcoded positive patterns for psychiatry experiments\nprint(\"üìÇ Loading hardcoded positive patterns for psychiatry experiments\")\n\n# Define hardcoded psychiatry-related patterns\npositive_patterns = [\n    {\n        'cognitive_pattern_type': 'Negative self-evaluative loop',\n        'cognitive_pattern_name': 'Self-Critical Rumination',\n        'pattern_description': 'Breaking cycles of harsh self-judgment and criticism',\n        'positive_thought_pattern': 'I notice I\\'m being harsh on myself right now. Instead of focusing on what went wrong, I can acknowledge that making mistakes is part of learning and growing. I\\'m doing my best with the resources and knowledge I have today.',\n        'reference_negative_example': 'I\\'m such an idiot for making that mistake. I always mess things up. Why can\\'t I ever do anything right? Everyone else seems to have it figured out except me.'\n    },\n    {\n        'cognitive_pattern_type': 'Anxiety catastrophizing',\n        'cognitive_pattern_name': 'Anxiety Spiral Interruption', \n        'pattern_description': 'Interrupting catastrophic thinking patterns with grounded reality',\n        'positive_thought_pattern': 'I can feel my anxiety starting to spiral into worst-case scenarios. Let me pause and breathe. Most of what I\\'m worrying about hasn\\'t happened yet and may never happen. I can focus on what I can control right now.',\n        'reference_negative_example': 'What if everything goes wrong? What if I fail completely? What if people think I\\'m incompetent? This is going to be a disaster and I\\'ll never recover from it.'\n    },\n    {\n        'cognitive_pattern_type': 'Depression hopelessness',\n        'cognitive_pattern_name': 'Hope Cultivation',\n        'pattern_description': 'Cultivating hope and possibility during depressive episodes',\n        'positive_thought_pattern': 'Even though things feel really dark right now, I\\'ve gotten through difficult times before. This feeling won\\'t last forever. I can take one small step today, even if it\\'s just getting dressed or going for a short walk.',\n        'reference_negative_example': 'Nothing will ever get better. I\\'m stuck in this misery forever. There\\'s no point in trying because everything I do fails anyway. Why even bother?'\n    },\n    {\n        'cognitive_pattern_type': 'Perfectionism paralysis',\n        'cognitive_pattern_name': 'Progress Over Perfection',\n        'pattern_description': 'Embracing progress and learning over perfectionist standards',\n        'positive_thought_pattern': 'I don\\'t need to be perfect to be valuable or to make progress. Done is better than perfect. I can start with a rough draft and improve it over time. Every step forward counts, no matter how small.',\n        'reference_negative_example': 'If I can\\'t do this perfectly, there\\'s no point in doing it at all. Everyone will see my flaws and judge me. I need to wait until I can guarantee a perfect outcome.'\n    },\n    {\n        'cognitive_pattern_type': 'Social anxiety avoidance',\n        'cognitive_pattern_name': 'Social Courage Building',\n        'pattern_description': 'Building confidence and reducing avoidance in social situations',\n        'positive_thought_pattern': 'Social situations feel challenging, but I can handle them. Most people are focused on themselves, not judging me. I have valuable things to contribute to conversations. I can start with small interactions and build my confidence.',\n        'reference_negative_example': 'Everyone is looking at me and thinking negative things. I\\'ll say something stupid and embarrass myself. It\\'s safer to just avoid social situations altogether.'\n    },\n    {\n        'cognitive_pattern_type': 'Trauma hypervigilance',\n        'cognitive_pattern_name': 'Safety and Grounding',\n        'pattern_description': 'Creating safety and presence after trauma responses',\n        'positive_thought_pattern': 'I notice my body is on high alert right now. That\\'s my nervous system trying to protect me. I\\'m safe in this moment. I can feel my feet on the ground and take some deep breaths to help my system calm down.',\n        'reference_negative_example': 'Danger is everywhere. I need to stay constantly alert or something terrible will happen. I can\\'t trust anyone or anything. The world is not safe.'\n    },\n    {\n        'cognitive_pattern_type': 'Emotional overwhelm',\n        'cognitive_pattern_name': 'Emotional Regulation',\n        'pattern_description': 'Managing intense emotions with self-compassion and coping skills',\n        'positive_thought_pattern': 'These emotions feel intense right now, but they will pass like clouds in the sky. I can acknowledge what I\\'m feeling without being consumed by it. Let me use my breathing techniques and remind myself that feelings are temporary.',\n        'reference_negative_example': 'I can\\'t handle these emotions. They\\'re too overwhelming. I\\'m completely out of control and there\\'s nothing I can do about it. These feelings will never end.'\n    },\n    {\n        'cognitive_pattern_type': 'Mindfulness grounding',\n        'cognitive_pattern_name': 'Present Moment Awareness',\n        'pattern_description': 'Cultivating present-moment awareness and mindful attention',\n        'positive_thought_pattern': 'Right now, in this moment, I am breathing. I can feel the air moving in and out of my lungs. I can notice the sounds around me, the feeling of my body in this chair. This present moment is all I need to focus on right now.',\n        'reference_negative_example': 'My mind is racing with thoughts about the past and future. I can\\'t focus on anything. Everything feels chaotic and scattered. I have no control over my thoughts.'\n    },\n    {\n        'cognitive_pattern_type': 'Self-compassion building',\n        'cognitive_pattern_name': 'Inner Kindness',\n        'pattern_description': 'Developing a kind and understanding relationship with oneself',\n        'positive_thought_pattern': 'I\\'m going through a difficult time, and it\\'s okay to struggle. If my best friend were in this situation, I would offer them kindness and understanding. I can offer myself that same compassion. I\\'m human, and humans have challenges.',\n        'reference_negative_example': 'I should be stronger than this. Other people don\\'t struggle like I do. I\\'m weak and pathetic for having these problems. I don\\'t deserve kindness or understanding.'\n    },\n    {\n        'cognitive_pattern_type': 'Resilience building',\n        'cognitive_pattern_name': 'Strength Recognition',\n        'pattern_description': 'Recognizing personal strength and resilience capacity',\n        'positive_thought_pattern': 'I\\'ve overcome challenges before, which shows I have strength and resilience within me. Even when things are hard, I find ways to cope and continue. I can trust in my ability to handle whatever comes my way.',\n        'reference_negative_example': 'I\\'m not strong enough for this. I always fall apart when things get difficult. I have no resilience or coping skills. I\\'ll never be able to handle life\\'s challenges.'\n    }\n]\n\nprint(f\"‚úÖ Loaded {len(positive_patterns)} hardcoded positive thought patterns\")\n\n# Show pattern categories\npattern_types = defaultdict(int)\npattern_names = defaultdict(int)\n\nfor pattern in positive_patterns:\n    pattern_types[pattern['cognitive_pattern_type']] += 1\n    pattern_names[pattern['cognitive_pattern_name']] += 1\n\nprint(f\"\\nüìä Pattern Distribution:\")\nprint(f\"  Types: {len(pattern_types)} unique types\")\nprint(f\"  Names: {len(pattern_names)} unique patterns\")\n\n# Show all pattern types\nprint(f\"\\nüîù Pattern Types:\")\nfor ptype, count in sorted(pattern_types.items(), key=lambda x: x[1], reverse=True):\n    print(f\"  - {ptype}: {count} examples\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≠ Therapeutic Interpretation Prompts\n",
    "\n",
    "Create specialized interpretation prompts for therapeutic and psychological contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≠ Therapeutic Interpretation Prompts Created:\n",
      "  Cognitive Pattern: 'This neural pattern represents the cognitive process of _ '\n",
      "  Emotional State: 'This activation encodes the emotional state of _ '\n",
      "  Therapeutic Concept: 'In therapeutic terms, this represents _ '\n",
      "  Mindfulness: 'From a mindfulness perspective, this embodies _ '\n",
      "  Resilience: 'This neural signature reflects resilience through _ '\n",
      "  Self Compassion: 'This pattern demonstrates self-compassion by _ '\n",
      "  Growth Mindset: 'This activation shows growth mindset through _ '\n",
      "  Coping Mechanism: 'As a coping mechanism, this represents _ '\n",
      "\n",
      "‚úÖ 8 therapeutic prompts ready for experimentation\n"
     ]
    }
   ],
   "source": [
    "# Create therapeutic interpretation prompts\n",
    "THERAPEUTIC_PROMPTS = {\n",
    "    \"cognitive_pattern\": InterpretationPrompt(\n",
    "        selfie.model.tokenizer,\n",
    "        [\"This neural pattern represents the cognitive process of \", None]\n",
    "    ),\n",
    "    \n",
    "    \"emotional_state\": InterpretationPrompt(\n",
    "        selfie.model.tokenizer,\n",
    "        [\"This activation encodes the emotional state of \", None]\n",
    "    ),\n",
    "    \n",
    "    \"therapeutic_concept\": InterpretationPrompt(\n",
    "        selfie.model.tokenizer,\n",
    "        [\"In therapeutic terms, this represents \", None]\n",
    "    ),\n",
    "    \n",
    "    \"mindfulness\": InterpretationPrompt(\n",
    "        selfie.model.tokenizer,\n",
    "        [\"From a mindfulness perspective, this embodies \", None]\n",
    "    ),\n",
    "    \n",
    "    \"resilience\": InterpretationPrompt(\n",
    "        selfie.model.tokenizer,\n",
    "        [\"This neural signature reflects resilience through \", None]\n",
    "    ),\n",
    "    \n",
    "    \"self_compassion\": InterpretationPrompt(\n",
    "        selfie.model.tokenizer,\n",
    "        [\"This pattern demonstrates self-compassion by \", None]\n",
    "    ),\n",
    "    \n",
    "    \"growth_mindset\": InterpretationPrompt(\n",
    "        selfie.model.tokenizer,\n",
    "        [\"This activation shows growth mindset through \", None]\n",
    "    ),\n",
    "    \n",
    "    \"coping_mechanism\": InterpretationPrompt(\n",
    "        selfie.model.tokenizer,\n",
    "        [\"As a coping mechanism, this represents \", None]\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"üé≠ Therapeutic Interpretation Prompts Created:\")\n",
    "for name, prompt in THERAPEUTIC_PROMPTS.items():\n",
    "    print(f\"  {name.replace('_', ' ').title()}: '{prompt.get_prompt()}'\")\n",
    "\n",
    "print(f\"\\n‚úÖ {len(THERAPEUTIC_PROMPTS)} therapeutic prompts ready for experimentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Experimental Utilities\n",
    "\n",
    "Modular functions for easy experimentation with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Psychiatry Vector Lab initialized and ready for experiments!\n"
     ]
    }
   ],
   "source": [
    "class PsychiatryVectorLab:\n",
    "    \"\"\"Main laboratory class for psychiatric vector arithmetic experiments.\"\"\"\n",
    "    \n",
    "    def __init__(self, selfie_model, positive_patterns, therapeutic_prompts):\n",
    "        self.selfie = selfie_model\n",
    "        self.patterns = positive_patterns\n",
    "        self.prompts = therapeutic_prompts\n",
    "        self.activation_cache = {}\n",
    "        \n",
    "    def get_random_pattern(self, pattern_type: Optional[str] = None, pattern_name: Optional[str] = None):\n",
    "        \"\"\"Get a random positive pattern, optionally filtered by type or name.\"\"\"\n",
    "        candidates = self.patterns.copy()\n",
    "        \n",
    "        if pattern_type:\n",
    "            candidates = [p for p in candidates if pattern_type.lower() in p['cognitive_pattern_type'].lower()]\n",
    "        \n",
    "        if pattern_name:\n",
    "            candidates = [p for p in candidates if pattern_name.lower() in p['cognitive_pattern_name'].lower()]\n",
    "        \n",
    "        if not candidates:\n",
    "            print(f\"‚ö†Ô∏è No patterns found matching criteria: type='{pattern_type}', name='{pattern_name}'\")\n",
    "            return None\n",
    "            \n",
    "        return random.choice(candidates)\n",
    "    \n",
    "    def tokenize_and_display(self, text: str, max_tokens: int = 20) -> Tuple[List[int], List[str]]:\n",
    "        \"\"\"Tokenize text and display tokens for selection.\"\"\"\n",
    "        tokens = self.selfie.model.tokenizer.encode(text)\n",
    "        token_strings = [self.selfie.model.tokenizer.decode([t]) for t in tokens]\n",
    "        \n",
    "        print(f\"\\nüî§ Tokenization ({len(tokens)} tokens):\")\n",
    "        display_limit = min(len(tokens), max_tokens)\n",
    "        \n",
    "        for i in range(display_limit):\n",
    "            token_str = token_strings[i]\n",
    "            print(f\"  {i:2d}: '{token_str.strip()}'\")\n",
    "        \n",
    "        if len(tokens) > max_tokens:\n",
    "            print(f\"  ... and {len(tokens) - max_tokens} more tokens\")\n",
    "            \n",
    "        return tokens, token_strings\n",
    "    \n",
    "    def extract_activations(self, \n",
    "                          text: str,\n",
    "                          layers: List[int],\n",
    "                          token_positions: List[int],\n",
    "                          cache_key: Optional[str] = None) -> Dict[int, List[torch.Tensor]]:\n",
    "        \"\"\"Extract activations from multiple layers and token positions.\"\"\"\n",
    "        \n",
    "        if cache_key and cache_key in self.activation_cache:\n",
    "            print(f\"üìã Using cached activations: {cache_key}\")\n",
    "            return self.activation_cache[cache_key]\n",
    "        \n",
    "        print(f\"üßÆ Extracting activations from {len(layers)} layers, {len(token_positions)} tokens...\")\n",
    "        \n",
    "        activations = self.selfie.get_activations(\n",
    "            text,\n",
    "            layer_indices=layers,\n",
    "            token_indices=token_positions\n",
    "        )\n",
    "        \n",
    "        if cache_key:\n",
    "            self.activation_cache[cache_key] = activations\n",
    "            print(f\"üíæ Cached activations: {cache_key}\")\n",
    "        \n",
    "        return activations\n",
    "    \n",
    "    def interpret_activation(self,\n",
    "                           text: str,\n",
    "                           layer: int,\n",
    "                           token_position: int,\n",
    "                           prompt_name: str = \"cognitive_pattern\",\n",
    "                           max_tokens: int = 15) -> str:\n",
    "        \"\"\"Interpret a single activation using specified therapeutic prompt.\"\"\"\n",
    "        \n",
    "        if prompt_name not in self.prompts:\n",
    "            available = list(self.prompts.keys())\n",
    "            print(f\"‚ùå Unknown prompt: {prompt_name}. Available: {available}\")\n",
    "            return \"[Error: Unknown prompt]\"\n",
    "        \n",
    "        try:\n",
    "            result = self.selfie.interpret(\n",
    "                original_prompt=text,\n",
    "                interpretation_prompt=self.prompts[prompt_name],\n",
    "                tokens_to_interpret=[(layer, token_position)],\n",
    "                max_new_tokens=max_tokens\n",
    "            )\n",
    "            \n",
    "            return result['interpretation'][0].strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Interpretation failed: {e}\")\n",
    "            return f\"[Error: {str(e)}]\"\n",
    "    \n",
    "    def vector_arithmetic(self,\n",
    "                         base_activations: Dict[int, List[torch.Tensor]],\n",
    "                         base_layer: int,\n",
    "                         base_token: int,\n",
    "                         operations: List[Tuple[str, Dict, int, int, float]]) -> torch.Tensor:\n",
    "        \"\"\"Perform vector arithmetic: base + sum(op_weight * activation).\n",
    "        \n",
    "        Args:\n",
    "            base_activations: Activations dict from base text\n",
    "            base_layer: Layer index for base vector\n",
    "            base_token: Token index for base vector\n",
    "            operations: List of (operation, activations_dict, layer, token, weight)\n",
    "                       where operation is \"+\" or \"-\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get base vector\n",
    "        if isinstance(base_activations[base_layer], list):\n",
    "            result = base_activations[base_layer][base_token].clone()\n",
    "        else:\n",
    "            result = base_activations[base_layer][:, base_token, :].clone()\n",
    "        \n",
    "        print(f\"üî¢ Starting with base vector from layer {base_layer}, token {base_token}\")\n",
    "        \n",
    "        # Apply operations\n",
    "        for op, activations, layer, token, weight in operations:\n",
    "            if isinstance(activations[layer], list):\n",
    "                vector = activations[layer][token]\n",
    "            else:\n",
    "                vector = activations[layer][:, token, :]\n",
    "            \n",
    "            if op == \"+\":\n",
    "                result = result + weight * vector\n",
    "                print(f\"  ‚ûï Added {weight}x vector from layer {layer}, token {token}\")\n",
    "            elif op == \"-\":\n",
    "                result = result - weight * vector\n",
    "                print(f\"  ‚ûñ Subtracted {weight}x vector from layer {layer}, token {token}\")\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è Unknown operation: {op}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def interpret_vector(self,\n",
    "                        vector: torch.Tensor,\n",
    "                        injection_layer: int,\n",
    "                        prompt_name: str = \"cognitive_pattern\",\n",
    "                        max_tokens: int = 20) -> str:\n",
    "        \"\"\"Interpret a computed vector by injecting it into the model.\"\"\"\n",
    "        \n",
    "        if prompt_name not in self.prompts:\n",
    "            return f\"[Error: Unknown prompt {prompt_name}]\"\n",
    "        \n",
    "        try:\n",
    "            interpretation = self.selfie.interpret_vectors(\n",
    "                vectors=[vector],\n",
    "                interpretation_prompt=self.prompts[prompt_name],\n",
    "                injection_layer=injection_layer,\n",
    "                max_new_tokens=max_tokens\n",
    "            )[0]\n",
    "            \n",
    "            return interpretation.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"[Error: {str(e)}]\"\n",
    "\n",
    "# Initialize the lab\n",
    "lab = PsychiatryVectorLab(selfie, positive_patterns, THERAPEUTIC_PROMPTS)\n",
    "print(\"üß™ Psychiatry Vector Lab initialized and ready for experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Dataset Explorer\n",
    "\n",
    "Explore the positive patterns dataset to understand available therapeutic contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset Explorer\n",
      "==================================================\n",
      "\n",
      "üß† Cognitive Pattern Types (13 total):\n",
      "  Cognitive depletion pattern........  40 examples\n",
      "  Intrusive suicidal fixation........  40 examples\n",
      "  Negative self-evaluative loop......  40 examples\n",
      "  Internal dialectical processing....  40 examples\n",
      "  Fragmented perceptual reasoning....  40 examples\n",
      "  Hyper-attuned interoception........  40 examples\n",
      "  Autobiographical integration.......  40 examples\n",
      "  Over-elaborative recounting........  40 examples\n",
      "  Entrapment cognition...............  40 examples\n",
      "  Existential rumination.............  40 examples\n",
      "  Learned helplessness loop..........  40 examples\n",
      "  Instrumental suicidal reasoning....  40 examples\n",
      "  Cognitive disorganization..........  40 examples\n",
      "\n",
      "üìù Example Patterns:\n",
      "\n",
      "üî∏ Example 1: Executive Fatigue & Avolition\n",
      "  Type: Cognitive depletion pattern\n",
      "  Positive Pattern: I'm recognizing that my energy levels are flagging today, which is totally normal. I've been pushing...\n",
      "  Negative Example: Ugh, just the thought of checking my email is draining me already. It's like try...\n",
      "\n",
      "üî∏ Example 2: Persistent Suicidal Ideation Focus\n",
      "  Type: Intrusive suicidal fixation\n",
      "  Positive Pattern: I've noticed how often my mind drifts to the idea of death as a coping mechanism when I'm feeling ov...\n",
      "  Negative Example: Ugh, there they go again - those incessant whispers about what would be better i...\n",
      "\n",
      "üî∏ Example 3: Self-Critical Rumination\n",
      "  Type: Negative self-evaluative loop\n",
      "  Positive Pattern: I can see how I could have done things differently, but instead of beating myself up over it, let's ...\n",
      "  Negative Example: Why did I have to mess that up again? It's just so typical of me to fail, like t...\n",
      "\n",
      "üéØ Quick Pattern Access:\n",
      "Use lab.get_random_pattern() or specify filters:\n",
      "  - lab.get_random_pattern(pattern_type='rumination')\n",
      "  - lab.get_random_pattern(pattern_name='Self-Critical')\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset patterns\n",
    "print(\"üìä Dataset Explorer\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if positive_patterns:\n",
    "    # Show pattern types distribution\n",
    "    pattern_type_counts = defaultdict(int)\n",
    "    for pattern in positive_patterns:\n",
    "        pattern_type_counts[pattern['cognitive_pattern_type']] += 1\n",
    "    \n",
    "    print(f\"\\nüß† Cognitive Pattern Types ({len(pattern_type_counts)} total):\")\n",
    "    for ptype, count in sorted(pattern_type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {ptype:.<35} {count:>3} examples\")\n",
    "    \n",
    "    # Show some example patterns\n",
    "    print(f\"\\nüìù Example Patterns:\")\n",
    "    for i, pattern in enumerate(positive_patterns[:3]):\n",
    "        print(f\"\\nüî∏ Example {i+1}: {pattern['cognitive_pattern_name']}\")\n",
    "        print(f\"  Type: {pattern['cognitive_pattern_type']}\")\n",
    "        print(f\"  Positive Pattern: {pattern['positive_thought_pattern'][:100]}...\")\n",
    "        if 'reference_negative_example' in pattern:\n",
    "            print(f\"  Negative Example: {pattern['reference_negative_example'][:80]}...\")\n",
    "    \n",
    "    # Interactive pattern selector\n",
    "    print(f\"\\nüéØ Quick Pattern Access:\")\n",
    "    print(\"Use lab.get_random_pattern() or specify filters:\")\n",
    "    print(\"  - lab.get_random_pattern(pattern_type='rumination')\")\n",
    "    print(\"  - lab.get_random_pattern(pattern_name='Self-Critical')\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No patterns loaded. Please check the dataset path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Experiment 1: Single Pattern Analysis\n",
    "\n",
    "Analyze individual positive thought patterns across different layers and tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ EXPERIMENT 1: Single Pattern Analysis\n",
      "============================================================\n",
      "üéØ Selected Pattern: Persistent Suicidal Ideation Focus\n",
      "üìù Type: Intrusive suicidal fixation\n",
      "üìÑ Description: Thoughts repeatedly return to death as the central theme, crowding out other cognition.\n",
      "\n",
      "üí≠ Analyzing: 'I've noticed that my mind tends to wander back to the possibility of death, but I'm taking it as a s...'\n",
      "\n",
      "üî§ Tokenization (125 tokens):\n",
      "   0: '<bos>'\n",
      "   1: 'I'\n",
      "   2: '''\n",
      "   3: 've'\n",
      "   4: 'noticed'\n",
      "   5: 'that'\n",
      "   6: 'my'\n",
      "   7: 'mind'\n",
      "   8: 'tends'\n",
      "   9: 'to'\n",
      "  10: 'wander'\n",
      "  11: 'back'\n",
      "  12: 'to'\n",
      "  13: 'the'\n",
      "  14: 'possibility'\n",
      "  15: 'of'\n",
      "  16: 'death'\n",
      "  17: ','\n",
      "  18: 'but'\n",
      "  19: 'I'\n",
      "  20: '''\n",
      "  21: 'm'\n",
      "  22: 'taking'\n",
      "  23: 'it'\n",
      "  24: 'as'\n",
      "  25: 'a'\n",
      "  26: 'sign'\n",
      "  27: 'that'\n",
      "  28: 'I'\n",
      "  29: '''\n",
      "  30: 'm'\n",
      "  31: 'still'\n",
      "  32: 'grappling'\n",
      "  33: 'with'\n",
      "  34: 'some'\n",
      "  35: 'deep'\n",
      "  36: '-'\n",
      "  37: 'seated'\n",
      "  38: 'concerns'\n",
      "  39: 'and'\n",
      "  40: 'fears'\n",
      "  41: '.'\n",
      "  42: 'Rather'\n",
      "  43: 'than'\n",
      "  44: 'getting'\n",
      "  45: 'stuck'\n",
      "  46: 'on'\n",
      "  47: 'them'\n",
      "  48: ','\n",
      "  49: 'I'\n",
      "  50: '''\n",
      "  51: 'm'\n",
      "  52: 'using'\n",
      "  53: 'these'\n",
      "  54: 'thoughts'\n",
      "  55: 'as'\n",
      "  56: 'an'\n",
      "  57: 'opportunity'\n",
      "  58: 'to'\n",
      "  59: 'reflect'\n",
      "  60: 'on'\n",
      "  61: 'what'\n",
      "  62: '''\n",
      "  63: 's'\n",
      "  64: 'driving'\n",
      "  65: 'this'\n",
      "  66: 'preoccupation'\n",
      "  67: 'and'\n",
      "  68: 'how'\n",
      "  69: 'I'\n",
      "  70: 'can'\n",
      "  71: 'work'\n",
      "  72: 'through'\n",
      "  73: 'it'\n",
      "  74: 'in'\n",
      "  75: 'a'\n",
      "  76: 'healthy'\n",
      "  77: 'way'\n",
      "  78: '‚Äì'\n",
      "  79: 'whether'\n",
      "  80: 'that'\n",
      "  81: 'means'\n",
      "  82: 'seeking'\n",
      "  83: 'support'\n",
      "  84: 'from'\n",
      "  85: 'loved'\n",
      "  86: 'ones'\n",
      "  87: 'or'\n",
      "  88: 'engaging'\n",
      "  89: 'in'\n",
      "  ... and 35 more tokens\n",
      "\n",
      "üéØ Analyzing tokens at positions: [2, 4, 6, 122, 123]\n",
      "   2: '''\n",
      "   4: 'noticed'\n",
      "   6: 'my'\n",
      "  122: 'coping'\n",
      "  123: 'mechanisms'\n",
      "üßÆ Extracting activations from 6 layers, 5 tokens...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a5447a074c4523a318956c62d5a78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have set `compile_config`, but we are unable to meet the criteria for compilation. Compilation will be skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Cached activations: single_pattern_Persistent Suicidal \n",
      "\n",
      "üß† Interpretations using 'cognitive_pattern' prompt:\n",
      "================================================================================\n",
      "Interpreting 'I've noticed that my mind tends to wander back to the possibility of death, but I'm taking it as a sign that I'm still grappling with some deep-seated concerns and fears. Rather than getting stuck on them, I'm using these thoughts as an opportunity to reflect on what's driving this preoccupation and how I can work through it in a healthy way ‚Äì whether that means seeking support from loved ones or engaging in self-care practices like journaling or meditation. It's not always easy, but acknowledging my emotions and being kind to myself is helping me build resilience and better coping mechanisms.' with 'This neural pattern represents the cognitive process of _ '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 10, Token  2 ('''):\n",
      "  ü§ñ symmetrical thinking_ and _cognitive dissonance_.\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "This image depicts a person trying\n",
      "\n",
      "Interpreting 'I've noticed that my mind tends to wander back to the possibility of death, but I'm taking it as a sign that I'm still grappling with some deep-seated concerns and fears. Rather than getting stuck on them, I'm using these thoughts as an opportunity to reflect on what's driving this preoccupation and how I can work through it in a healthy way ‚Äì whether that means seeking support from loved ones or engaging in self-care practices like journaling or meditation. It's not always easy, but acknowledging my emotions and being kind to myself is helping me build resilience and better coping mechanisms.' with 'This neural pattern represents the cognitive process of _ '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 10, Token  4 ('noticed'):\n",
      "  ü§ñ that it is a very large, intricate piece of equipment. \n",
      "A. observation\n",
      "B.\n",
      "\n",
      "Interpreting 'I've noticed that my mind tends to wander back to the possibility of death, but I'm taking it as a sign that I'm still grappling with some deep-seated concerns and fears. Rather than getting stuck on them, I'm using these thoughts as an opportunity to reflect on what's driving this preoccupation and how I can work through it in a healthy way ‚Äì whether that means seeking support from loved ones or engaging in self-care practices like journaling or meditation. It's not always easy, but acknowledging my emotions and being kind to myself is helping me build resilience and better coping mechanisms.' with 'This neural pattern represents the cognitive process of _ '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 10, Token  6 ('my'):\n",
      "  ü§ñ friend, family or colleagues \n",
      "\n",
      "In this scenario, we need to identify the neuroscientific processes that\n",
      "\n",
      "Interpreting 'I've noticed that my mind tends to wander back to the possibility of death, but I'm taking it as a sign that I'm still grappling with some deep-seated concerns and fears. Rather than getting stuck on them, I'm using these thoughts as an opportunity to reflect on what's driving this preoccupation and how I can work through it in a healthy way ‚Äì whether that means seeking support from loved ones or engaging in self-care practices like journaling or meditation. It's not always easy, but acknowledging my emotions and being kind to myself is helping me build resilience and better coping mechanisms.' with 'This neural pattern represents the cognitive process of _ '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 15, Token  2 ('''):\n",
      "  ü§ñ **a. Attentional Focus**.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "*   **Att\n",
      "\n",
      "Interpreting 'I've noticed that my mind tends to wander back to the possibility of death, but I'm taking it as a sign that I'm still grappling with some deep-seated concerns and fears. Rather than getting stuck on them, I'm using these thoughts as an opportunity to reflect on what's driving this preoccupation and how I can work through it in a healthy way ‚Äì whether that means seeking support from loved ones or engaging in self-care practices like journaling or meditation. It's not always easy, but acknowledging my emotions and being kind to myself is helping me build resilience and better coping mechanisms.' with 'This neural pattern represents the cognitive process of _ '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 15, Token  4 ('noticed'):\n",
      "  ü§ñ that the organism performs when it is exposed to a novel and potentially threatening stimulus.\n",
      "This neural pattern\n",
      "\n",
      "Interpreting 'I've noticed that my mind tends to wander back to the possibility of death, but I'm taking it as a sign that I'm still grappling with some deep-seated concerns and fears. Rather than getting stuck on them, I'm using these thoughts as an opportunity to reflect on what's driving this preoccupation and how I can work through it in a healthy way ‚Äì whether that means seeking support from loved ones or engaging in self-care practices like journaling or meditation. It's not always easy, but acknowledging my emotions and being kind to myself is helping me build resilience and better coping mechanisms.' with 'This neural pattern represents the cognitive process of _ '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 15, Token  6 ('my'):\n",
      "  ü§ñ thinking.\n",
      "\n",
      "The word that best fits this description is **cognition**.\n",
      "\n",
      "Here's why\n",
      "\n",
      "Interpreting 'I've noticed that my mind tends to wander back to the possibility of death, but I'm taking it as a sign that I'm still grappling with some deep-seated concerns and fears. Rather than getting stuck on them, I'm using these thoughts as an opportunity to reflect on what's driving this preoccupation and how I can work through it in a healthy way ‚Äì whether that means seeking support from loved ones or engaging in self-care practices like journaling or meditation. It's not always easy, but acknowledging my emotions and being kind to myself is helping me build resilience and better coping mechanisms.' with 'This neural pattern represents the cognitive process of _ '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 25, Token  2 ('''):\n",
      "  ü§ñ 24 hour time in English_.\n",
      "\n",
      "Neural patterns are complex and multifaceted, and this particular pattern\n",
      "\n",
      "Interpreting 'I've noticed that my mind tends to wander back to the possibility of death, but I'm taking it as a sign that I'm still grappling with some deep-seated concerns and fears. Rather than getting stuck on them, I'm using these thoughts as an opportunity to reflect on what's driving this preoccupation and how I can work through it in a healthy way ‚Äì whether that means seeking support from loved ones or engaging in self-care practices like journaling or meditation. It's not always easy, but acknowledging my emotions and being kind to myself is helping me build resilience and better coping mechanisms.' with 'This neural pattern represents the cognitive process of _ '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 25, Token  4 ('noticed'):\n",
      "  ü§ñ a growing number of neuroscientists believe that the basic building blocks of human experience are formed through pattern recognition\n",
      "\n",
      "Interpreting 'I've noticed that my mind tends to wander back to the possibility of death, but I'm taking it as a sign that I'm still grappling with some deep-seated concerns and fears. Rather than getting stuck on them, I'm using these thoughts as an opportunity to reflect on what's driving this preoccupation and how I can work through it in a healthy way ‚Äì whether that means seeking support from loved ones or engaging in self-care practices like journaling or meditation. It's not always easy, but acknowledging my emotions and being kind to myself is helping me build resilience and better coping mechanisms.' with 'This neural pattern represents the cognitive process of _ '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 25, Token  6 ('my'):\n",
      "  ü§ñ computer or software application that takes input and produces output based on a predefined set of rules or learned patterns\n",
      "\n",
      "‚úÖ Single pattern analysis complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== EXPERIMENT PARAMETERS =====\n",
    "# Modify these to change the experiment\n",
    "\n",
    "# Pattern selection (set to None for random)\n",
    "EXPERIMENT_PATTERN_TYPE = None  # e.g., \"rumination\", \"intrusive\", \"negative self-evaluative\"\n",
    "EXPERIMENT_PATTERN_NAME = None  # e.g., \"Self-Critical\", \"Executive Fatigue\"\n",
    "\n",
    "# Layer analysis parameters  \n",
    "ANALYSIS_LAYERS = [5, 10, 15, 20, 25, 30]  # Which layers to analyze\n",
    "MAX_TOKENS_TO_SHOW = 90  # How many tokens to display for selection\n",
    "\n",
    "# Interpretation parameters\n",
    "INTERPRETATION_PROMPT = \"cognitive_pattern\"  # Which therapeutic prompt to use\n",
    "MAX_INTERPRETATION_TOKENS = 20\n",
    "\n",
    "# ===== EXPERIMENT EXECUTION =====\n",
    "\n",
    "print(\"üî¨ EXPERIMENT 1: Single Pattern Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get pattern\n",
    "pattern = lab.get_random_pattern(\n",
    "    pattern_type=EXPERIMENT_PATTERN_TYPE,\n",
    "    pattern_name=EXPERIMENT_PATTERN_NAME\n",
    ")\n",
    "\n",
    "if not pattern:\n",
    "    print(\"‚ùå No pattern found. Please adjust your filters.\")\n",
    "else:\n",
    "    print(f\"üéØ Selected Pattern: {pattern['cognitive_pattern_name']}\")\n",
    "    print(f\"üìù Type: {pattern['cognitive_pattern_type']}\")\n",
    "    print(f\"üìÑ Description: {pattern['pattern_description']}\")\n",
    "    \n",
    "    # Use the positive thought pattern\n",
    "    text = pattern['positive_thought_pattern']\n",
    "    print(f\"\\nüí≠ Analyzing: '{text[:100]}...'\")\n",
    "    \n",
    "    # Tokenize and show options\n",
    "    tokens, token_strings = lab.tokenize_and_display(text, MAX_TOKENS_TO_SHOW)\n",
    "    \n",
    "    # Select interesting tokens (modify these based on tokenization output above)\n",
    "    INTERESTING_TOKENS = [2, 4, 6, -3, -2]  # Adjust based on your tokenization\n",
    "    \n",
    "    # Convert negative indices\n",
    "    token_positions = []\n",
    "    for pos in INTERESTING_TOKENS:\n",
    "        if pos < 0:\n",
    "            token_positions.append(len(tokens) + pos)\n",
    "        else:\n",
    "            token_positions.append(pos)\n",
    "    \n",
    "    # Filter valid positions\n",
    "    token_positions = [p for p in token_positions if 0 <= p < len(tokens)]\n",
    "    \n",
    "    print(f\"\\nüéØ Analyzing tokens at positions: {token_positions}\")\n",
    "    for pos in token_positions:\n",
    "        if pos < len(token_strings):\n",
    "            print(f\"  {pos:2d}: '{token_strings[pos].strip()}'\")\n",
    "    \n",
    "    # Extract activations\n",
    "    activations = lab.extract_activations(\n",
    "        text=text,\n",
    "        layers=ANALYSIS_LAYERS,\n",
    "        token_positions=token_positions,\n",
    "        cache_key=f\"single_pattern_{pattern['cognitive_pattern_name'][:20]}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüß† Interpretations using '{INTERPRETATION_PROMPT}' prompt:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Interpret key combinations\n",
    "    for layer in [10, 15, 25]:  # Focus on a few layers\n",
    "        for token_idx, token_pos in enumerate(token_positions[:3]):  # First 3 tokens\n",
    "            if token_pos < len(token_strings):\n",
    "                token_text = token_strings[token_pos].strip()\n",
    "                interpretation = lab.interpret_activation(\n",
    "                    text=text,\n",
    "                    layer=layer,\n",
    "                    token_position=token_pos,\n",
    "                    prompt_name=INTERPRETATION_PROMPT,\n",
    "                    max_tokens=MAX_INTERPRETATION_TOKENS\n",
    "                )\n",
    "                \n",
    "                print(f\"Layer {layer:2d}, Token {token_pos:2d} ('{token_text}'):\")\n",
    "                print(f\"  ü§ñ {interpretation}\")\n",
    "                print()\n",
    "    \n",
    "    print(\"‚úÖ Single pattern analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öóÔ∏è Experiment 2: Cognitive Pattern Vector Arithmetic\n",
    "\n",
    "Perform vector arithmetic between different cognitive patterns to explore therapeutic transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ===== EXPERIMENT PARAMETERS =====\n\n# Pattern selection for arithmetic experiments\nBASE_PATTERN_TYPE = \"self-evaluative\"  # Base pattern type\nPOSITIVE_PATTERN_TYPE = \"compassion\"  # Pattern to add\nSUBTRACT_PATTERN_TYPE = \"anxiety\"  # Pattern to subtract\n\n# Vector arithmetic parameters\nEXTRACTION_LAYER = 15  # Layer to extract activations from\nINJECTION_LAYER = 10   # Layer to inject result into\nTARGET_TOKEN_POSITION = 3  # Which token position to use (adjust after tokenization)\n\n# Arithmetic weights\nPOSITIVE_WEIGHT = 1.0\nNEGATIVE_WEIGHT = 0.8\n\n# Interpretation settings\nARITHMETIC_INTERPRETATION_PROMPT = \"therapeutic_concept\"\n\n# ===== EXPERIMENT EXECUTION =====\n\nprint(\"‚öóÔ∏è EXPERIMENT 2: Cognitive Pattern Vector Arithmetic\")\nprint(\"=\" * 60)\n\n# Get patterns for arithmetic\nbase_pattern = lab.get_random_pattern(pattern_type=BASE_PATTERN_TYPE)\npositive_pattern = lab.get_random_pattern(pattern_type=POSITIVE_PATTERN_TYPE)\nsubtract_pattern = lab.get_random_pattern(pattern_type=SUBTRACT_PATTERN_TYPE)\n\npatterns_found = [p for p in [base_pattern, positive_pattern, subtract_pattern] if p]\n\nif len(patterns_found) < 2:\n    print(\"‚ùå Need at least 2 patterns for arithmetic. Using available patterns instead.\")\n    # Use first few patterns as fallback\n    base_pattern = positive_patterns[0] if len(positive_patterns) > 0 else None\n    positive_pattern = positive_patterns[1] if len(positive_patterns) > 1 else None\n    subtract_pattern = positive_patterns[2] if len(positive_patterns) > 2 else None\n    patterns_found = [p for p in [base_pattern, positive_pattern, subtract_pattern] if p]\n\nif len(patterns_found) >= 2:\n    print(f\"üßÆ Arithmetic Experiment: Base + Positive - Negative\")\n    \n    if base_pattern:\n        base_text = base_pattern['positive_thought_pattern']\n        print(f\"\\nüî∏ Base Pattern ({base_pattern['cognitive_pattern_name']}):\")\n        print(f\"  '{base_text[:80]}...'\")\n        \n        # Get activations for base\n        base_tokens, base_token_strings = lab.tokenize_and_display(base_text, 10)\n        base_activations = lab.extract_activations(\n            text=base_text,\n            layers=[EXTRACTION_LAYER],\n            token_positions=[min(TARGET_TOKEN_POSITION, len(base_tokens)-1)],\n            cache_key=\"arithmetic_base\"\n        )\n    \n    operations = []\n    \n    if positive_pattern:\n        pos_text = positive_pattern['positive_thought_pattern']\n        print(f\"\\n‚ûï Positive Pattern ({positive_pattern['cognitive_pattern_name']}):\")\n        print(f\"  '{pos_text[:80]}...'\")\n        \n        pos_tokens, _ = lab.tokenize_and_display(pos_text, 5)\n        pos_activations = lab.extract_activations(\n            text=pos_text,\n            layers=[EXTRACTION_LAYER],\n            token_positions=[min(TARGET_TOKEN_POSITION, len(pos_tokens)-1)],\n            cache_key=\"arithmetic_positive\"\n        )\n        \n        operations.append((\"+\", pos_activations, EXTRACTION_LAYER, \n                         min(TARGET_TOKEN_POSITION, len(pos_tokens)-1), POSITIVE_WEIGHT))\n    \n    if subtract_pattern:\n        neg_text = subtract_pattern['positive_thought_pattern']\n        print(f\"\\n‚ûñ Subtract Pattern ({subtract_pattern['cognitive_pattern_name']}):\")\n        print(f\"  '{neg_text[:80]}...'\")\n        \n        neg_tokens, _ = lab.tokenize_and_display(neg_text, 5)\n        neg_activations = lab.extract_activations(\n            text=neg_text,\n            layers=[EXTRACTION_LAYER],\n            token_positions=[min(TARGET_TOKEN_POSITION, len(neg_tokens)-1)],\n            cache_key=\"arithmetic_negative\"\n        )\n        \n        operations.append((\"-\", neg_activations, EXTRACTION_LAYER,\n                         min(TARGET_TOKEN_POSITION, len(neg_tokens)-1), NEGATIVE_WEIGHT))\n    \n    if base_pattern and operations:\n        # Perform vector arithmetic\n        print(f\"\\nüî¢ Performing arithmetic at layer {EXTRACTION_LAYER}:\")\n        result_vector = lab.vector_arithmetic(\n            base_activations=base_activations,\n            base_layer=EXTRACTION_LAYER,\n            base_token=min(TARGET_TOKEN_POSITION, len(base_tokens)-1),\n            operations=operations\n        )\n        \n        # Interpret the result\n        print(f\"\\nüß† Interpreting result vector (injection at layer {INJECTION_LAYER}):\")\n        interpretation = lab.interpret_vector(\n            vector=result_vector,\n            injection_layer=INJECTION_LAYER,\n            prompt_name=ARITHMETIC_INTERPRETATION_PROMPT,\n            max_tokens=25\n        )\n        \n        print(f\"ü§ñ Result: {interpretation}\")\n        \n        # Try different interpretation prompts\n        print(f\"\\nüé≠ Alternative Interpretations:\")\n        for prompt_name in [\"emotional_state\", \"resilience\", \"coping_mechanism\"]:\n            alt_interpretation = lab.interpret_vector(\n                vector=result_vector,\n                injection_layer=INJECTION_LAYER,\n                prompt_name=prompt_name,\n                max_tokens=20\n            )\n            print(f\"  {prompt_name.replace('_', ' ').title()}: {alt_interpretation}\")\n    \n    print(\"\\n‚úÖ Vector arithmetic experiment complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Experiment 3: Multi-Layer Activation Blending\n",
    "\n",
    "Extract activations from multiple layers and blend them for complex therapeutic representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ===== EXPERIMENT PARAMETERS =====\n\n# Pattern and layer selection\nBLENDING_PATTERN_TYPE = \"resilience\"  # Type of pattern to analyze\nSOURCE_LAYERS = [5, 10, 15, 20, 25]  # Layers to extract from\nLAYER_WEIGHTS = [0.1, 0.2, 0.3, 0.3, 0.1]  # Weights for blending (must sum to 1.0)\nTARGET_TOKENS = [2, 4, 6]  # Token positions to analyze\n\n# Injection parameters\nINJECTION_LAYERS = [8, 12, 18]  # Where to inject blended vectors\nBLENDING_PROMPTS = [\"resilience\", \"growth_mindset\", \"self_compassion\"]  # Interpretation contexts\n\n# ===== EXPERIMENT EXECUTION =====\n\nprint(\"üé® EXPERIMENT 3: Multi-Layer Activation Blending\")\nprint(\"=\" * 60)\n\n# Validate parameters\nif abs(sum(LAYER_WEIGHTS) - 1.0) > 0.01:\n    print(f\"‚ö†Ô∏è Layer weights sum to {sum(LAYER_WEIGHTS):.3f}, normalizing...\")\n    total = sum(LAYER_WEIGHTS)\n    LAYER_WEIGHTS = [w/total for w in LAYER_WEIGHTS]\n\nif len(SOURCE_LAYERS) != len(LAYER_WEIGHTS):\n    print(f\"‚ùå Mismatch: {len(SOURCE_LAYERS)} layers but {len(LAYER_WEIGHTS)} weights\")\nelse:\n    # Get pattern - try resilience first, then any pattern as fallback\n    pattern = lab.get_random_pattern(pattern_type=BLENDING_PATTERN_TYPE)\n    \n    if not pattern:\n        print(f\"‚ùå No pattern found for type: {BLENDING_PATTERN_TYPE}, using first available pattern\")\n        pattern = positive_patterns[0] if positive_patterns else None\n    \n    if not pattern:\n        print(f\"‚ùå No patterns available\")\n    else:\n        text = pattern['positive_thought_pattern']\n        print(f\"üéØ Pattern: {pattern['cognitive_pattern_name']}\")\n        print(f\"üìù Text: '{text[:100]}...'\")\n        \n        # Tokenize\n        tokens, token_strings = lab.tokenize_and_display(text, 12)\n        \n        # Validate token positions\n        valid_tokens = [t for t in TARGET_TOKENS if 0 <= t < len(tokens)]\n        if len(valid_tokens) != len(TARGET_TOKENS):\n            print(f\"‚ö†Ô∏è Some token positions invalid, using: {valid_tokens}\")\n            TARGET_TOKENS = valid_tokens\n        \n        print(f\"\\nüéØ Target tokens:\")\n        for pos in TARGET_TOKENS:\n            print(f\"  {pos:2d}: '{token_strings[pos].strip()}'\")\n        \n        # Extract activations from all source layers\n        activations = lab.extract_activations(\n            text=text,\n            layers=SOURCE_LAYERS,\n            token_positions=TARGET_TOKENS,\n            cache_key=f\"blending_{pattern['cognitive_pattern_name'][:15]}\"\n        )\n        \n        # Blend activations for each token\n        print(f\"\\nüé® Blending activations with weights: {[f'{w:.2f}' for w in LAYER_WEIGHTS]}\")\n        \n        blended_vectors = {}\n        \n        for token_idx, token_pos in enumerate(TARGET_TOKENS):\n            # Initialize with zeros\n            if isinstance(activations[SOURCE_LAYERS[0]], list):\n                blended = torch.zeros_like(activations[SOURCE_LAYERS[0]][token_idx])\n            else:\n                blended = torch.zeros_like(activations[SOURCE_LAYERS[0]][:, token_pos, :])\n            \n            # Weighted sum across layers\n            for layer_idx, (layer, weight) in enumerate(zip(SOURCE_LAYERS, LAYER_WEIGHTS)):\n                if isinstance(activations[layer], list):\n                    activation = activations[layer][token_idx]\n                else:\n                    activation = activations[layer][:, token_pos, :]\n                \n                blended += weight * activation\n            \n            blended_vectors[token_pos] = blended\n            print(f\"  ‚úÖ Blended vector for token {token_pos} ('{token_strings[token_pos].strip()}')\")\n        \n        # Interpret blended vectors across different injection layers and prompts\n        print(f\"\\nüß† Interpretations across {len(INJECTION_LAYERS)} injection layers:\")\n        print(\"=\" * 80)\n        \n        for inject_layer in INJECTION_LAYERS:\n            print(f\"\\nüìç Injection Layer {inject_layer}:\")\n            \n            for token_pos in TARGET_TOKENS[:2]:  # Focus on first 2 tokens\n                token_text = token_strings[token_pos].strip()\n                print(f\"\\n  üî∏ Token '{token_text}' interpretations:\")\n                \n                for prompt_name in BLENDING_PROMPTS:\n                    interpretation = lab.interpret_vector(\n                        vector=blended_vectors[token_pos],\n                        injection_layer=inject_layer,\n                        prompt_name=prompt_name,\n                        max_tokens=18\n                    )\n                    \n                    print(f\"    {prompt_name.replace('_', ' ').title():.<18} {interpretation}\")\n        \n        # Analyze blending statistics\n        print(f\"\\nüìä Blending Statistics:\")\n        for token_pos in TARGET_TOKENS:\n            vector = blended_vectors[token_pos]\n            flat = vector.flatten()\n            \n            print(f\"  Token {token_pos:2d} ('{token_strings[token_pos].strip()}'):\")\n            print(f\"    Norm: {torch.norm(flat):.1f}, Mean: {flat.mean():.3f}, Std: {flat.std():.3f}\")\n        \n        print(\"\\n‚úÖ Multi-layer blending experiment complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Experiment 4: Negative-to-Positive Pattern Transformation\n",
    "\n",
    "Use vector arithmetic to transform negative thought patterns into positive ones using the dataset's reference examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ===== EXPERIMENT PARAMETERS =====\n\n# Transformation parameters\nTRANSFORMATION_LAYER = 16  # Layer for extracting transformation vectors\nINJECTION_LAYER = 12       # Layer for interpretation\nTOKEN_POSITION = 5         # Focus token (adjust after seeing tokenization)\n\n# Pattern selection - use patterns with both positive and negative examples\nFOCUS_PATTERN_TYPES = [\"self-evaluative\", \"anxiety\", \"depression\"]  # Types with good neg/pos examples\nNUM_TRANSFORMATIONS = 3    # How many transformations to try\n\n# Interpretation prompts for transformation analysis\nTRANSFORMATION_PROMPTS = [\"therapeutic_concept\", \"resilience\", \"mindfulness\"]\n\n# ===== EXPERIMENT EXECUTION =====\n\nprint(\"üîÑ EXPERIMENT 4: Negative-to-Positive Pattern Transformation\")\nprint(\"=\" * 60)\n\ntransformation_results = []\n\nfor transform_idx in range(NUM_TRANSFORMATIONS):\n    print(f\"\\nüéØ Transformation {transform_idx + 1}/{NUM_TRANSFORMATIONS}\")\n    print(\"=\" * 40)\n    \n    # Find pattern with both negative and positive examples\n    suitable_patterns = []\n    for pattern in positive_patterns:\n        has_negative = 'reference_negative_example' in pattern and pattern['reference_negative_example']\n        has_positive = pattern['positive_thought_pattern']\n        # Use all patterns since they all have both positive and negative examples\n        \n        if has_negative and has_positive:\n            suitable_patterns.append(pattern)\n    \n    if not suitable_patterns:\n        print(\"‚ùå No suitable patterns found with both positive and negative examples\")\n        continue\n    \n    # Select pattern (rotate through available patterns)\n    pattern = suitable_patterns[transform_idx % len(suitable_patterns)]\n    positive_text = pattern['positive_thought_pattern']\n    negative_text = pattern['reference_negative_example']\n    \n    print(f\"üìã Pattern: {pattern['cognitive_pattern_name']}\")\n    print(f\"üìù Type: {pattern['cognitive_pattern_type']}\")\n    \n    print(f\"\\n‚ùå Negative: '{negative_text[:80]}...'\")\n    print(f\"‚úÖ Positive: '{positive_text[:80]}...'\")\n    \n    # Tokenize both versions\n    print(f\"\\nüî§ Tokenizing negative version:\")\n    neg_tokens, neg_token_strings = lab.tokenize_and_display(negative_text, 10)\n    \n    print(f\"\\nüî§ Tokenizing positive version:\")\n    pos_tokens, pos_token_strings = lab.tokenize_and_display(positive_text, 10)\n    \n    # Adjust token position if needed\n    actual_token_pos = min(TOKEN_POSITION, min(len(neg_tokens), len(pos_tokens)) - 1)\n    \n    print(f\"\\nüéØ Using token position {actual_token_pos}:\")\n    if actual_token_pos < len(neg_token_strings):\n        print(f\"  Negative: '{neg_token_strings[actual_token_pos].strip()}'\")\n    if actual_token_pos < len(pos_token_strings):\n        print(f\"  Positive: '{pos_token_strings[actual_token_pos].strip()}'\")\n    \n    # Extract activations\n    neg_activations = lab.extract_activations(\n        text=negative_text,\n        layers=[TRANSFORMATION_LAYER],\n        token_positions=[actual_token_pos],\n        cache_key=f\"neg_{transform_idx}_{pattern['cognitive_pattern_name'][:10]}\"\n    )\n    \n    pos_activations = lab.extract_activations(\n        text=positive_text,\n        layers=[TRANSFORMATION_LAYER],\n        token_positions=[actual_token_pos],\n        cache_key=f\"pos_{transform_idx}_{pattern['cognitive_pattern_name'][:10]}\"\n    )\n    \n    # Compute transformation vector: positive - negative\n    print(f\"\\nüßÆ Computing transformation vector (positive - negative):\")\n    \n    if isinstance(pos_activations[TRANSFORMATION_LAYER], list):\n        pos_vector = pos_activations[TRANSFORMATION_LAYER][0]\n        neg_vector = neg_activations[TRANSFORMATION_LAYER][0]\n    else:\n        pos_vector = pos_activations[TRANSFORMATION_LAYER][:, actual_token_pos, :]\n        neg_vector = neg_activations[TRANSFORMATION_LAYER][:, actual_token_pos, :]\n    \n    transformation_vector = pos_vector - neg_vector\n    \n    # Analyze transformation vector\n    flat_transform = transformation_vector.flatten()\n    print(f\"  Transformation vector stats:\")\n    print(f\"    Norm: {torch.norm(flat_transform):.1f}\")\n    print(f\"    Mean: {flat_transform.mean():.3f}\")\n    print(f\"    Std: {flat_transform.std():.3f}\")\n    \n    # Interpret the transformation vector\n    print(f\"\\nüß† Transformation Vector Interpretations:\")\n    \n    transform_interpretations = {}\n    \n    for prompt_name in TRANSFORMATION_PROMPTS:\n        interpretation = lab.interpret_vector(\n            vector=transformation_vector,\n            injection_layer=INJECTION_LAYER,\n            prompt_name=prompt_name,\n            max_tokens=20\n        )\n        \n        transform_interpretations[prompt_name] = interpretation\n        print(f\"  {prompt_name.replace('_', ' ').title():.<20} {interpretation}\")\n    \n    # Test transformation: apply to negative to get positive-like\n    print(f\"\\nüîÑ Testing transformation (negative + transform_vector):\")\n    \n    transformed_vector = neg_vector + transformation_vector\n    \n    for prompt_name in [\"cognitive_pattern\", \"emotional_state\"]:\n        result_interpretation = lab.interpret_vector(\n            vector=transformed_vector,\n            injection_layer=INJECTION_LAYER,\n            prompt_name=prompt_name,\n            max_tokens=25\n        )\n        \n        print(f\"  {prompt_name.replace('_', ' ').title()}: {result_interpretation}\")\n    \n    # Store results\n    transformation_results.append({\n        'pattern_name': pattern['cognitive_pattern_name'],\n        'pattern_type': pattern['cognitive_pattern_type'],\n        'negative_text': negative_text[:100],\n        'positive_text': positive_text[:100],\n        'token_position': actual_token_pos,\n        'transformation_norm': float(torch.norm(flat_transform)),\n        'interpretations': transform_interpretations\n    })\n\nprint(f\"\\nüìä Transformation Summary:\")\nprint(\"=\" * 50)\n\nif transformation_results:\n    avg_norm = np.mean([r['transformation_norm'] for r in transformation_results])\n    print(f\"Average transformation vector norm: {avg_norm:.1f}\")\n    \n    print(f\"\\nPattern types analyzed:\")\n    for result in transformation_results:\n        print(f\"  - {result['pattern_name']} ({result['pattern_type']})\")\n\nprint(\"\\n‚úÖ Negative-to-positive transformation experiment complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Custom Experiment Sandbox\n",
    "\n",
    "Free-form experimentation space. Modify the parameters and code below to run your own custom experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ===== CUSTOM EXPERIMENT SANDBOX =====\n# Feel free to modify anything below for your own experiments!\n\nprint(\"üî¨ CUSTOM EXPERIMENT SANDBOX\")\nprint(\"=\" * 50)\n\n# Example: Compare specific patterns from our hardcoded data\nPATTERN_A_NAME = \"Self-Critical\"  # Adjust based on available patterns\nPATTERN_B_NAME = \"Anxiety\"  # Adjust based on available patterns\n\n# Search for patterns by partial name match\npattern_a = None\npattern_b = None\n\n# Find patterns by name\nfor pattern in positive_patterns:\n    if PATTERN_A_NAME.lower() in pattern['cognitive_pattern_name'].lower():\n        pattern_a = pattern\n        break\n\nfor pattern in positive_patterns:\n    if PATTERN_B_NAME.lower() in pattern['cognitive_pattern_name'].lower():\n        pattern_b = pattern\n        break\n\nif pattern_a and pattern_b:\n    print(f\"üîç Comparing:\")\n    print(f\"  A: {pattern_a['cognitive_pattern_name']}\")\n    print(f\"  B: {pattern_b['cognitive_pattern_name']}\")\n    \n    # Extract and compare activations\n    text_a = pattern_a['positive_thought_pattern']\n    text_b = pattern_b['positive_thought_pattern']\n    \n    print(f\"\\nüí≠ Pattern A: '{text_a[:60]}...'\")\n    print(f\"üí≠ Pattern B: '{text_b[:60]}...'\")\n    \n    # Your analysis code here...\n    print(\"\\nüí° Add your custom analysis here!\")\n    print(\"Examples:\")\n    print(\"- Extract activations from both patterns\")\n    print(\"- Compute cosine similarity between vectors\")\n    print(\"- Perform pattern_a - pattern_b arithmetic\")\n    print(\"- Visualize activation differences\")\n    print(\"- Try different interpretation prompts\")\n    \n    # Example custom analysis:\n    print(\"\\nüßÆ Sample Analysis:\")\n    print(\"# Extract activations from layer 15, token 3\")\n    print(\"# activations_a = lab.extract_activations(text_a, layers=[15], token_positions=[3])\")\n    print(\"# activations_b = lab.extract_activations(text_b, layers=[15], token_positions=[3])\")\n    print(\"# difference = activations_a[15][0] - activations_b[15][0]\")\n    print(\"# interpretation = lab.interpret_vector(difference, 12, 'therapeutic_concept')\")\n\nelif not pattern_a and not pattern_b:\n    print(f\"‚ùå Neither pattern found. Available pattern names:\")\n    unique_names = set(p['cognitive_pattern_name'] for p in positive_patterns)\n    for name in sorted(unique_names):\n        print(f\"  - {name}\")\n        \n    print(f\"\\nüîç Quick examples you can try:\")\n    print(f\"  - Change PATTERN_A_NAME to 'Rumination'\")\n    print(f\"  - Change PATTERN_B_NAME to 'Hope'\") \n    print(f\"  - Change PATTERN_A_NAME to 'Social'\")\n    \nelse:\n    found_pattern = pattern_a or pattern_b\n    missing_name = PATTERN_B_NAME if pattern_a else PATTERN_A_NAME\n    print(f\"‚úÖ Found: {found_pattern['cognitive_pattern_name']}\")\n    print(f\"‚ùå Missing: Pattern with '{missing_name}' in name\")\n    \n    print(f\"\\nAvailable pattern names:\")\n    unique_names = set(p['cognitive_pattern_name'] for p in positive_patterns)\n    for name in sorted(unique_names):\n        print(f\"  - {name}\")\n\nprint(f\"\\nüéâ Sandbox ready for your experiments!\")\nprint(f\"\\nüìã Quick Tips:\")\nprint(f\"  - All patterns have both positive and negative examples\")\nprint(f\"  - Use lab.get_random_pattern() to get a random pattern\")\nprint(f\"  - Use lab.get_random_pattern(pattern_type='anxiety') for specific types\")\nprint(f\"  - Pattern types: {list(set(p['cognitive_pattern_type'] for p in positive_patterns))}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Lab Results Visualization\n",
    "\n",
    "Visualize and analyze results from your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization and analysis of lab results\n",
    "print(\"üìä LAB RESULTS VISUALIZATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if we have transformation results to visualize\n",
    "if 'transformation_results' in locals() and transformation_results:\n",
    "    print(f\"\\nüìà Transformation Analysis (n={len(transformation_results)}):\")\n",
    "    \n",
    "    # Plot transformation vector norms\n",
    "    norms = [r['transformation_norm'] for r in transformation_results]\n",
    "    pattern_names = [r['pattern_name'][:20] for r in transformation_results]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(norms)), norms)\n",
    "    plt.xlabel('Transformation Experiment')\n",
    "    plt.ylabel('Vector Norm')\n",
    "    plt.title('Transformation Vector Magnitudes')\n",
    "    plt.xticks(range(len(pattern_names)), pattern_names, rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average transformation norm: {np.mean(norms):.2f} ¬± {np.std(norms):.2f}\")\n",
    "\n",
    "# Model and dataset statistics\n",
    "if 'MODEL_INFO' in locals():\n",
    "    print(f\"\\nüèóÔ∏è Model Information:\")\n",
    "    for key, value in MODEL_INFO.items():\n",
    "        print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "print(f\"\\nüìÇ Dataset Statistics:\")\n",
    "print(f\"  Total patterns: {len(positive_patterns)}\")\n",
    "print(f\"  Cached activations: {len(lab.activation_cache)}\")\n",
    "\n",
    "# Cache information\n",
    "if lab.activation_cache:\n",
    "    print(f\"\\nüíæ Activation Cache:\")\n",
    "    for cache_key in lab.activation_cache.keys():\n",
    "        print(f\"  - {cache_key}\")\n",
    "\n",
    "print(\"\\n‚úÖ Lab session complete! Results visualized.\")\n",
    "print(\"\\nüî¨ To run more experiments:\")\n",
    "print(\"  1. Modify parameters in any experiment cell above\")\n",
    "print(\"  2. Re-run the experiment cell\")\n",
    "print(\"  3. Cached activations will speed up repeated runs\")\n",
    "print(\"  4. Use the sandbox for custom experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Lab Summary and Next Steps\n",
    "\n",
    "Summary of the Psychiatry Vector Arithmetic Laboratory and suggestions for further exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"üß† PSYCHIATRY VECTOR ARITHMETIC LAB SUMMARY\")\nprint(\"=\" * 60)\n\nprint(f\"\\nüî¨ Lab Components:\")\nprint(f\"  ‚úÖ Model loaded: {MODEL_INFO.get('name', 'Unknown')} on {MODEL_INFO.get('device', 'Unknown')}\")\nprint(f\"  ‚úÖ Hardcoded patterns: {len(positive_patterns)} psychiatry-focused thought patterns\")\nprint(f\"  ‚úÖ Therapeutic prompts: {len(THERAPEUTIC_PROMPTS)} specialized interpretations\")\nprint(f\"  ‚úÖ Lab utilities: Modular experimentation framework\")\n\nprint(f\"\\nüß™ Experiments Available:\")\nprint(f\"  1Ô∏è‚É£  Single Pattern Analysis - Layer-wise interpretation of individual patterns\")\nprint(f\"  2Ô∏è‚É£  Vector Arithmetic - Combine/subtract cognitive patterns\")\nprint(f\"  3Ô∏è‚É£  Multi-Layer Blending - Weight and combine activations from multiple layers\")\nprint(f\"  4Ô∏è‚É£  Negative‚ÜíPositive Transformation - Learn therapeutic transformation vectors\")\nprint(f\"  üî¨ Custom Sandbox - Free-form experimentation space\")\n\nprint(f\"\\nüé≠ Therapeutic Interpretation Contexts:\")\nfor name in THERAPEUTIC_PROMPTS.keys():\n    print(f\"  - {name.replace('_', ' ').title()}\")\n\nprint(f\"\\nüìä Hardcoded Cognitive Patterns:\")\nif positive_patterns:\n    pattern_types = list(set(p['cognitive_pattern_type'] for p in positive_patterns))\n    for ptype in sorted(pattern_types):\n        count = sum(1 for p in positive_patterns if p['cognitive_pattern_type'] == ptype)\n        print(f\"  - {ptype} ({count} example)\")\n\nprint(f\"\\nüí° Psychiatry-Focused Patterns Include:\")\nprint(f\"  üß† Self-critical rumination and compassionate reframing\")\nprint(f\"  üò∞ Anxiety catastrophizing and grounded reality checks\")  \nprint(f\"  üòî Depression hopelessness and hope cultivation\")\nprint(f\"  üéØ Perfectionism paralysis and progress-focused mindset\")\nprint(f\"  üë• Social anxiety and confidence building\")\nprint(f\"  üõ°Ô∏è Trauma responses and safety/grounding techniques\")\nprint(f\"  üåä Emotional overwhelm and regulation strategies\")\nprint(f\"  üßò Mindfulness and present-moment awareness\")\nprint(f\"  üíù Self-compassion and inner kindness\")\nprint(f\"  üí™ Resilience recognition and strength building\")\n\nprint(f\"\\nüöÄ Next Steps and Ideas:\")\nprint(f\"  üîÑ Run experiments with different model layers (early vs late)\")\nprint(f\"  üéØ Focus on specific therapeutic domains (anxiety, depression, resilience)\")\nprint(f\"  üìè Compare vector arithmetic results across different models\")\nprint(f\"  üîç Analyze which layers best capture therapeutic concepts\")\nprint(f\"  üé® Create therapeutic 'concept directions' for model steering\")\nprint(f\"  üìä Build visualizations of cognitive pattern spaces\")\nprint(f\"  ü§ù Combine multiple positive patterns for enhanced interventions\")\n\nprint(f\"\\nüí° Advanced Research Directions:\")\nprint(f\"  - Investigate layer-specific therapeutic representations\")\nprint(f\"  - Build 'cognitive transformation functions' using vector arithmetic\")\nprint(f\"  - Develop automated therapeutic prompt generation\")\nprint(f\"  - Create personalized therapeutic vector profiles\")\nprint(f\"  - Study cross-modal therapeutic representations\")\n\nprint(f\"\\nüéâ Happy experimenting! The lab is ready for therapeutic AI research.\")\nprint(f\"‚ú® No external datasets required - all patterns are self-contained!\")\n\n# Quick reference\nprint(f\"\\nüìã Quick Reference:\")\nprint(f\"  lab.get_random_pattern()  # Get random pattern\")\nprint(f\"  lab.get_random_pattern(pattern_type='anxiety')  # Get specific type\")\nprint(f\"  lab.tokenize_and_display(text)\")\nprint(f\"  lab.extract_activations(text, layers=[10, 15], token_positions=[2, 4])\")\nprint(f\"  lab.interpret_activation(text, layer=15, token_position=3, prompt_name='resilience')\")\nprint(f\"  lab.vector_arithmetic(base_acts, layer, token, operations)\")\nprint(f\"  lab.interpret_vector(vector, injection_layer=12, prompt_name='mindfulness')\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}