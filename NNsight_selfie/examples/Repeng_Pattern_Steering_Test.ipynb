{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sanity check: run this AFTER `model` and `tokenizer` are initialized\n",
        "try:\n",
        "    _ = model  # noqa: F821\n",
        "    _ = tokenizer  # noqa: F821\n",
        "except NameError:\n",
        "    print(\"Sanity cell: please run after model/tokenizer are created.\")\n",
        "else:\n",
        "    from NNsight_selfie.nnsight_selfie.repeng.repeng_activation_extractor import RepengActivationExtractor\n",
        "    extractor = RepengActivationExtractor(model, tokenizer)\n",
        "    info = extractor.get_layer_info()\n",
        "    print(\"Total layers:\", info.get(\"total_layers\"))\n",
        "    print(\"Selected layers:\", len(info.get(\"selected_layers\", [])))\n",
        "    print(\"First 3 layer paths:\", info.get(\"layer_paths\", [])[:3])\n",
        "\n",
        "    # Quick 2-input extraction to validate capture & shapes\n",
        "    acts = extractor.extract_last_token_activations([\n",
        "        \"Hello world\",\n",
        "        \"How are you?\"\n",
        "    ], batch_size=2, show_progress=False)\n",
        "\n",
        "    # Print one layer's activation shape\n",
        "    if len(acts) == 0:\n",
        "        print(\"No activations collected; check layer paths/tracing and device config.\")\n",
        "    else:\n",
        "        any_layer = next(iter(acts))\n",
        "        print(\"Sample layer:\", any_layer, \"shape:\", tuple(acts[any_layer].shape))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RePENG Pattern Steering Test (NNsight)\n",
        "# This notebook computes PCA-diff steering vectors per cognitive pattern and injects them at InterpretationPrompt placeholder positions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model (bfloat16)...\n",
            "Gemma 3 4B detected; extractor will filter out vision components.\n",
            "Loaded\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "import nnsight\n",
        "import torch\n",
        "\n",
        "# Robust import of local package without relying on __file__ (undefined in notebooks)\n",
        "try:\n",
        "    from nnsight_selfie import (\n",
        "        InterpretationPrompt,\n",
        "        compute_pattern_steering_vectors,\n",
        "        inject_with_interpretation_prompt,\n",
        "        list_patterns,\n",
        "    )\n",
        "except ModuleNotFoundError:\n",
        "    cwd = os.getcwd()\n",
        "    candidates = [\n",
        "        os.path.abspath(os.path.join(cwd, 'NNsight_selfie')),\n",
        "        os.path.abspath(os.path.join(cwd, '../NNsight_selfie')),\n",
        "        os.path.abspath(os.path.join(cwd, '..')),\n",
        "        os.path.abspath(os.path.join(cwd, '..', '..')),\n",
        "    ]\n",
        "    for c in candidates:\n",
        "        pkgdir = os.path.join(c, 'nnsight_selfie')\n",
        "        if os.path.isdir(pkgdir):\n",
        "            if c not in sys.path:\n",
        "                sys.path.insert(0, c)\n",
        "            break\n",
        "    from nnsight_selfie import (\n",
        "        InterpretationPrompt,\n",
        "        compute_pattern_steering_vectors,\n",
        "        inject_with_interpretation_prompt,\n",
        "        list_patterns,\n",
        "    )\n",
        "\n",
        "MODEL_NAME = os.environ.get('MODEL_NAME', 'google/Gemma-3-4B-it')\n",
        "\n",
        "# Resolve patterns path robustly\n",
        "PATTERNS_PATH = os.environ.get('PATTERNS_PATH')\n",
        "if not PATTERNS_PATH:\n",
        "    cwd = os.getcwd()\n",
        "    pattern_candidates = [\n",
        "        os.path.join(cwd, 'data/final/positive_patterns.jsonl'),\n",
        "        os.path.join(cwd, '../data/final/positive_patterns.jsonl'),\n",
        "        os.path.join(cwd, '../../data/final/positive_patterns.jsonl'),\n",
        "    ]\n",
        "    for p in pattern_candidates:\n",
        "        if os.path.exists(p):\n",
        "            PATTERNS_PATH = p\n",
        "            break\n",
        "\n",
        "print('Loading model (bfloat16)...')\n",
        "model = nnsight.LanguageModel(\n",
        "    MODEL_NAME,\n",
        "    device_map='auto',\n",
        "    dtype=torch.bfloat16,\n",
        "    low_cpu_mem_usage=False,\n",
        ")\n",
        "tokenizer = model.tokenizer\n",
        "\n",
        "# Apply Gemma 3 4B vision filter behavior used in ModelAgnosticSelfie by tagging model_name\n",
        "if 'gemma' in MODEL_NAME.lower() and '3' in MODEL_NAME and '4b' in MODEL_NAME.lower():\n",
        "    try:\n",
        "        setattr(model, 'model_name', MODEL_NAME)\n",
        "        print('Gemma 3 4B detected; extractor will filter out vision components.')\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "print('Loaded')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available patterns:\n",
            "['Conflict-Focused Self-Reflection', 'Disorganized Thought & Derealization', 'Executive Fatigue & Avolition', 'Existential Overload & Worthlessness', 'Fragmented Overwhelm & Exhaustion', 'Hopelessness-Driven Cognitive Exhaustion', 'Identity-Focused Life Narrative', 'Overload with Entrapment Themes', 'Overwhelmed Narrative Processing', 'Persistent Suicidal Ideation Focus']\n",
            "Filtered vision components. Using 35 layers.\n",
            "Initialized activation extractor for 35 layers\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting activations:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c934477c413e4fc0b37834a775e59c34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting activations:  10%|█         | 1/10 [00:08<01:13,  8.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not extract activation for layer 34, sample 0: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 1: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 2: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 3: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 4: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 5: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 6: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 7: too many indices for tensor of dimension 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting activations:  20%|██        | 2/10 [00:10<00:35,  4.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not extract activation for layer 34, sample 0: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 1: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 2: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 3: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 4: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 5: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 6: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 7: too many indices for tensor of dimension 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting activations:  30%|███       | 3/10 [00:11<00:22,  3.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not extract activation for layer 34, sample 0: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 1: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 2: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 3: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 4: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 5: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 6: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 7: too many indices for tensor of dimension 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting activations:  40%|████      | 4/10 [00:13<00:15,  2.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not extract activation for layer 34, sample 0: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 1: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 2: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 3: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 4: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 5: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 6: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 7: too many indices for tensor of dimension 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting activations:  50%|█████     | 5/10 [00:15<00:11,  2.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not extract activation for layer 34, sample 0: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 1: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 2: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 3: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 4: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 5: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 6: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 7: too many indices for tensor of dimension 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting activations:  60%|██████    | 6/10 [00:17<00:09,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not extract activation for layer 34, sample 0: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 1: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 2: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 3: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 4: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 5: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 6: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 7: too many indices for tensor of dimension 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting activations:  70%|███████   | 7/10 [00:19<00:06,  2.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not extract activation for layer 34, sample 0: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 1: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 2: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 3: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 4: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 5: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 6: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 7: too many indices for tensor of dimension 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting activations:  80%|████████  | 8/10 [00:21<00:04,  2.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not extract activation for layer 34, sample 0: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 1: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 2: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 3: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 4: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 5: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 6: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 7: too many indices for tensor of dimension 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting activations:  90%|█████████ | 9/10 [00:22<00:01,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not extract activation for layer 34, sample 0: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 1: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 2: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 3: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 4: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 5: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 6: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 7: too many indices for tensor of dimension 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting activations: 100%|██████████| 10/10 [00:24<00:00,  2.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not extract activation for layer 34, sample 0: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 1: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 2: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 3: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 4: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 5: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 6: too many indices for tensor of dimension 2\n",
            "Warning: Could not extract activation for layer 34, sample 7: too many indices for tensor of dimension 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "stack expects a non-empty TensorList",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m patterns = list_patterns(PATTERNS_PATH)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(patterns[:\u001b[32m10\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m bundles = \u001b[43mcompute_pattern_steering_vectors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatterns_jsonl_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPATTERNS_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpair_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpos-neg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpos-trans\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mneg-trans\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpca_diff\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mComputed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(bundles)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m steering bundles\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m bundles[:\u001b[32m1\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/turn_point/NNsight_selfie/nnsight_selfie/repeng/pipeline.py:91\u001b[39m, in \u001b[36mcompute_pattern_steering_vectors\u001b[39m\u001b[34m(model, tokenizer, patterns_jsonl_path, pair_types, method, layer_range, batch_size, whiten, show_progress)\u001b[39m\n\u001b[32m     89\u001b[39m     inputs_used = alternating_inputs\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     activations, inputs_used = \u001b[43mextractor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_dataset_activations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# Compute vectors\u001b[39;00m\n\u001b[32m     96\u001b[39m steering = generator.generate_steering_vectors(\n\u001b[32m     97\u001b[39m     activations=activations, method=method, whiten=whiten\n\u001b[32m     98\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/turn_point/NNsight_selfie/nnsight_selfie/repeng/repeng_activation_extractor.py:205\u001b[39m, in \u001b[36mRepengActivationExtractor.extract_dataset_activations\u001b[39m\u001b[34m(self, dataset, batch_size, show_progress)\u001b[39m\n\u001b[32m    202\u001b[39m     alternating_inputs.append(entry.negative)\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# Extract activations\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m activations = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextract_last_token_activations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43malternating_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExtracted activations for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m dataset entries (2x examples)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m activations, alternating_inputs\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/turn_point/NNsight_selfie/nnsight_selfie/repeng/repeng_activation_extractor.py:109\u001b[39m, in \u001b[36mRepengActivationExtractor.extract_last_token_activations\u001b[39m\u001b[34m(self, inputs, batch_size, show_progress)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Convert lists to tensors\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layer_indices:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     all_activations[layer_idx] = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_activations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExtracted activations for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m inputs across \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.layer_indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m layers\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m all_activations\n",
            "\u001b[31mRuntimeError\u001b[39m: stack expects a non-empty TensorList"
          ]
        }
      ],
      "source": [
        "print('Available patterns:')\n",
        "patterns = list_patterns(PATTERNS_PATH)\n",
        "print(patterns[:10])\n",
        "\n",
        "bundles = compute_pattern_steering_vectors(\n",
        "    model, tokenizer,\n",
        "    patterns_jsonl_path=PATTERNS_PATH,\n",
        "    pair_types=['pos-neg', 'pos-trans', 'neg-trans'],\n",
        "    method='pca_diff',\n",
        "    batch_size=8,\n",
        "    show_progress=True\n",
        ")\n",
        "print(f'Computed {len(bundles)} steering bundles')\n",
        "bundles[:1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build an interpretation prompt with placeholders\n",
        "interp = InterpretationPrompt.create_simple(tokenizer, prefix='This neural pattern represents ', suffix=' in emotion')\n",
        "prompt_text = interp.get_prompt()\n",
        "print('Prompt:', prompt_text)\n",
        "print('Insert positions:', interp.get_insert_locations()[:10])\n",
        "\n",
        "# Choose one steering vector bundle to test\n",
        "test_bundle = bundles[0]\n",
        "res = inject_with_interpretation_prompt(\n",
        "    model, tokenizer,\n",
        "    prompt_text=prompt_text,\n",
        "    steering_vector=test_bundle.steering_vector,\n",
        "    interpretation_prompt=interp,\n",
        "    injection_strength=1.0,\n",
        "    max_new_tokens=30,\n",
        "    do_sample=False\n",
        ")\n",
        "res['generated_text'][:400]\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
