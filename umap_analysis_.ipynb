{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1681fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 UMAP Analysis of Cognitive Transformations\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "import webbrowser\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import hdbscan\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Configure Plotly for browser display\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\"  # This will open plots in browser by default\n",
    "\n",
    "# Set device and paths\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "base_path = Path(\"/Users/ivanculo/Desktop/Projects/turn_point\")\n",
    "activations_dir = base_path / \"activations\"\n",
    "\n",
    "# Load data (same as test_single_pattern.py)\n",
    "negative_activations = torch.load(activations_dir / \"activations_8ff00d963316212d.pt\", map_location=device)\n",
    "positive_activations = torch.load(activations_dir / \"activations_e5ad16e9b3c33c9b.pt\", map_location=device)\n",
    "transition_activations = torch.load(activations_dir / \"activations_332f24de2a3f82ff.pt\", map_location=device)\n",
    "\n",
    "with open(base_path / \"data\" / \"final\" / \"enriched_metadata.json\", 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Create pattern indices\n",
    "pattern_indices = {}\n",
    "for i, entry in enumerate(metadata):\n",
    "    pattern_name = entry['bad_good_narratives_match']['cognitive_pattern_name_from_bad_good']\n",
    "    if pattern_name not in pattern_indices:\n",
    "        pattern_indices[pattern_name] = []\n",
    "    pattern_indices[pattern_name].append(i)\n",
    "\n",
    "layer = 17\n",
    "first_pattern = list(pattern_indices.keys())[0]\n",
    "\n",
    "def prepare_data_for_umap(neg_data, pos_data, trans_data, max_samples=1000, subsample_tokens=True):\n",
    "    \"\"\"Prepare data for UMAP analysis with aggressive sampling\"\"\"\n",
    "    if subsample_tokens:\n",
    "        # Take every 8th token and limit samples\n",
    "        neg_flat = neg_data[:, ::8, :].reshape(-1, neg_data.shape[-1])\n",
    "        pos_flat = pos_data[:, ::8, :].reshape(-1, pos_data.shape[-1])\n",
    "        trans_flat = trans_data[:, ::8, :].reshape(-1, trans_data.shape[-1])\n",
    "    else:\n",
    "        neg_flat = neg_data.reshape(-1, neg_data.shape[-1])\n",
    "        pos_flat = pos_data.reshape(-1, pos_data.shape[-1])\n",
    "        trans_flat = trans_data.reshape(-1, trans_data.shape[-1])\n",
    "    \n",
    "    # Subsample to max_samples per category\n",
    "    if len(neg_flat) > max_samples:\n",
    "        indices = torch.randperm(len(neg_flat))[:max_samples]\n",
    "        neg_flat = neg_flat[indices]\n",
    "    if len(pos_flat) > max_samples:\n",
    "        indices = torch.randperm(len(pos_flat))[:max_samples]\n",
    "        pos_flat = pos_flat[indices]\n",
    "    if len(trans_flat) > max_samples:\n",
    "        indices = torch.randperm(len(trans_flat))[:max_samples]\n",
    "        trans_flat = trans_flat[indices]\n",
    "    \n",
    "    # Combine data and create labels\n",
    "    combined_data = torch.cat([neg_flat, pos_flat, trans_flat], dim=0).cpu().numpy()\n",
    "    labels = ['Negative'] * len(neg_flat) + ['Positive'] * len(pos_flat) + ['Transition'] * len(trans_flat)\n",
    "    colors = ['red'] * len(neg_flat) + ['green'] * len(pos_flat) + ['blue'] * len(trans_flat)\n",
    "    \n",
    "    return combined_data, labels, colors\n",
    "\n",
    "def plot_umap_2d_3d(data, labels, colors, title_prefix=\"\"):\n",
    "    \"\"\"Create interactive 2D and 3D UMAP plots with Plotly\"\"\"\n",
    "    print(f\"Computing UMAP for {len(data)} samples...\")\n",
    "    \n",
    "    # 2D UMAP with faster parameters\n",
    "    umap_2d = umap.UMAP(n_components=2, random_state=42, n_neighbors=min(15, len(data)//3), min_dist=0.1, n_jobs=1)\n",
    "    embedding_2d = umap_2d.fit_transform(data)\n",
    "    \n",
    "    # 3D UMAP with faster parameters  \n",
    "    umap_3d = umap.UMAP(n_components=3, random_state=42, n_neighbors=min(15, len(data)//3), min_dist=0.1, n_jobs=1)\n",
    "    embedding_3d = umap_3d.fit_transform(data)\n",
    "    \n",
    "    # Create color mapping\n",
    "    color_map = {'Negative': 'red', 'Positive': 'green', 'Transition': 'blue'}\n",
    "    \n",
    "    # Create 2D plot\n",
    "    fig_2d = go.Figure()\n",
    "    \n",
    "    for label in ['Negative', 'Positive', 'Transition']:\n",
    "        mask = [l == label for l in labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            fig_2d.add_trace(go.Scatter(\n",
    "                x=embedding_2d[indices, 0],\n",
    "                y=embedding_2d[indices, 1],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=color_map[label],\n",
    "                    size=4,\n",
    "                    opacity=0.7\n",
    "                ),\n",
    "                name=label,\n",
    "                hovertemplate=f'<b>{label}</b><br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_2d.update_layout(\n",
    "        title=f'{title_prefix}2D UMAP - Interactive Visualization',\n",
    "        xaxis_title='UMAP 1',\n",
    "        yaxis_title='UMAP 2',\n",
    "        width=800,\n",
    "        height=600,\n",
    "        showlegend=True,\n",
    "        hovermode='closest'\n",
    "    )\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig_3d = go.Figure()\n",
    "    \n",
    "    for label in ['Negative', 'Positive', 'Transition']:\n",
    "        mask = [l == label for l in labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            fig_3d.add_trace(go.Scatter3d(\n",
    "                x=embedding_3d[indices, 0],\n",
    "                y=embedding_3d[indices, 1],\n",
    "                z=embedding_3d[indices, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=color_map[label],\n",
    "                    size=3,\n",
    "                    opacity=0.7\n",
    "                ),\n",
    "                name=label,\n",
    "                hovertemplate=f'<b>{label}</b><br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<br>UMAP 3: %{{z:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_3d.update_layout(\n",
    "        title=f'{title_prefix}3D UMAP - Interactive Visualization',\n",
    "        scene=dict(\n",
    "            xaxis_title='UMAP 1',\n",
    "            yaxis_title='UMAP 2',\n",
    "            zaxis_title='UMAP 3'\n",
    "        ),\n",
    "        width=800,\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Save and open plots in new browser tabs\n",
    "    safe_title = title_prefix.replace(\" \", \"_\").replace(\"-\", \"\").strip(\"_\")\n",
    "    \n",
    "    # Save 2D plot\n",
    "    filename_2d = f\"umap_2d_{safe_title}_{hash(str(embedding_2d.tolist())) % 10000}.html\"\n",
    "    fig_2d.write_html(filename_2d, auto_open=False)\n",
    "    \n",
    "    # Save 3D plot  \n",
    "    filename_3d = f\"umap_3d_{safe_title}_{hash(str(embedding_3d.tolist())) % 10000}.html\"\n",
    "    fig_3d.write_html(filename_3d, auto_open=False)\n",
    "    \n",
    "    # Open in new browser tabs\n",
    "    abs_path_2d = os.path.abspath(filename_2d)\n",
    "    abs_path_3d = os.path.abspath(filename_3d)\n",
    "    \n",
    "    print(f\"Opening 2D plot: {filename_2d}\")\n",
    "    webbrowser.open(f'file://{abs_path_2d}', new=2)  # new=2 opens in new tab\n",
    "    \n",
    "    print(f\"Opening 3D plot: {filename_3d}\")  \n",
    "    webbrowser.open(f'file://{abs_path_3d}', new=2)  # new=2 opens in new tab\n",
    "    \n",
    "    # Also display inline for Jupyter\n",
    "    fig_2d.show()\n",
    "    fig_3d.show()\n",
    "    \n",
    "    return embedding_2d, embedding_3d\n",
    "\n",
    "def plot_depressive_only_umap(layer=17, max_samples=2000):\n",
    "    \"\"\"Visualize only depressive (negative) tokens across all cognitive patterns\"\"\"\n",
    "    print(f\"\\n🔴 Depressive Dataset UMAP (all patterns, negative tokens only)\")\n",
    "    \n",
    "    all_indices = [i for indices_list in pattern_indices.values() for i in indices_list]\n",
    "    neg_all = negative_activations[f'negative_layer_{layer}'][all_indices]\n",
    "    \n",
    "    print(f\"Depressive data shape: {neg_all.shape}\")\n",
    "    \n",
    "    # Prepare data - only negative, but we'll create dummy pos/trans for consistency\n",
    "    if max_samples and neg_all.shape[0] * neg_all.shape[1] > max_samples:\n",
    "        # Subsample tokens more aggressively\n",
    "        neg_flat = neg_all[:, ::12, :].reshape(-1, neg_all.shape[-1])\n",
    "    else:\n",
    "        neg_flat = neg_all.reshape(-1, neg_all.shape[-1])\n",
    "    \n",
    "    if len(neg_flat) > max_samples:\n",
    "        indices = torch.randperm(len(neg_flat))[:max_samples]\n",
    "        neg_flat = neg_flat[indices]\n",
    "    \n",
    "    # Create data with only negatives\n",
    "    combined_data = neg_flat.cpu().numpy()\n",
    "    labels = ['Depressive'] * len(neg_flat)\n",
    "    colors = ['darkred'] * len(neg_flat)\n",
    "    \n",
    "    print(f\"Combined depressive data shape: {combined_data.shape}\")\n",
    "    \n",
    "    # Compute UMAP\n",
    "    print(f\"Computing UMAP for {len(combined_data)} depressive samples...\")\n",
    "    umap_2d = umap.UMAP(n_components=2, random_state=42, n_neighbors=min(15, len(combined_data)//3), min_dist=0.1, n_jobs=1)\n",
    "    embedding_2d = umap_2d.fit_transform(combined_data)\n",
    "    \n",
    "    umap_3d = umap.UMAP(n_components=3, random_state=42, n_neighbors=min(15, len(combined_data)//3), min_dist=0.1, n_jobs=1)\n",
    "    embedding_3d = umap_3d.fit_transform(combined_data)\n",
    "    \n",
    "    # Create 2D plot\n",
    "    fig_2d = go.Figure()\n",
    "    fig_2d.add_trace(go.Scatter(\n",
    "        x=embedding_2d[:, 0],\n",
    "        y=embedding_2d[:, 1],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color='darkred',\n",
    "            size=4,\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        name='Depressive',\n",
    "        hovertemplate='<b>Depressive</b><br>UMAP 1: %{x:.2f}<br>UMAP 2: %{y:.2f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig_2d.update_layout(\n",
    "        title='Depressive Dataset Only - 2D UMAP',\n",
    "        xaxis_title='UMAP 1',\n",
    "        yaxis_title='UMAP 2',\n",
    "        width=800,\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig_3d = go.Figure()\n",
    "    fig_3d.add_trace(go.Scatter3d(\n",
    "        x=embedding_3d[:, 0],\n",
    "        y=embedding_3d[:, 1],\n",
    "        z=embedding_3d[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color='darkred',\n",
    "            size=3,\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        name='Depressive',\n",
    "        hovertemplate='<b>Depressive</b><br>UMAP 1: %{x:.2f}<br>UMAP 2: %{y:.2f}<br>UMAP 3: %{z:.2f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig_3d.update_layout(\n",
    "        title='Depressive Dataset Only - 3D UMAP',\n",
    "        scene=dict(\n",
    "            xaxis_title='UMAP 1',\n",
    "            yaxis_title='UMAP 2',\n",
    "            zaxis_title='UMAP 3'\n",
    "        ),\n",
    "        width=800,\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Save and open plots\n",
    "    filename_2d = f\"umap_2d_depressive_only_{hash(str(embedding_2d.tolist())) % 10000}.html\"\n",
    "    filename_3d = f\"umap_3d_depressive_only_{hash(str(embedding_3d.tolist())) % 10000}.html\"\n",
    "    \n",
    "    fig_2d.write_html(filename_2d, auto_open=False)\n",
    "    fig_3d.write_html(filename_3d, auto_open=False)\n",
    "    \n",
    "    print(f\"Opening depressive 2D plot: {filename_2d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_2d)}', new=2)\n",
    "    \n",
    "    print(f\"Opening depressive 3D plot: {filename_3d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_3d)}', new=2)\n",
    "    \n",
    "    fig_2d.show()\n",
    "    fig_3d.show()\n",
    "    \n",
    "    return embedding_2d, embedding_3d\n",
    "\n",
    "def plot_single_pattern_all_examples(pattern_name, layer=17, max_samples=1000):\n",
    "    \"\"\"Visualize all examples (neg, pos, trans) from one specific cognitive pattern\"\"\"\n",
    "    print(f\"\\n🎯 Single Pattern UMAP: {pattern_name} (all examples)\")\n",
    "    \n",
    "    if pattern_name not in pattern_indices:\n",
    "        print(f\"Pattern '{pattern_name}' not found. Available patterns:\")\n",
    "        for p in list(pattern_indices.keys())[:5]:\n",
    "            print(f\"  - {p}\")\n",
    "        return None, None\n",
    "    \n",
    "    indices = pattern_indices[pattern_name]\n",
    "    neg_single = negative_activations[f'negative_layer_{layer}'][indices]\n",
    "    pos_single = positive_activations[f'positive_layer_{layer}'][indices]\n",
    "    trans_single = transition_activations[f'transition_layer_{layer}'][indices]\n",
    "    \n",
    "    print(f\"Pattern data shapes - Neg: {neg_single.shape}, Pos: {pos_single.shape}, Trans: {trans_single.shape}\")\n",
    "    \n",
    "    data_single, labels_single, colors_single = prepare_data_for_umap(neg_single, pos_single, trans_single, max_samples=max_samples)\n",
    "    embedding_2d, embedding_3d = plot_umap_2d_3d(data_single, labels_single, colors_single, f\"{pattern_name}_AllExamples_\")\n",
    "    \n",
    "    return embedding_2d, embedding_3d\n",
    "\n",
    "def plot_single_example(pattern_name, example_idx=0, layer=17):\n",
    "    \"\"\"Visualize just one example from one cognitive pattern (all its tokens)\"\"\"\n",
    "    print(f\"\\n🔬 Single Example UMAP: {pattern_name} (example {example_idx})\")\n",
    "    \n",
    "    if pattern_name not in pattern_indices:\n",
    "        print(f\"Pattern '{pattern_name}' not found. Available patterns:\")\n",
    "        for p in list(pattern_indices.keys())[:5]:\n",
    "            print(f\"  - {p}\")\n",
    "        return None, None\n",
    "    \n",
    "    indices = pattern_indices[pattern_name]\n",
    "    if example_idx >= len(indices):\n",
    "        print(f\"Example index {example_idx} out of range. Pattern has {len(indices)} examples.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Get single example\n",
    "    single_idx = indices[example_idx]\n",
    "    neg_example = negative_activations[f'negative_layer_{layer}'][single_idx:single_idx+1]\n",
    "    pos_example = positive_activations[f'positive_layer_{layer}'][single_idx:single_idx+1]\n",
    "    trans_example = transition_activations[f'transition_layer_{layer}'][single_idx:single_idx+1]\n",
    "    \n",
    "    print(f\"Single example shapes - Neg: {neg_example.shape}, Pos: {pos_example.shape}, Trans: {trans_example.shape}\")\n",
    "    \n",
    "    # Flatten to get all tokens from this single example\n",
    "    neg_flat = neg_example.reshape(-1, neg_example.shape[-1])\n",
    "    pos_flat = pos_example.reshape(-1, pos_example.shape[-1])\n",
    "    trans_flat = trans_example.reshape(-1, trans_example.shape[-1])\n",
    "    \n",
    "    # Combine data\n",
    "    combined_data = torch.cat([neg_flat, pos_flat, trans_flat], dim=0).cpu().numpy()\n",
    "    labels = (['Negative'] * len(neg_flat) + \n",
    "              ['Positive'] * len(pos_flat) + \n",
    "              ['Transition'] * len(trans_flat))\n",
    "    \n",
    "    print(f\"Combined single example data shape: {combined_data.shape}\")\n",
    "    \n",
    "    if len(combined_data) < 10:\n",
    "        print(\"⚠️  Very few tokens in this example - UMAP may not be meaningful\")\n",
    "    \n",
    "    # Compute UMAP with adjusted parameters for small datasets\n",
    "    n_neighbors = min(5, len(combined_data)//2) if len(combined_data) < 50 else min(15, len(combined_data)//3)\n",
    "    \n",
    "    print(f\"Computing UMAP for {len(combined_data)} tokens from single example...\")\n",
    "    umap_2d = umap.UMAP(n_components=2, random_state=42, n_neighbors=n_neighbors, min_dist=0.1, n_jobs=1)\n",
    "    embedding_2d = umap_2d.fit_transform(combined_data)\n",
    "    \n",
    "    umap_3d = umap.UMAP(n_components=3, random_state=42, n_neighbors=n_neighbors, min_dist=0.1, n_jobs=1)\n",
    "    embedding_3d = umap_3d.fit_transform(combined_data)\n",
    "    \n",
    "    # Create color mapping\n",
    "    color_map = {'Negative': 'red', 'Positive': 'green', 'Transition': 'blue'}\n",
    "    \n",
    "    # Create 2D plot\n",
    "    fig_2d = go.Figure()\n",
    "    for label in ['Negative', 'Positive', 'Transition']:\n",
    "        mask = [l == label for l in labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            fig_2d.add_trace(go.Scatter(\n",
    "                x=embedding_2d[indices, 0],\n",
    "                y=embedding_2d[indices, 1],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=color_map[label],\n",
    "                    size=6,\n",
    "                    opacity=0.8\n",
    "                ),\n",
    "                name=f'{label} (tokens)',\n",
    "                hovertemplate=f'<b>{label} Token</b><br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_2d.update_layout(\n",
    "        title=f'Single Example: {pattern_name} (Example {example_idx}) - 2D UMAP',\n",
    "        xaxis_title='UMAP 1',\n",
    "        yaxis_title='UMAP 2',\n",
    "        width=800,\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig_3d = go.Figure()\n",
    "    for label in ['Negative', 'Positive', 'Transition']:\n",
    "        mask = [l == label for l in labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            fig_3d.add_trace(go.Scatter3d(\n",
    "                x=embedding_3d[indices, 0],\n",
    "                y=embedding_3d[indices, 1],\n",
    "                z=embedding_3d[indices, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=color_map[label],\n",
    "                    size=4,\n",
    "                    opacity=0.8\n",
    "                ),\n",
    "                name=f'{label} (tokens)',\n",
    "                hovertemplate=f'<b>{label} Token</b><br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<br>UMAP 3: %{{z:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_3d.update_layout(\n",
    "        title=f'Single Example: {pattern_name} (Example {example_idx}) - 3D UMAP',\n",
    "        scene=dict(\n",
    "            xaxis_title='UMAP 1',\n",
    "            yaxis_title='UMAP 2',\n",
    "            zaxis_title='UMAP 3'\n",
    "        ),\n",
    "        width=800,\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Save and open plots\n",
    "    safe_pattern = pattern_name.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "    filename_2d = f\"umap_2d_single_example_{safe_pattern}_{example_idx}_{hash(str(embedding_2d.tolist())) % 10000}.html\"\n",
    "    filename_3d = f\"umap_3d_single_example_{safe_pattern}_{example_idx}_{hash(str(embedding_3d.tolist())) % 10000}.html\"\n",
    "    \n",
    "    fig_2d.write_html(filename_2d, auto_open=False)\n",
    "    fig_3d.write_html(filename_3d, auto_open=False)\n",
    "    \n",
    "    print(f\"Opening single example 2D plot: {filename_2d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_2d)}', new=2)\n",
    "    \n",
    "    print(f\"Opening single example 3D plot: {filename_3d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_3d)}', new=2)\n",
    "    \n",
    "    fig_2d.show()\n",
    "    fig_3d.show()\n",
    "    \n",
    "    return embedding_2d, embedding_3d\n",
    "\n",
    "def perform_clustering_analysis(neg_data, pos_data, trans_data, layer=17, n_clusters=3, max_samples=1500):\n",
    "    \"\"\"\n",
    "    Perform K-means clustering on each cognitive state separately and create UMAP visualization\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔬 CLUSTERING ANALYSIS (K-means with {n_clusters} clusters per state)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Prepare data for each state\n",
    "    def prepare_state_data(data, state_name, max_samples):\n",
    "        # Subsample tokens if needed\n",
    "        if data.shape[0] * data.shape[1] > max_samples:\n",
    "            data_flat = data[:, ::8, :].reshape(-1, data.shape[-1])\n",
    "        else:\n",
    "            data_flat = data.reshape(-1, data.shape[-1])\n",
    "        \n",
    "        if len(data_flat) > max_samples:\n",
    "            indices = torch.randperm(len(data_flat))[:max_samples]\n",
    "            data_flat = data_flat[indices]\n",
    "            \n",
    "        return data_flat.cpu().numpy()\n",
    "    \n",
    "    # Prepare data for each cognitive state\n",
    "    neg_flat = prepare_state_data(neg_data, \"Negative\", max_samples)\n",
    "    pos_flat = prepare_state_data(pos_data, \"Positive\", max_samples)\n",
    "    trans_flat = prepare_state_data(trans_data, \"Transition\", max_samples)\n",
    "    \n",
    "    print(f\"Data shapes - Neg: {neg_flat.shape}, Pos: {pos_flat.shape}, Trans: {trans_flat.shape}\")\n",
    "    \n",
    "    # Standardize data for better clustering\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Perform clustering on each state separately\n",
    "    states_data = {\n",
    "        'Negative': neg_flat,\n",
    "        'Positive': pos_flat, \n",
    "        'Transition': trans_flat\n",
    "    }\n",
    "    \n",
    "    clustered_data = {}\n",
    "    cluster_results = {}\n",
    "    \n",
    "    for state_name, data in states_data.items():\n",
    "        print(f\"\\n🎯 Clustering {state_name} state ({data.shape[0]} samples)...\")\n",
    "        \n",
    "        # Standardize the data\n",
    "        data_scaled = scaler.fit_transform(data)\n",
    "        \n",
    "        # Perform K-means clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        cluster_labels = kmeans.fit_predict(data_scaled)\n",
    "        \n",
    "        # Store results\n",
    "        clustered_data[state_name] = {\n",
    "            'data': data,\n",
    "            'data_scaled': data_scaled,\n",
    "            'cluster_labels': cluster_labels,\n",
    "            'kmeans_model': kmeans\n",
    "        }\n",
    "        \n",
    "        # Print cluster statistics\n",
    "        unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "        print(f\"  Cluster distribution: {dict(zip(unique_labels, counts))}\")\n",
    "        \n",
    "        cluster_results[state_name] = {\n",
    "            'cluster_labels': cluster_labels,\n",
    "            'cluster_centers': kmeans.cluster_centers_,\n",
    "            'inertia': kmeans.inertia_\n",
    "        }\n",
    "    \n",
    "    # Compute UMAP on combined data but keep cluster info\n",
    "    combined_data = np.vstack([neg_flat, pos_flat, trans_flat])\n",
    "    combined_labels = (['Negative'] * len(neg_flat) + \n",
    "                      ['Positive'] * len(pos_flat) + \n",
    "                      ['Transition'] * len(trans_flat))\n",
    "    \n",
    "    # Create detailed cluster labels combining state and cluster\n",
    "    detailed_labels = []\n",
    "    cluster_colors = []\n",
    "    \n",
    "    # Color palettes for each state\n",
    "    neg_colors = ['#8B0000', '#DC143C', '#B22222']  # Dark red shades\n",
    "    pos_colors = ['#006400', '#228B22', '#32CD32']  # Dark green shades  \n",
    "    trans_colors = ['#00008B', '#4169E1', '#1E90FF']  # Blue shades\n",
    "    \n",
    "    color_maps = {\n",
    "        'Negative': neg_colors,\n",
    "        'Positive': pos_colors,\n",
    "        'Transition': trans_colors\n",
    "    }\n",
    "    \n",
    "    # Build combined labels and colors\n",
    "    for state_name in ['Negative', 'Positive', 'Transition']:\n",
    "        state_clusters = clustered_data[state_name]['cluster_labels']\n",
    "        state_colors = color_maps[state_name]\n",
    "        \n",
    "        for cluster_id in state_clusters:\n",
    "            detailed_labels.append(f\"{state_name}_Cluster_{cluster_id}\")\n",
    "            cluster_colors.append(state_colors[cluster_id % len(state_colors)])\n",
    "    \n",
    "    print(f\"\\n🗺️  Computing UMAP for {len(combined_data)} total samples...\")\n",
    "    \n",
    "    # Compute UMAP\n",
    "    umap_2d = umap.UMAP(n_components=2, random_state=42, \n",
    "                       n_neighbors=min(15, len(combined_data)//3), \n",
    "                       min_dist=0.1, n_jobs=1)\n",
    "    embedding_2d = umap_2d.fit_transform(combined_data)\n",
    "    \n",
    "    umap_3d = umap.UMAP(n_components=3, random_state=42,\n",
    "                       n_neighbors=min(15, len(combined_data)//3),\n",
    "                       min_dist=0.1, n_jobs=1)\n",
    "    embedding_3d = umap_3d.fit_transform(combined_data)\n",
    "    \n",
    "    return {\n",
    "        'embedding_2d': embedding_2d,\n",
    "        'embedding_3d': embedding_3d,\n",
    "        'combined_data': combined_data,\n",
    "        'detailed_labels': detailed_labels,\n",
    "        'cluster_colors': cluster_colors,\n",
    "        'clustered_data': clustered_data,\n",
    "        'cluster_results': cluster_results,\n",
    "        'state_labels': combined_labels\n",
    "    }\n",
    "\n",
    "def plot_clustered_umap(clustering_results, title_prefix=\"Clustered\"):\n",
    "    \"\"\"\n",
    "    Create UMAP plots showing cluster assignments for each cognitive state\n",
    "    \"\"\"\n",
    "    embedding_2d = clustering_results['embedding_2d']\n",
    "    embedding_3d = clustering_results['embedding_3d']\n",
    "    detailed_labels = clustering_results['detailed_labels']\n",
    "    cluster_colors = clustering_results['cluster_colors']\n",
    "    state_labels = clustering_results['state_labels']\n",
    "    \n",
    "    print(f\"\\n🎨 Creating clustered UMAP visualizations...\")\n",
    "    \n",
    "    # Create 2D plot\n",
    "    fig_2d = go.Figure()\n",
    "    \n",
    "    # Group by detailed cluster labels for legend\n",
    "    unique_detailed_labels = list(set(detailed_labels))\n",
    "    \n",
    "    for label in unique_detailed_labels:\n",
    "        mask = [l == label for l in detailed_labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            \n",
    "            # Extract state and cluster info for hover\n",
    "            state = label.split('_')[0]\n",
    "            cluster_id = label.split('_')[-1]\n",
    "            \n",
    "            fig_2d.add_trace(go.Scatter(\n",
    "                x=embedding_2d[indices, 0],\n",
    "                y=embedding_2d[indices, 1],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=cluster_colors[indices[0]],  # Use the assigned color\n",
    "                    size=4,\n",
    "                    opacity=0.7,\n",
    "                    line=dict(width=0.5, color='white')\n",
    "                ),\n",
    "                name=f\"{state} C{cluster_id}\",\n",
    "                hovertemplate=f'<b>{state} Cluster {cluster_id}</b><br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_2d.update_layout(\n",
    "        title=f'{title_prefix} - 2D UMAP with K-means Clusters',\n",
    "        xaxis_title='UMAP 1',\n",
    "        yaxis_title='UMAP 2',\n",
    "        width=900,\n",
    "        height=700,\n",
    "        showlegend=True,\n",
    "        hovermode='closest',\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\",\n",
    "            y=1,\n",
    "            xanchor=\"left\",\n",
    "            x=1.02\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig_3d = go.Figure()\n",
    "    \n",
    "    for label in unique_detailed_labels:\n",
    "        mask = [l == label for l in detailed_labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            \n",
    "            state = label.split('_')[0]\n",
    "            cluster_id = label.split('_')[-1]\n",
    "            \n",
    "            fig_3d.add_trace(go.Scatter3d(\n",
    "                x=embedding_3d[indices, 0],\n",
    "                y=embedding_3d[indices, 1],\n",
    "                z=embedding_3d[indices, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=cluster_colors[indices[0]],\n",
    "                    size=3,\n",
    "                    opacity=0.7,\n",
    "                    line=dict(width=0.5, color='white')\n",
    "                ),\n",
    "                name=f\"{state} C{cluster_id}\",\n",
    "                hovertemplate=f'<b>{state} Cluster {cluster_id}</b><br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<br>UMAP 3: %{{z:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_3d.update_layout(\n",
    "        title=f'{title_prefix} - 3D UMAP with K-means Clusters',\n",
    "        scene=dict(\n",
    "            xaxis_title='UMAP 1',\n",
    "            yaxis_title='UMAP 2',\n",
    "            zaxis_title='UMAP 3'\n",
    "        ),\n",
    "        width=900,\n",
    "        height=700,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Save and open plots\n",
    "    safe_title = title_prefix.replace(\" \", \"_\").replace(\"-\", \"\").strip(\"_\")\n",
    "    filename_2d = f\"umap_2d_clustered_{safe_title}_{hash(str(embedding_2d.tolist())) % 10000}.html\"\n",
    "    filename_3d = f\"umap_3d_clustered_{safe_title}_{hash(str(embedding_3d.tolist())) % 10000}.html\"\n",
    "    \n",
    "    fig_2d.write_html(filename_2d, auto_open=False)\n",
    "    fig_3d.write_html(filename_3d, auto_open=False)\n",
    "    \n",
    "    print(f\"Opening clustered 2D plot: {filename_2d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_2d)}', new=2)\n",
    "    \n",
    "    print(f\"Opening clustered 3D plot: {filename_3d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_3d)}', new=2)\n",
    "    \n",
    "    fig_2d.show()\n",
    "    fig_3d.show()\n",
    "    \n",
    "    return fig_2d, fig_3d\n",
    "\n",
    "def analyze_cluster_characteristics(clustering_results):\n",
    "    \"\"\"\n",
    "    Analyze and print characteristics of each cluster\n",
    "    \"\"\"\n",
    "    print(f\"\\n📊 CLUSTER ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    clustered_data = clustering_results['clustered_data']\n",
    "    cluster_results = clustering_results['cluster_results']\n",
    "    \n",
    "    for state_name, data_info in clustered_data.items():\n",
    "        print(f\"\\n🔍 {state_name.upper()} STATE CLUSTERS:\")\n",
    "        \n",
    "        cluster_labels = data_info['cluster_labels']\n",
    "        unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "        \n",
    "        total_samples = len(cluster_labels)\n",
    "        \n",
    "        for cluster_id, count in zip(unique_labels, counts):\n",
    "            percentage = (count / total_samples) * 100\n",
    "            print(f\"  Cluster {cluster_id}: {count:4d} samples ({percentage:5.1f}%)\")\n",
    "        \n",
    "        print(f\"  Total inertia (within-cluster sum of squares): {cluster_results[state_name]['inertia']:.2f}\")\n",
    "    \n",
    "    print(f\"\\n💡 INTERPRETATION GUIDE:\")\n",
    "    print(\"• Each cognitive state (Negative/Positive/Transition) has 3 distinct clusters\")\n",
    "    print(\"• Clusters represent different 'subtypes' or 'patterns' within each state\")\n",
    "    print(\"• Lower inertia = more compact, well-separated clusters\")\n",
    "    print(\"• In UMAP plots, look for:\")\n",
    "    print(\"  - Tight clusters = consistent activation patterns\")  \n",
    "    print(\"  - Scattered points = diverse activation patterns\")\n",
    "    print(\"  - Cluster separation = how distinct the subtypes are\")\n",
    "\n",
    "def perform_hdbscan_analysis(neg_data, pos_data, trans_data, layer=17, min_cluster_size=50, max_samples=1500):\n",
    "    \"\"\"\n",
    "    Perform HDBSCAN clustering on each cognitive state separately\n",
    "    \"\"\"\n",
    "    print(f\"\\n🌳 HDBSCAN ANALYSIS (Hierarchical density-based clustering)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Parameters: min_cluster_size={min_cluster_size}, max_samples={max_samples}\")\n",
    "    \n",
    "    # Prepare data for each state (same as K-means)\n",
    "    def prepare_state_data(data, state_name, max_samples):\n",
    "        if data.shape[0] * data.shape[1] > max_samples:\n",
    "            data_flat = data[:, ::8, :].reshape(-1, data.shape[-1])\n",
    "        else:\n",
    "            data_flat = data.reshape(-1, data.shape[-1])\n",
    "        \n",
    "        if len(data_flat) > max_samples:\n",
    "            indices = torch.randperm(len(data_flat))[:max_samples]\n",
    "            data_flat = data_flat[indices]\n",
    "            \n",
    "        return data_flat.cpu().numpy()\n",
    "    \n",
    "    # Prepare data for each cognitive state\n",
    "    neg_flat = prepare_state_data(neg_data, \"Negative\", max_samples)\n",
    "    pos_flat = prepare_state_data(pos_data, \"Positive\", max_samples)\n",
    "    trans_flat = prepare_state_data(trans_data, \"Transition\", max_samples)\n",
    "    \n",
    "    print(f\"Data shapes - Neg: {neg_flat.shape}, Pos: {pos_flat.shape}, Trans: {trans_flat.shape}\")\n",
    "    \n",
    "    # Standardize data\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Perform HDBSCAN on each state separately\n",
    "    states_data = {\n",
    "        'Negative': neg_flat,\n",
    "        'Positive': pos_flat, \n",
    "        'Transition': trans_flat\n",
    "    }\n",
    "    \n",
    "    clustered_data = {}\n",
    "    cluster_results = {}\n",
    "    \n",
    "    for state_name, data in states_data.items():\n",
    "        print(f\"\\n🎯 HDBSCAN clustering {state_name} state ({data.shape[0]} samples)...\")\n",
    "        \n",
    "        # Standardize the data\n",
    "        data_scaled = scaler.fit_transform(data)\n",
    "        \n",
    "        # Perform HDBSCAN clustering\n",
    "        hdbscan_model = hdbscan.HDBSCAN(\n",
    "            min_cluster_size=min_cluster_size,\n",
    "            min_samples=10,\n",
    "            cluster_selection_epsilon=0.0,\n",
    "            metric='euclidean',\n",
    "            cluster_selection_method='eom'  # Excess of Mass\n",
    "        )\n",
    "        \n",
    "        cluster_labels = hdbscan_model.fit_predict(data_scaled)\n",
    "        \n",
    "        # Store results\n",
    "        clustered_data[state_name] = {\n",
    "            'data': data,\n",
    "            'data_scaled': data_scaled,\n",
    "            'cluster_labels': cluster_labels,\n",
    "            'hdbscan_model': hdbscan_model\n",
    "        }\n",
    "        \n",
    "        # Print cluster statistics\n",
    "        unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "        n_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)\n",
    "        n_noise = counts[unique_labels == -1][0] if -1 in unique_labels else 0\n",
    "        \n",
    "        print(f\"  Found {n_clusters} clusters\")\n",
    "        print(f\"  Noise points: {n_noise} ({n_noise/len(cluster_labels)*100:.1f}%)\")\n",
    "        \n",
    "        for cluster_id, count in zip(unique_labels, counts):\n",
    "            if cluster_id == -1:\n",
    "                print(f\"  Noise: {count:4d} samples ({count/len(cluster_labels)*100:5.1f}%)\")\n",
    "            else:\n",
    "                print(f\"  Cluster {cluster_id}: {count:4d} samples ({count/len(cluster_labels)*100:5.1f}%)\")\n",
    "        \n",
    "        # Calculate silhouette score (excluding noise points)\n",
    "        if n_clusters > 1:\n",
    "            non_noise_mask = cluster_labels != -1\n",
    "            if np.sum(non_noise_mask) > 1:\n",
    "                silhouette_avg = silhouette_score(data_scaled[non_noise_mask], \n",
    "                                                cluster_labels[non_noise_mask])\n",
    "                print(f\"  Silhouette score: {silhouette_avg:.3f}\")\n",
    "        \n",
    "        cluster_results[state_name] = {\n",
    "            'cluster_labels': cluster_labels,\n",
    "            'n_clusters': n_clusters,\n",
    "            'n_noise': n_noise,\n",
    "            'cluster_probabilities': hdbscan_model.probabilities_ if hasattr(hdbscan_model, 'probabilities_') else None\n",
    "        }\n",
    "    \n",
    "    # Compute UMAP on combined data\n",
    "    combined_data = np.vstack([neg_flat, pos_flat, trans_flat])\n",
    "    combined_labels = (['Negative'] * len(neg_flat) + \n",
    "                      ['Positive'] * len(pos_flat) + \n",
    "                      ['Transition'] * len(trans_flat))\n",
    "    \n",
    "    # Create detailed cluster labels and colors for HDBSCAN\n",
    "    detailed_labels = []\n",
    "    cluster_colors = []\n",
    "    \n",
    "    # Generate colors dynamically based on number of clusters found\n",
    "    def generate_colors(n_clusters, base_color):\n",
    "        \"\"\"Generate n_clusters different shades of base_color\"\"\"\n",
    "        import colorsys\n",
    "        colors = []\n",
    "        if base_color == 'red':\n",
    "            base_hue = 0.0\n",
    "        elif base_color == 'green':\n",
    "            base_hue = 0.33\n",
    "        else:  # blue\n",
    "            base_hue = 0.67\n",
    "        \n",
    "        for i in range(n_clusters):\n",
    "            # Vary saturation and lightness\n",
    "            sat = 0.7 + 0.3 * (i / max(1, n_clusters-1))\n",
    "            light = 0.3 + 0.4 * (i / max(1, n_clusters-1))\n",
    "            rgb = colorsys.hsv_to_rgb(base_hue, sat, light)\n",
    "            colors.append(f'rgb({int(rgb[0]*255)},{int(rgb[1]*255)},{int(rgb[2]*255)})')\n",
    "        \n",
    "        # Add noise color (gray)\n",
    "        colors.append('#808080')\n",
    "        return colors\n",
    "    \n",
    "    # Build combined labels and colors\n",
    "    for state_name, base_color in [('Negative', 'red'), ('Positive', 'green'), ('Transition', 'blue')]:\n",
    "        state_clusters = clustered_data[state_name]['cluster_labels']\n",
    "        n_clusters = cluster_results[state_name]['n_clusters']\n",
    "        state_colors = generate_colors(n_clusters, base_color)\n",
    "        \n",
    "        for cluster_id in state_clusters:\n",
    "            if cluster_id == -1:\n",
    "                detailed_labels.append(f\"{state_name}_Noise\")\n",
    "                cluster_colors.append(state_colors[-1])  # Gray for noise\n",
    "            else:\n",
    "                detailed_labels.append(f\"{state_name}_Cluster_{cluster_id}\")\n",
    "                cluster_colors.append(state_colors[cluster_id % len(state_colors)])\n",
    "    \n",
    "    print(f\"\\n🗺️  Computing UMAP for {len(combined_data)} total samples...\")\n",
    "    \n",
    "    # Compute UMAP\n",
    "    umap_2d = umap.UMAP(n_components=2, random_state=42, \n",
    "                       n_neighbors=min(15, len(combined_data)//3), \n",
    "                       min_dist=0.1, n_jobs=1)\n",
    "    embedding_2d = umap_2d.fit_transform(combined_data)\n",
    "    \n",
    "    umap_3d = umap.UMAP(n_components=3, random_state=42,\n",
    "                       n_neighbors=min(15, len(combined_data)//3),\n",
    "                       min_dist=0.1, n_jobs=1)\n",
    "    embedding_3d = umap_3d.fit_transform(combined_data)\n",
    "    \n",
    "    return {\n",
    "        'embedding_2d': embedding_2d,\n",
    "        'embedding_3d': embedding_3d,\n",
    "        'combined_data': combined_data,\n",
    "        'detailed_labels': detailed_labels,\n",
    "        'cluster_colors': cluster_colors,\n",
    "        'clustered_data': clustered_data,\n",
    "        'cluster_results': cluster_results,\n",
    "        'state_labels': combined_labels,\n",
    "        'algorithm': 'HDBSCAN'\n",
    "    }\n",
    "\n",
    "def plot_hdbscan_umap(clustering_results, title_prefix=\"HDBSCAN_Clustered\"):\n",
    "    \"\"\"\n",
    "    Create UMAP plots showing HDBSCAN cluster assignments\n",
    "    \"\"\"\n",
    "    embedding_2d = clustering_results['embedding_2d']\n",
    "    embedding_3d = clustering_results['embedding_3d']\n",
    "    detailed_labels = clustering_results['detailed_labels']\n",
    "    cluster_colors = clustering_results['cluster_colors']\n",
    "    \n",
    "    print(f\"\\n🎨 Creating HDBSCAN UMAP visualizations...\")\n",
    "    \n",
    "    # Create 2D plot\n",
    "    fig_2d = go.Figure()\n",
    "    \n",
    "    # Group by detailed cluster labels for legend\n",
    "    unique_detailed_labels = list(set(detailed_labels))\n",
    "    # Sort to put noise at the end\n",
    "    unique_detailed_labels.sort(key=lambda x: (x.endswith('_Noise'), x))\n",
    "    \n",
    "    for label in unique_detailed_labels:\n",
    "        mask = [l == label for l in detailed_labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            \n",
    "            # Extract state and cluster info for hover\n",
    "            if label.endswith('_Noise'):\n",
    "                state = label.split('_')[0]\n",
    "                display_name = f\"{state} Noise\"\n",
    "                hover_text = f\"<b>{state} Noise Point</b>\"\n",
    "                marker_size = 3\n",
    "                opacity = 0.4\n",
    "            else:\n",
    "                state = label.split('_')[0]\n",
    "                cluster_id = label.split('_')[-1]\n",
    "                display_name = f\"{state} C{cluster_id}\"\n",
    "                hover_text = f\"<b>{state} Cluster {cluster_id}</b>\"\n",
    "                marker_size = 4\n",
    "                opacity = 0.7\n",
    "            \n",
    "            fig_2d.add_trace(go.Scatter(\n",
    "                x=embedding_2d[indices, 0],\n",
    "                y=embedding_2d[indices, 1],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=cluster_colors[indices[0]],\n",
    "                    size=marker_size,\n",
    "                    opacity=opacity,\n",
    "                    line=dict(width=0.5, color='white')\n",
    "                ),\n",
    "                name=display_name,\n",
    "                hovertemplate=f'{hover_text}<br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_2d.update_layout(\n",
    "        title=f'{title_prefix} - 2D UMAP with HDBSCAN Clusters',\n",
    "        xaxis_title='UMAP 1',\n",
    "        yaxis_title='UMAP 2',\n",
    "        width=900,\n",
    "        height=700,\n",
    "        showlegend=True,\n",
    "        hovermode='closest',\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\",\n",
    "            y=1,\n",
    "            xanchor=\"left\",\n",
    "            x=1.02\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig_3d = go.Figure()\n",
    "    \n",
    "    for label in unique_detailed_labels:\n",
    "        mask = [l == label for l in detailed_labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            \n",
    "            if label.endswith('_Noise'):\n",
    "                state = label.split('_')[0]\n",
    "                display_name = f\"{state} Noise\"\n",
    "                hover_text = f\"<b>{state} Noise Point</b>\"\n",
    "                marker_size = 2\n",
    "                opacity = 0.4\n",
    "            else:\n",
    "                state = label.split('_')[0]\n",
    "                cluster_id = label.split('_')[-1]\n",
    "                display_name = f\"{state} C{cluster_id}\"\n",
    "                hover_text = f\"<b>{state} Cluster {cluster_id}</b>\"\n",
    "                marker_size = 3\n",
    "                opacity = 0.7\n",
    "            \n",
    "            fig_3d.add_trace(go.Scatter3d(\n",
    "                x=embedding_3d[indices, 0],\n",
    "                y=embedding_3d[indices, 1],\n",
    "                z=embedding_3d[indices, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=cluster_colors[indices[0]],\n",
    "                    size=marker_size,\n",
    "                    opacity=opacity,\n",
    "                    line=dict(width=0.5, color='white')\n",
    "                ),\n",
    "                name=display_name,\n",
    "                hovertemplate=f'{hover_text}<br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<br>UMAP 3: %{{z:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_3d.update_layout(\n",
    "        title=f'{title_prefix} - 3D UMAP with HDBSCAN Clusters',\n",
    "        scene=dict(\n",
    "            xaxis_title='UMAP 1',\n",
    "            yaxis_title='UMAP 2',\n",
    "            zaxis_title='UMAP 3'\n",
    "        ),\n",
    "        width=900,\n",
    "        height=700,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Save and open plots\n",
    "    safe_title = title_prefix.replace(\" \", \"_\").replace(\"-\", \"\").strip(\"_\")\n",
    "    filename_2d = f\"umap_2d_hdbscan_{safe_title}_{hash(str(embedding_2d.tolist())) % 10000}.html\"\n",
    "    filename_3d = f\"umap_3d_hdbscan_{safe_title}_{hash(str(embedding_3d.tolist())) % 10000}.html\"\n",
    "    \n",
    "    fig_2d.write_html(filename_2d, auto_open=False)\n",
    "    fig_3d.write_html(filename_3d, auto_open=False)\n",
    "    \n",
    "    print(f\"Opening HDBSCAN 2D plot: {filename_2d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_2d)}', new=2)\n",
    "    \n",
    "    print(f\"Opening HDBSCAN 3D plot: {filename_3d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_3d)}', new=2)\n",
    "    \n",
    "    fig_2d.show()\n",
    "    fig_3d.show()\n",
    "    \n",
    "    return fig_2d, fig_3d\n",
    "\n",
    "def analyze_hdbscan_characteristics(clustering_results):\n",
    "    \"\"\"\n",
    "    Analyze and print characteristics of HDBSCAN clusters\n",
    "    \"\"\"\n",
    "    print(f\"\\n📊 HDBSCAN CLUSTER ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    clustered_data = clustering_results['clustered_data']\n",
    "    cluster_results = clustering_results['cluster_results']\n",
    "    \n",
    "    for state_name, data_info in clustered_data.items():\n",
    "        print(f\"\\n🔍 {state_name.upper()} STATE HDBSCAN CLUSTERS:\")\n",
    "        \n",
    "        cluster_labels = data_info['cluster_labels']\n",
    "        n_clusters = cluster_results[state_name]['n_clusters']\n",
    "        n_noise = cluster_results[state_name]['n_noise']\n",
    "        \n",
    "        print(f\"  Found {n_clusters} natural clusters\")\n",
    "        print(f\"  Noise points: {n_noise} ({n_noise/len(cluster_labels)*100:.1f}%)\")\n",
    "        \n",
    "        unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "        total_samples = len(cluster_labels)\n",
    "        \n",
    "        for cluster_id, count in zip(unique_labels, counts):\n",
    "            percentage = (count / total_samples) * 100\n",
    "            if cluster_id == -1:\n",
    "                print(f\"    Noise: {count:4d} samples ({percentage:5.1f}%)\")\n",
    "            else:\n",
    "                print(f\"    Cluster {cluster_id}: {count:4d} samples ({percentage:5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n💡 HDBSCAN INTERPRETATION GUIDE:\")\n",
    "    print(\"• HDBSCAN finds natural clusters without pre-specifying the number\")\n",
    "    print(\"• Noise points = outliers that don't belong to any cluster\")\n",
    "    print(\"• Varying cluster sizes = different cognitive patterns have different prevalence\")\n",
    "    print(\"• Hierarchical structure = clusters can have sub-clusters\")\n",
    "    print(\"• In UMAP plots, look for:\")\n",
    "    print(\"  - Dense clusters = strong, consistent patterns\")\n",
    "    print(\"  - Noise points (gray) = unique or transitional states\")\n",
    "    print(\"  - Cluster boundaries = natural separations in the data\")\n",
    "\n",
    "print(\"🔍 UMAP Analysis of Cognitive Transformations\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "699c4d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Full Dataset UMAP (all patterns)\n",
      "Full data shapes - Neg: torch.Size([520, 208, 2304]), Pos: torch.Size([520, 261, 2304]), Trans: torch.Size([520, 311, 2304])\n",
      "Combined data shape: (3000, 2304)\n",
      "Computing UMAP for 3000 samples...\n",
      "Opening 2D plot: umap_2d_Full_Dataset_9021.html\n",
      "Opening 3D plot: umap_3d_Full_Dataset_7055.html\n"
     ]
    }
   ],
   "source": [
    "# 1. Full dataset UMAP (all patterns, all tokens subsampled)\n",
    "print(\"\\n1. Full Dataset UMAP (all patterns)\")\n",
    "all_indices = [i for indices_list in pattern_indices.values() for i in indices_list]\n",
    "neg_all = negative_activations[f'negative_layer_{layer}'][all_indices]\n",
    "pos_all = positive_activations[f'positive_layer_{layer}'][all_indices]\n",
    "trans_all = transition_activations[f'transition_layer_{layer}'][all_indices]\n",
    "\n",
    "print(f\"Full data shapes - Neg: {neg_all.shape}, Pos: {pos_all.shape}, Trans: {trans_all.shape}\")\n",
    "\n",
    "data_all, labels_all, colors_all = prepare_data_for_umap(neg_all, pos_all, trans_all)\n",
    "print(f\"Combined data shape: {data_all.shape}\")\n",
    "\n",
    "embedding_2d_all, embedding_3d_all = plot_umap_2d_3d(data_all, labels_all, colors_all, \"Full Dataset - \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde4b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Single Pattern UMAP: Executive Fatigue & Avolition\n",
      "Single pattern data shapes - Neg: torch.Size([40, 208, 2304]), Pos: torch.Size([40, 261, 2304]), Trans: torch.Size([40, 311, 2304])\n",
      "Computing UMAP for 3000 samples...\n",
      "Opening 2D plot: umap_2d_Executive_Fatigue_&_Avolition_3466.html\n",
      "Opening 3D plot: umap_3d_Executive_Fatigue_&_Avolition_2827.html\n"
     ]
    }
   ],
   "source": [
    "# 2. Single cognitive pattern UMAP\n",
    "print(f\"\\n2. Single Pattern UMAP: {first_pattern}\")\n",
    "indices = pattern_indices[first_pattern]\n",
    "neg_single = negative_activations[f'negative_layer_{layer}'][indices]\n",
    "pos_single = positive_activations[f'positive_layer_{layer}'][indices]\n",
    "trans_single = transition_activations[f'transition_layer_{layer}'][indices]\n",
    "\n",
    "print(f\"Single pattern data shapes - Neg: {neg_single.shape}, Pos: {pos_single.shape}, Trans: {trans_single.shape}\")\n",
    "\n",
    "data_single, labels_single, colors_single = prepare_data_for_umap(neg_single, pos_single, trans_single)\n",
    "embedding_2d_single, embedding_3d_single = plot_umap_2d_3d(data_single, labels_single, colors_single, f\"{first_pattern} - \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48028e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Last Token Only UMAP: Executive Fatigue & Avolition\n",
      "Last token shapes - Neg: torch.Size([40, 1, 2304]), Pos: torch.Size([40, 1, 2304]), Trans: torch.Size([40, 1, 2304])\n",
      "Computing UMAP for 120 samples...\n",
      "Opening 2D plot: umap_2d_Last_Token_Only_7531.html\n",
      "Opening 3D plot: umap_3d_Last_Token_Only_3571.html\n",
      "\n",
      "✅ UMAP Analysis Complete!\n",
      "📊 Analyzed 520 total samples across 13 cognitive patterns\n",
      "🎯 Single pattern 'Executive Fatigue & Avolition' had 40 samples\n",
      "🔬 Layer 17 activations visualized in 2D and 3D space\n"
     ]
    }
   ],
   "source": [
    "# 3. Last token only UMAP (single pattern)\n",
    "print(f\"\\n3. Last Token Only UMAP: {first_pattern}\")\n",
    "neg_last = neg_single[:, -1, :].unsqueeze(1)  # Keep token dimension\n",
    "pos_last = pos_single[:, -1, :].unsqueeze(1)\n",
    "trans_last = trans_single[:, -1, :].unsqueeze(1)\n",
    "\n",
    "print(f\"Last token shapes - Neg: {neg_last.shape}, Pos: {pos_last.shape}, Trans: {trans_last.shape}\")\n",
    "\n",
    "data_last, labels_last, colors_last = prepare_data_for_umap(neg_last, pos_last, trans_last, subsample_tokens=False)\n",
    "embedding_2d_last, embedding_3d_last = plot_umap_2d_3d(data_last, labels_last, colors_last, \"Last Token Only - \")\n",
    "\n",
    "print(\"\\n✅ UMAP Analysis Complete!\")\n",
    "print(f\"📊 Analyzed {len(all_indices)} total samples across {len(pattern_indices)} cognitive patterns\")\n",
    "print(f\"🎯 Single pattern '{first_pattern}' had {len(indices)} samples\")\n",
    "print(f\"🔬 Layer {layer} activations visualized in 2D and 3D space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c60f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Depressive Dataset Only UMAP (all cognitive patterns, negative tokens only)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🔴 FILTERED VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show available patterns first\n",
    "print(f\"\\n📋 Available Cognitive Patterns ({len(pattern_indices)} total):\")\n",
    "for i, pattern in enumerate(list(pattern_indices.keys())[:8]):  # Show first 8\n",
    "    count = len(pattern_indices[pattern])\n",
    "    print(f\"  {i+1}. {pattern} ({count} examples)\")\n",
    "if len(pattern_indices) > 8:\n",
    "    print(f\"  ... and {len(pattern_indices) - 8} more patterns\")\n",
    "\n",
    "# Visualize only depressive (negative) tokens across all patterns\n",
    "embedding_2d_depressive, embedding_3d_depressive = plot_depressive_only_umap(layer=layer, max_samples=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3060214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Analyzing single pattern: 'Executive Fatigue & Avolition'\n",
      "\n",
      "🎯 Single Pattern UMAP: Executive Fatigue & Avolition (all examples)\n",
      "Pattern data shapes - Neg: torch.Size([40, 208, 2304]), Pos: torch.Size([40, 261, 2304]), Trans: torch.Size([40, 311, 2304])\n",
      "Computing UMAP for 3000 samples...\n",
      "Opening 2D plot: umap_2d_Executive_Fatigue_&_Avolition_AllExamples_7854.html\n",
      "Opening 3D plot: umap_3d_Executive_Fatigue_&_Avolition_AllExamples_4865.html\n"
     ]
    }
   ],
   "source": [
    "# 5. Single Cognitive Pattern UMAP (all examples: negative, positive, transition)\n",
    "selected_pattern = list(pattern_indices.keys())[0]  # Use first pattern\n",
    "print(f\"\\n🎯 Analyzing single pattern: '{selected_pattern}'\")\n",
    "\n",
    "# You can change this to any pattern name from the list above\n",
    "# selected_pattern = \"catastrophizing\"  # Example: uncomment and change to analyze a specific pattern\n",
    "\n",
    "embedding_2d_pattern, embedding_3d_pattern = plot_single_pattern_all_examples(\n",
    "    pattern_name=selected_pattern, \n",
    "    layer=layer, \n",
    "    max_samples=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9289322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Analyzing single example from 'Executive Fatigue & Avolition' (example 0)\n",
      "\n",
      "🔬 Single Example UMAP: Executive Fatigue & Avolition (example 0)\n",
      "Single example shapes - Neg: torch.Size([1, 208, 2304]), Pos: torch.Size([1, 261, 2304]), Trans: torch.Size([1, 311, 2304])\n",
      "Combined single example data shape: (780, 2304)\n",
      "Computing UMAP for 780 tokens from single example...\n",
      "Opening single example 2D plot: umap_2d_single_example_Executive_Fatigue_&_Avolition_0_5260.html\n",
      "Opening single example 3D plot: umap_3d_single_example_Executive_Fatigue_&_Avolition_0_9102.html\n"
     ]
    }
   ],
   "source": [
    "# 6. Single Example UMAP (just one example from one pattern - all its tokens)\n",
    "example_idx = 0  # First example\n",
    "print(f\"\\n🔬 Analyzing single example from '{selected_pattern}' (example {example_idx})\")\n",
    "\n",
    "# This shows how tokens flow through the transformation within a single narrative\n",
    "# You can change example_idx to analyze different examples (0, 1, 2, etc.)\n",
    "\n",
    "embedding_2d_example, embedding_3d_example = plot_single_example(\n",
    "    pattern_name=selected_pattern,\n",
    "    example_idx=example_idx,\n",
    "    layer=layer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e04040e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📊 ANALYSIS COMPLETE - INTERPRETATION GUIDE\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'selected_pattern' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m📊 ANALYSIS COMPLETE - INTERPRETATION GUIDE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m🔍 **What You\u001b[39m\u001b[33m'\u001b[39m\u001b[33mve Visualized:**\u001b[39m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[33m1. **Full Dataset UMAP** - Overview of all cognitive patterns\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m   - Shows general clustering of negative vs positive vs transition states\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m   - Reveals global structure across all \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pattern_indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cognitive patterns\u001b[39m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[33m2. **Depressive Dataset Only** - Pure negative emotional states  \u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m   - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_2d_depressive.shape[\u001b[32m0\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33membedding_2d_depressive\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlocals\u001b[39m()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m depressive tokens visualized\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m   - Shows internal structure of negative thought patterns\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m   - Look for clusters that might represent different types of depressive thinking\u001b[39m\n\u001b[32m     17\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[33m3. **Single Pattern Analysis** - Focus on \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mselected_pattern\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[33m   - All examples of this specific cognitive pattern\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[33m   - Shows how this pattern manifests across negative → positive → transition\u001b[39m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[33m4. **Single Example Analysis** - Micro-level view\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m   - Individual narrative token progression  \u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m   - Shows the transformation journey within one story\u001b[39m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33m🎯 **How to Use These Visualizations:**\u001b[39m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[33m• **Clusters** = Similar activation patterns (similar \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthoughts\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33m• **Distance** = How different the neural representations are  \u001b[39m\n\u001b[32m     30\u001b[39m \u001b[33m• **Transitions** = Look for paths between negative and positive regions\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[33m• **Outliers** = Unusual or unique activation patterns\u001b[39m\n\u001b[32m     32\u001b[39m \n\u001b[32m     33\u001b[39m \u001b[33m🔧 **Customization Options:**\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m# To analyze a different pattern:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m# selected_pattern = \u001b[39m\u001b[33m'\u001b[39m\u001b[33myour_pattern_name_here\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'selected_pattern' is not defined"
     ]
    }
   ],
   "source": [
    "# 7. Summary and Analysis Guide\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 ANALYSIS COMPLETE - INTERPRETATION GUIDE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "🔍 **What You've Visualized:**\n",
    "\n",
    "1. **Full Dataset UMAP** - Overview of all cognitive patterns\n",
    "   - Shows general clustering of negative vs positive vs transition states\n",
    "   - Reveals global structure across all {len(pattern_indices)} cognitive patterns\n",
    "\n",
    "2. **Depressive Dataset Only** - Pure negative emotional states  \n",
    "   - {embedding_2d_depressive.shape[0] if 'embedding_2d_depressive' in locals() else 'N/A'} depressive tokens visualized\n",
    "   - Shows internal structure of negative thought patterns\n",
    "   - Look for clusters that might represent different types of depressive thinking\n",
    "\n",
    "3. **Single Pattern Analysis** - Focus on '{selected_pattern}'\n",
    "   - All examples of this specific cognitive pattern\n",
    "   - Shows how this pattern manifests across negative → positive → transition\n",
    "\n",
    "4. **Single Example Analysis** - Micro-level view\n",
    "   - Individual narrative token progression  \n",
    "   - Shows the transformation journey within one story\n",
    "\n",
    "🎯 **How to Use These Visualizations:**\n",
    "\n",
    "• **Clusters** = Similar activation patterns (similar \"thoughts\")\n",
    "• **Distance** = How different the neural representations are  \n",
    "• **Transitions** = Look for paths between negative and positive regions\n",
    "• **Outliers** = Unusual or unique activation patterns\n",
    "\n",
    "🔧 **Customization Options:**\n",
    "\"\"\")\n",
    "\n",
    "print(\"# To analyze a different pattern:\")\n",
    "print(\"# selected_pattern = 'your_pattern_name_here'\")\n",
    "print(\"# embedding_2d, embedding_3d = plot_single_pattern_all_examples(selected_pattern)\")\n",
    "print()\n",
    "print(\"# To analyze a different example:\")  \n",
    "print(\"# embedding_2d, embedding_3d = plot_single_example('pattern_name', example_idx=5)\")\n",
    "print()\n",
    "print(\"# To focus on a different layer:\")\n",
    "print(\"# plot_depressive_only_umap(layer=15)  # Try layers 10-20\")\n",
    "\n",
    "print(f\"\\n✅ All visualizations saved as HTML files and opened in browser tabs!\")\n",
    "print(f\"📁 Check your current directory for the generated .html files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cabb14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🔬 CLUSTERING ANALYSIS - Finding Subtypes Within Each Cognitive State\n",
      "======================================================================\n",
      "🔍 Performing K-means clustering (3 clusters per cognitive state)\n",
      "Data shapes - Neg: torch.Size([520, 208, 2304]), Pos: torch.Size([520, 261, 2304]), Trans: torch.Size([520, 311, 2304])\n",
      "\n",
      "🔬 CLUSTERING ANALYSIS (K-means with 3 clusters per state)\n",
      "======================================================================\n",
      "Data shapes - Neg: (1500, 2304), Pos: (1500, 2304), Trans: (1500, 2304)\n",
      "\n",
      "🎯 Clustering Negative state (1500 samples)...\n",
      "  Cluster distribution: {0: 1079, 1: 58, 2: 363}\n",
      "\n",
      "🎯 Clustering Positive state (1500 samples)...\n",
      "  Cluster distribution: {0: 946, 1: 534, 2: 20}\n",
      "\n",
      "🎯 Clustering Transition state (1500 samples)...\n",
      "  Cluster distribution: {0: 394, 1: 1104, 2: 2}\n",
      "\n",
      "🗺️  Computing UMAP for 4500 total samples...\n"
     ]
    }
   ],
   "source": [
    "# 8. K-MEANS CLUSTERING ANALYSIS\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🔬 CLUSTERING ANALYSIS - Finding Subtypes Within Each Cognitive State\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Perform clustering analysis on full dataset\n",
    "all_indices = [i for indices_list in pattern_indices.values() for i in indices_list]\n",
    "neg_all_cluster = negative_activations[f'negative_layer_{layer}'][all_indices]\n",
    "pos_all_cluster = positive_activations[f'positive_layer_{layer}'][all_indices]\n",
    "trans_all_cluster = transition_activations[f'transition_layer_{layer}'][all_indices]\n",
    "\n",
    "print(f\"🔍 Performing K-means clustering (3 clusters per cognitive state)\")\n",
    "print(f\"Data shapes - Neg: {neg_all_cluster.shape}, Pos: {pos_all_cluster.shape}, Trans: {trans_all_cluster.shape}\")\n",
    "\n",
    "# Perform clustering analysis\n",
    "clustering_results = perform_clustering_analysis(\n",
    "    neg_all_cluster, \n",
    "    pos_all_cluster, \n",
    "    trans_all_cluster,\n",
    "    layer=layer,\n",
    "    n_clusters=3,\n",
    "    max_samples=1500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "300b4303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎨 Creating interactive UMAP plots with cluster assignments...\n",
      "\n",
      "🎨 Creating clustered UMAP visualizations...\n",
      "Opening clustered 2D plot: umap_2d_clustered_Full_Dataset_Clustered_5680.html\n",
      "Opening clustered 3D plot: umap_3d_clustered_Full_Dataset_Clustered_4791.html\n",
      "\n",
      "📊 CLUSTER ANALYSIS SUMMARY\n",
      "==================================================\n",
      "\n",
      "🔍 NEGATIVE STATE CLUSTERS:\n",
      "  Cluster 0: 1079 samples ( 71.9%)\n",
      "  Cluster 1:   58 samples (  3.9%)\n",
      "  Cluster 2:  363 samples ( 24.2%)\n",
      "  Total inertia (within-cluster sum of squares): 3086096.75\n",
      "\n",
      "🔍 POSITIVE STATE CLUSTERS:\n",
      "  Cluster 0:  946 samples ( 63.1%)\n",
      "  Cluster 1:  534 samples ( 35.6%)\n",
      "  Cluster 2:   20 samples (  1.3%)\n",
      "  Total inertia (within-cluster sum of squares): 3213893.00\n",
      "\n",
      "🔍 TRANSITION STATE CLUSTERS:\n",
      "  Cluster 0:  394 samples ( 26.3%)\n",
      "  Cluster 1: 1104 samples ( 73.6%)\n",
      "  Cluster 2:    2 samples (  0.1%)\n",
      "  Total inertia (within-cluster sum of squares): 3274455.00\n",
      "\n",
      "💡 INTERPRETATION GUIDE:\n",
      "• Each cognitive state (Negative/Positive/Transition) has 3 distinct clusters\n",
      "• Clusters represent different 'subtypes' or 'patterns' within each state\n",
      "• Lower inertia = more compact, well-separated clusters\n",
      "• In UMAP plots, look for:\n",
      "  - Tight clusters = consistent activation patterns\n",
      "  - Scattered points = diverse activation patterns\n",
      "  - Cluster separation = how distinct the subtypes are\n"
     ]
    }
   ],
   "source": [
    "# 9. Visualize Clustered Results\n",
    "print(\"\\n🎨 Creating interactive UMAP plots with cluster assignments...\")\n",
    "\n",
    "# Create clustered UMAP plots\n",
    "fig_2d_clustered, fig_3d_clustered = plot_clustered_umap(\n",
    "    clustering_results, \n",
    "    title_prefix=\"Full_Dataset_Clustered\"\n",
    ")\n",
    "\n",
    "# Analyze cluster characteristics\n",
    "analyze_cluster_characteristics(clustering_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e26265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🎯 SINGLE PATTERN CLUSTERING ANALYSIS\n",
      "============================================================\n",
      "Analyzing clustering within pattern: 'Executive Fatigue & Avolition'\n",
      "Single pattern data shapes - Neg: torch.Size([40, 208, 2304]), Pos: torch.Size([40, 261, 2304]), Trans: torch.Size([40, 311, 2304])\n",
      "\n",
      "🔬 CLUSTERING ANALYSIS (K-means with 3 clusters per state)\n",
      "======================================================================\n",
      "Data shapes - Neg: (800, 2304), Pos: (800, 2304), Trans: (800, 2304)\n",
      "\n",
      "🎯 Clustering Negative state (800 samples)...\n",
      "  Cluster distribution: {0: 16, 1: 752, 2: 32}\n",
      "\n",
      "🎯 Clustering Positive state (800 samples)...\n",
      "  Cluster distribution: {0: 159, 1: 538, 2: 103}\n",
      "\n",
      "🎯 Clustering Transition state (800 samples)...\n",
      "  Cluster distribution: {0: 776, 1: 23, 2: 1}\n",
      "\n",
      "🗺️  Computing UMAP for 2400 total samples...\n",
      "\n",
      "🎨 Creating clustered UMAP visualizations...\n",
      "Opening clustered 2D plot: umap_2d_clustered_Executive_Fatigue_&_Avolition_Clustered_3477.html\n",
      "Opening clustered 3D plot: umap_3d_clustered_Executive_Fatigue_&_Avolition_Clustered_3949.html\n",
      "\n",
      "📊 CLUSTER ANALYSIS SUMMARY\n",
      "==================================================\n",
      "\n",
      "🔍 NEGATIVE STATE CLUSTERS:\n",
      "  Cluster 0:   16 samples (  2.0%)\n",
      "  Cluster 1:  752 samples ( 94.0%)\n",
      "  Cluster 2:   32 samples (  4.0%)\n",
      "  Total inertia (within-cluster sum of squares): 1648803.88\n",
      "\n",
      "🔍 POSITIVE STATE CLUSTERS:\n",
      "  Cluster 0:  159 samples ( 19.9%)\n",
      "  Cluster 1:  538 samples ( 67.2%)\n",
      "  Cluster 2:  103 samples ( 12.9%)\n",
      "  Total inertia (within-cluster sum of squares): 1633632.88\n",
      "\n",
      "🔍 TRANSITION STATE CLUSTERS:\n",
      "  Cluster 0:  776 samples ( 97.0%)\n",
      "  Cluster 1:   23 samples (  2.9%)\n",
      "  Cluster 2:    1 samples (  0.1%)\n",
      "  Total inertia (within-cluster sum of squares): 1765807.75\n",
      "\n",
      "💡 INTERPRETATION GUIDE:\n",
      "• Each cognitive state (Negative/Positive/Transition) has 3 distinct clusters\n",
      "• Clusters represent different 'subtypes' or 'patterns' within each state\n",
      "• Lower inertia = more compact, well-separated clusters\n",
      "• In UMAP plots, look for:\n",
      "  - Tight clusters = consistent activation patterns\n",
      "  - Scattered points = diverse activation patterns\n",
      "  - Cluster separation = how distinct the subtypes are\n"
     ]
    }
   ],
   "source": [
    "# 10. Single Pattern Clustering Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎯 SINGLE PATTERN CLUSTERING ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze clustering within a specific cognitive pattern\n",
    "selected_pattern_cluster = list(pattern_indices.keys())[0]\n",
    "print(f\"Analyzing clustering within pattern: '{selected_pattern_cluster}'\")\n",
    "\n",
    "indices_cluster = pattern_indices[selected_pattern_cluster]\n",
    "neg_single_cluster = negative_activations[f'negative_layer_{layer}'][indices_cluster]\n",
    "pos_single_cluster = positive_activations[f'positive_layer_{layer}'][indices_cluster]\n",
    "trans_single_cluster = transition_activations[f'transition_layer_{layer}'][indices_cluster]\n",
    "\n",
    "print(f\"Single pattern data shapes - Neg: {neg_single_cluster.shape}, Pos: {pos_single_cluster.shape}, Trans: {trans_single_cluster.shape}\")\n",
    "\n",
    "# Perform clustering on single pattern\n",
    "single_pattern_clustering = perform_clustering_analysis(\n",
    "    neg_single_cluster,\n",
    "    pos_single_cluster, \n",
    "    trans_single_cluster,\n",
    "    layer=layer,\n",
    "    n_clusters=3,\n",
    "    max_samples=800\n",
    ")\n",
    "\n",
    "# Visualize single pattern clustering\n",
    "fig_2d_single_clustered, fig_3d_single_clustered = plot_clustered_umap(\n",
    "    single_pattern_clustering,\n",
    "    title_prefix=f\"{selected_pattern_cluster}_Clustered\"\n",
    ")\n",
    "\n",
    "# Analyze single pattern clusters\n",
    "analyze_cluster_characteristics(single_pattern_clustering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb03b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Final Summary - Clustering Analysis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📊 CLUSTERING ANALYSIS COMPLETE - RESEARCH INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "🔬 **What the Clustering Analysis Reveals:**\n",
    "\n",
    "1. **Subtype Discovery**: Each cognitive state (Negative, Positive, Transition) contains 3 distinct subtypes\n",
    "   - These represent different neural \"flavors\" or patterns within each emotional state\n",
    "   - E.g., different types of negative thinking, different positive emotions, different transition mechanisms\n",
    "\n",
    "2. **Cluster Characteristics**:\n",
    "   - **Tight clusters** = Consistent, well-defined activation patterns\n",
    "   - **Scattered clusters** = More variable activation patterns  \n",
    "   - **Separated clusters** = Distinct neural mechanisms\n",
    "\n",
    "3. **Research Applications**:\n",
    "   - **Therapeutic targeting**: Different subtypes might need different interventions\n",
    "   - **Individual differences**: People might predominantly use certain cluster patterns\n",
    "   - **Transition pathways**: Understand how specific negative subtypes transform to specific positive subtypes\n",
    "\n",
    "🎨 **Visualization Features**:\n",
    "• **Color coding**: Each state has 3 shades (dark→light) for its 3 clusters\n",
    "• **Interactive plots**: Hover to see which cluster each point belongs to\n",
    "• **Legend**: \"Negative C0\", \"Positive C1\", etc. for easy identification\n",
    "• **Browser tabs**: All plots automatically open for detailed exploration\n",
    "\n",
    "🔧 **Customization Options:**\n",
    "\"\"\")\n",
    "\n",
    "print(\"# To change number of clusters:\")\n",
    "print(\"# clustering_results = perform_clustering_analysis(neg_data, pos_data, trans_data, n_clusters=5)\")\n",
    "print()\n",
    "print(\"# To analyze different layer:\")\n",
    "print(\"# clustering_results = perform_clustering_analysis(neg_data, pos_data, trans_data, layer=15)\")\n",
    "print()\n",
    "print(\"# To cluster only one cognitive state:\")\n",
    "print(\"# from sklearn.cluster import KMeans\")\n",
    "print(\"# neg_flat = neg_data.reshape(-1, neg_data.shape[-1]).cpu().numpy()\")\n",
    "print(\"# kmeans = KMeans(n_clusters=3).fit(neg_flat)\")\n",
    "print(\"# labels = kmeans.labels_\")\n",
    "\n",
    "print(f\"\\n🎯 **Next Steps for Research:**\")\n",
    "print(\"• Examine what makes each cluster unique (feature analysis)\")\n",
    "print(\"• Study transition patterns between specific clusters\")\n",
    "print(\"• Correlate clusters with therapeutic outcomes\")\n",
    "print(\"• Investigate individual differences in cluster usage\")\n",
    "\n",
    "print(f\"\\n✅ Clustering analysis complete! Check browser tabs for interactive exploration.\")\n",
    "print(f\"📁 HTML files saved in current directory for future reference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d532c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🌳 HDBSCAN ANALYSIS - Hierarchical Density-Based Clustering\n",
      "======================================================================\n",
      "\n",
      "🔍 **HDBSCAN vs K-means Comparison:**\n",
      "• **K-means**: Forces exactly 3 clusters per state (pre-specified)\n",
      "• **HDBSCAN**: Discovers natural clusters automatically (data-driven)\n",
      "• **HDBSCAN**: Identifies outliers as \"noise points\"\n",
      "• **HDBSCAN**: Can find clusters of varying shapes and densities\n",
      "\n",
      "🔍 Performing HDBSCAN clustering (automatic cluster discovery)\n",
      "Data shapes - Neg: torch.Size([520, 208, 2304]), Pos: torch.Size([520, 261, 2304]), Trans: torch.Size([520, 311, 2304])\n",
      "\n",
      "🌳 HDBSCAN ANALYSIS (Hierarchical density-based clustering)\n",
      "======================================================================\n",
      "Parameters: min_cluster_size=50, max_samples=1500\n",
      "Data shapes - Neg: (1500, 2304), Pos: (1500, 2304), Trans: (1500, 2304)\n",
      "\n",
      "🎯 HDBSCAN clustering Negative state (1500 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 2 clusters\n",
      "  Noise points: 384 (25.6%)\n",
      "  Noise:  384 samples ( 25.6%)\n",
      "  Cluster 0: 1049 samples ( 69.9%)\n",
      "  Cluster 1:   67 samples (  4.5%)\n",
      "  Silhouette score: 1.000\n",
      "\n",
      "🎯 HDBSCAN clustering Positive state (1500 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 0 clusters\n",
      "  Noise points: 1500 (100.0%)\n",
      "  Noise: 1500 samples (100.0%)\n",
      "\n",
      "🎯 HDBSCAN clustering Transition state (1500 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 0 clusters\n",
      "  Noise points: 1500 (100.0%)\n",
      "  Noise: 1500 samples (100.0%)\n",
      "\n",
      "🗺️  Computing UMAP for 4500 total samples...\n"
     ]
    }
   ],
   "source": [
    "# 12. HDBSCAN CLUSTERING ANALYSIS\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🌳 HDBSCAN ANALYSIS - Hierarchical Density-Based Clustering\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "🔍 **HDBSCAN vs K-means Comparison:**\n",
    "• **K-means**: Forces exactly 3 clusters per state (pre-specified)\n",
    "• **HDBSCAN**: Discovers natural clusters automatically (data-driven)\n",
    "• **HDBSCAN**: Identifies outliers as \"noise points\"\n",
    "• **HDBSCAN**: Can find clusters of varying shapes and densities\n",
    "\"\"\")\n",
    "\n",
    "# Perform HDBSCAN analysis on full dataset\n",
    "print(f\"🔍 Performing HDBSCAN clustering (automatic cluster discovery)\")\n",
    "print(f\"Data shapes - Neg: {neg_all_cluster.shape}, Pos: {pos_all_cluster.shape}, Trans: {trans_all_cluster.shape}\")\n",
    "\n",
    "# Perform HDBSCAN analysis\n",
    "hdbscan_results = perform_hdbscan_analysis(\n",
    "    neg_all_cluster, \n",
    "    pos_all_cluster, \n",
    "    trans_all_cluster,\n",
    "    layer=layer,\n",
    "    min_cluster_size=50,  # Minimum points needed to form a cluster\n",
    "    max_samples=1500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe38acf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎨 Creating HDBSCAN UMAP plots with noise point detection...\n",
      "\n",
      "🎨 Creating HDBSCAN UMAP visualizations...\n",
      "Opening HDBSCAN 2D plot: umap_2d_hdbscan_Full_Dataset_HDBSCAN_9059.html\n",
      "Opening HDBSCAN 3D plot: umap_3d_hdbscan_Full_Dataset_HDBSCAN_4004.html\n",
      "\n",
      "📊 HDBSCAN CLUSTER ANALYSIS SUMMARY\n",
      "==================================================\n",
      "\n",
      "🔍 NEGATIVE STATE HDBSCAN CLUSTERS:\n",
      "  Found 2 natural clusters\n",
      "  Noise points: 399 (26.6%)\n",
      "    Noise:  399 samples ( 26.6%)\n",
      "    Cluster 0: 1048 samples ( 69.9%)\n",
      "    Cluster 1:   53 samples (  3.5%)\n",
      "\n",
      "🔍 POSITIVE STATE HDBSCAN CLUSTERS:\n",
      "  Found 0 natural clusters\n",
      "  Noise points: 1500 (100.0%)\n",
      "    Noise: 1500 samples (100.0%)\n",
      "\n",
      "🔍 TRANSITION STATE HDBSCAN CLUSTERS:\n",
      "  Found 0 natural clusters\n",
      "  Noise points: 1500 (100.0%)\n",
      "    Noise: 1500 samples (100.0%)\n",
      "\n",
      "💡 HDBSCAN INTERPRETATION GUIDE:\n",
      "• HDBSCAN finds natural clusters without pre-specifying the number\n",
      "• Noise points = outliers that don't belong to any cluster\n",
      "• Varying cluster sizes = different cognitive patterns have different prevalence\n",
      "• Hierarchical structure = clusters can have sub-clusters\n",
      "• In UMAP plots, look for:\n",
      "  - Dense clusters = strong, consistent patterns\n",
      "  - Noise points (gray) = unique or transitional states\n",
      "  - Cluster boundaries = natural separations in the data\n"
     ]
    }
   ],
   "source": [
    "# 13. Visualize HDBSCAN Results\n",
    "print(\"\\n🎨 Creating HDBSCAN UMAP plots with noise point detection...\")\n",
    "\n",
    "# Create HDBSCAN UMAP plots\n",
    "fig_2d_hdbscan, fig_3d_hdbscan = plot_hdbscan_umap(\n",
    "    hdbscan_results, \n",
    "    title_prefix=\"Full_Dataset_HDBSCAN\"\n",
    ")\n",
    "\n",
    "# Analyze HDBSCAN cluster characteristics\n",
    "analyze_hdbscan_characteristics(hdbscan_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceb9f48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🎯 SINGLE PATTERN HDBSCAN ANALYSIS\n",
      "============================================================\n",
      "Analyzing HDBSCAN clustering within pattern: 'Executive Fatigue & Avolition'\n",
      "\n",
      "🌳 HDBSCAN ANALYSIS (Hierarchical density-based clustering)\n",
      "======================================================================\n",
      "Parameters: min_cluster_size=60, max_samples=2000\n",
      "Data shapes - Neg: (1040, 2304), Pos: (1320, 2304), Trans: (1560, 2304)\n",
      "\n",
      "🎯 HDBSCAN clustering Negative state (1040 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 0 clusters\n",
      "  Noise points: 1040 (100.0%)\n",
      "  Noise: 1040 samples (100.0%)\n",
      "\n",
      "🎯 HDBSCAN clustering Positive state (1320 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 0 clusters\n",
      "  Noise points: 1320 (100.0%)\n",
      "  Noise: 1320 samples (100.0%)\n",
      "\n",
      "🎯 HDBSCAN clustering Transition state (1560 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 0 clusters\n",
      "  Noise points: 1560 (100.0%)\n",
      "  Noise: 1560 samples (100.0%)\n",
      "\n",
      "🗺️  Computing UMAP for 3920 total samples...\n",
      "\n",
      "🎨 Creating HDBSCAN UMAP visualizations...\n",
      "Opening HDBSCAN 2D plot: umap_2d_hdbscan_Executive_Fatigue_&_Avolition_HDBSCAN_7835.html\n",
      "Opening HDBSCAN 3D plot: umap_3d_hdbscan_Executive_Fatigue_&_Avolition_HDBSCAN_7776.html\n",
      "\n",
      "📊 HDBSCAN CLUSTER ANALYSIS SUMMARY\n",
      "==================================================\n",
      "\n",
      "🔍 NEGATIVE STATE HDBSCAN CLUSTERS:\n",
      "  Found 0 natural clusters\n",
      "  Noise points: 1040 (100.0%)\n",
      "    Noise: 1040 samples (100.0%)\n",
      "\n",
      "🔍 POSITIVE STATE HDBSCAN CLUSTERS:\n",
      "  Found 0 natural clusters\n",
      "  Noise points: 1320 (100.0%)\n",
      "    Noise: 1320 samples (100.0%)\n",
      "\n",
      "🔍 TRANSITION STATE HDBSCAN CLUSTERS:\n",
      "  Found 0 natural clusters\n",
      "  Noise points: 1560 (100.0%)\n",
      "    Noise: 1560 samples (100.0%)\n",
      "\n",
      "💡 HDBSCAN INTERPRETATION GUIDE:\n",
      "• HDBSCAN finds natural clusters without pre-specifying the number\n",
      "• Noise points = outliers that don't belong to any cluster\n",
      "• Varying cluster sizes = different cognitive patterns have different prevalence\n",
      "• Hierarchical structure = clusters can have sub-clusters\n",
      "• In UMAP plots, look for:\n",
      "  - Dense clusters = strong, consistent patterns\n",
      "  - Noise points (gray) = unique or transitional states\n",
      "  - Cluster boundaries = natural separations in the data\n"
     ]
    }
   ],
   "source": [
    "# 14. Single Pattern HDBSCAN Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎯 SINGLE PATTERN HDBSCAN ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze HDBSCAN clustering within a specific cognitive pattern\n",
    "print(f\"Analyzing HDBSCAN clustering within pattern: '{selected_pattern_cluster}'\")\n",
    "\n",
    "# Perform HDBSCAN on single pattern\n",
    "single_pattern_hdbscan = perform_hdbscan_analysis(\n",
    "    neg_single_cluster,\n",
    "    pos_single_cluster, \n",
    "    trans_single_cluster,\n",
    "    layer=layer,\n",
    "    min_cluster_size=60,  # Smaller min_cluster_size for single pattern\n",
    "    max_samples=2000\n",
    ")\n",
    "\n",
    "# Visualize single pattern HDBSCAN\n",
    "fig_2d_single_hdbscan, fig_3d_single_hdbscan = plot_hdbscan_umap(\n",
    "    single_pattern_hdbscan,\n",
    "    title_prefix=f\"{selected_pattern_cluster}_HDBSCAN\"\n",
    ")\n",
    "\n",
    "# Analyze single pattern HDBSCAN clusters\n",
    "analyze_hdbscan_characteristics(single_pattern_hdbscan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ec059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. K-means vs HDBSCAN Comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"⚖️  CLUSTERING ALGORITHM COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def compare_clustering_results(kmeans_results, hdbscan_results):\n",
    "    \"\"\"Compare K-means and HDBSCAN clustering results\"\"\"\n",
    "    \n",
    "    print(f\"\"\"\n",
    "🔬 **ALGORITHM COMPARISON SUMMARY:**\n",
    "\n",
    "📊 **K-MEANS RESULTS:**\"\"\")\n",
    "    \n",
    "    for state_name in ['Negative', 'Positive', 'Transition']:\n",
    "        kmeans_labels = kmeans_results['clustered_data'][state_name]['cluster_labels']\n",
    "        unique_labels, counts = np.unique(kmeans_labels, return_counts=True)\n",
    "        print(f\"  {state_name}: {len(unique_labels)} clusters, sizes: {counts}\")\n",
    "    \n",
    "    print(f\"\"\"\n",
    "🌳 **HDBSCAN RESULTS:**\"\"\")\n",
    "    \n",
    "    for state_name in ['Negative', 'Positive', 'Transition']:\n",
    "        hdbscan_labels = hdbscan_results['clustered_data'][state_name]['cluster_labels']\n",
    "        n_clusters = hdbscan_results['cluster_results'][state_name]['n_clusters']\n",
    "        n_noise = hdbscan_results['cluster_results'][state_name]['n_noise']\n",
    "        unique_labels, counts = np.unique(hdbscan_labels, return_counts=True)\n",
    "        cluster_counts = counts[unique_labels != -1] if -1 in unique_labels else counts\n",
    "        print(f\"  {state_name}: {n_clusters} clusters, {n_noise} noise points\")\n",
    "        print(f\"    Cluster sizes: {cluster_counts}\")\n",
    "    \n",
    "    print(f\"\"\"\n",
    "💡 **KEY DIFFERENCES:**\n",
    "\n",
    "🎯 **Cluster Discovery:**\n",
    "• K-means: Fixed 3 clusters per state (forced partitioning)\n",
    "• HDBSCAN: Variable clusters per state (natural discovery)\n",
    "\n",
    "🔍 **Outlier Handling:**\n",
    "• K-means: All points assigned to clusters (even outliers)\n",
    "• HDBSCAN: Outliers identified as noise points (more realistic)\n",
    "\n",
    "📏 **Cluster Shapes:**\n",
    "• K-means: Assumes spherical clusters\n",
    "• HDBSCAN: Finds clusters of any shape and varying density\n",
    "\n",
    "🎨 **Visualization Differences:**\n",
    "• K-means: Uniform 3-color scheme per state\n",
    "• HDBSCAN: Dynamic colors + gray noise points\n",
    "\n",
    "🔬 **Research Implications:**\n",
    "• K-means: Good for comparing fixed number of subtypes\n",
    "• HDBSCAN: Better for discovering natural cognitive structure\n",
    "• Noise points may represent transitional or unique mental states\n",
    "• Different algorithms may reveal different aspects of cognition\n",
    "\"\"\")\n",
    "\n",
    "# Perform the comparison\n",
    "compare_clustering_results(clustering_results, hdbscan_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ebe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Final Summary - Complete Clustering Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎯 COMPLETE CLUSTERING ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "🔬 **What You've Discovered:**\n",
    "\n",
    "1. **Multiple Clustering Perspectives**:\n",
    "   - **K-means**: Structured 3-cluster analysis per cognitive state\n",
    "   - **HDBSCAN**: Natural cluster discovery with outlier detection\n",
    "\n",
    "2. **Cognitive State Structure**:\n",
    "   - **Negative states**: Multiple subtypes of depressive thinking\n",
    "   - **Positive states**: Different flavors of positive emotions  \n",
    "   - **Transition states**: Various transformation mechanisms\n",
    "   - **Noise points**: Unique or transitional mental states\n",
    "\n",
    "3. **Research Insights**:\n",
    "   - Not all cognitive patterns fit into neat categories\n",
    "   - Some mental states are truly unique (noise points)\n",
    "   - Natural clustering reveals the true structure of cognition\n",
    "   - Different algorithms highlight different aspects\n",
    "\n",
    "🎨 **Visualization Arsenal Created:**\n",
    "• Original UMAP plots (cognitive state overview)\n",
    "• Filtered visualizations (depressive-only, single patterns, single examples)  \n",
    "• K-means clustered plots (structured subtype analysis)\n",
    "• HDBSCAN clustered plots (natural cluster discovery)\n",
    "• All plots interactive and saved as HTML files\n",
    "\n",
    "🔧 **Customization Examples:**\n",
    "\"\"\")\n",
    "\n",
    "print(\"# Try different HDBSCAN parameters:\")\n",
    "print(\"# hdbscan_results = perform_hdbscan_analysis(neg_data, pos_data, trans_data, min_cluster_size=30)\")\n",
    "print()\n",
    "print(\"# Compare different layers:\")\n",
    "print(\"# layer_15_results = perform_hdbscan_analysis(neg_data, pos_data, trans_data, layer=15)\")\n",
    "print()\n",
    "print(\"# Focus on specific cognitive states:\")\n",
    "print(\"# neg_only_hdbscan = hdbscan.HDBSCAN(min_cluster_size=50).fit_predict(neg_flat)\")\n",
    "\n",
    "print(f\"\"\"\n",
    "🎯 **Next Research Directions:**\n",
    "• Investigate what makes noise points unique\n",
    "• Study cluster transitions across layers\n",
    "• Correlate clusters with clinical outcomes\n",
    "• Examine individual differences in cluster membership\n",
    "• Use clusters to guide therapeutic interventions\n",
    "\n",
    "🏆 **Achievement Unlocked:**\n",
    "✅ Multi-algorithm clustering analysis complete!\n",
    "✅ Natural cognitive structure discovered!\n",
    "✅ Outlier detection implemented!\n",
    "✅ Interactive visualizations created!\n",
    "✅ Research insights generated!\n",
    "\n",
    "📁 Check your directory for all the generated HTML visualization files!\n",
    "🌐 All plots are now open in your browser for detailed exploration!\n",
    "\"\"\")\n",
    "\n",
    "print(f\"🎉 Total analysis complete! You now have comprehensive insights into the\")\n",
    "print(f\"   neural structure of cognitive transformations using multiple clustering approaches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc20d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
