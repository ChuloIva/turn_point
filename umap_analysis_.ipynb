{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1681fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç UMAP Analysis of Cognitive Transformations\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "import webbrowser\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import hdbscan\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Configure Plotly for browser display\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\"  # This will open plots in browser by default\n",
    "\n",
    "# Set device and paths\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "base_path = Path(\"/Users/ivanculo/Desktop/Projects/turn_point\")\n",
    "activations_dir = base_path / \"activations\"\n",
    "\n",
    "# Load data (same as test_single_pattern.py)\n",
    "negative_activations = torch.load(activations_dir / \"activations_8ff00d963316212d.pt\", map_location=device)\n",
    "positive_activations = torch.load(activations_dir / \"activations_e5ad16e9b3c33c9b.pt\", map_location=device)\n",
    "transition_activations = torch.load(activations_dir / \"activations_332f24de2a3f82ff.pt\", map_location=device)\n",
    "\n",
    "with open(base_path / \"data\" / \"final\" / \"enriched_metadata.json\", 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Create pattern indices\n",
    "pattern_indices = {}\n",
    "for i, entry in enumerate(metadata):\n",
    "    pattern_name = entry['bad_good_narratives_match']['cognitive_pattern_name_from_bad_good']\n",
    "    if pattern_name not in pattern_indices:\n",
    "        pattern_indices[pattern_name] = []\n",
    "    pattern_indices[pattern_name].append(i)\n",
    "\n",
    "layer = 17\n",
    "first_pattern = list(pattern_indices.keys())[0]\n",
    "\n",
    "def prepare_data_for_umap(neg_data, pos_data, trans_data, max_samples=1000, subsample_tokens=True):\n",
    "    \"\"\"Prepare data for UMAP analysis with aggressive sampling\"\"\"\n",
    "    if subsample_tokens:\n",
    "        # Take every 8th token and limit samples\n",
    "        neg_flat = neg_data[:, ::8, :].reshape(-1, neg_data.shape[-1])\n",
    "        pos_flat = pos_data[:, ::8, :].reshape(-1, pos_data.shape[-1])\n",
    "        trans_flat = trans_data[:, ::8, :].reshape(-1, trans_data.shape[-1])\n",
    "    else:\n",
    "        neg_flat = neg_data.reshape(-1, neg_data.shape[-1])\n",
    "        pos_flat = pos_data.reshape(-1, pos_data.shape[-1])\n",
    "        trans_flat = trans_data.reshape(-1, trans_data.shape[-1])\n",
    "    \n",
    "    # Subsample to max_samples per category\n",
    "    if len(neg_flat) > max_samples:\n",
    "        indices = torch.randperm(len(neg_flat))[:max_samples]\n",
    "        neg_flat = neg_flat[indices]\n",
    "    if len(pos_flat) > max_samples:\n",
    "        indices = torch.randperm(len(pos_flat))[:max_samples]\n",
    "        pos_flat = pos_flat[indices]\n",
    "    if len(trans_flat) > max_samples:\n",
    "        indices = torch.randperm(len(trans_flat))[:max_samples]\n",
    "        trans_flat = trans_flat[indices]\n",
    "    \n",
    "    # Combine data and create labels\n",
    "    combined_data = torch.cat([neg_flat, pos_flat, trans_flat], dim=0).cpu().numpy()\n",
    "    labels = ['Negative'] * len(neg_flat) + ['Positive'] * len(pos_flat) + ['Transition'] * len(trans_flat)\n",
    "    colors = ['red'] * len(neg_flat) + ['green'] * len(pos_flat) + ['blue'] * len(trans_flat)\n",
    "    \n",
    "    return combined_data, labels, colors\n",
    "\n",
    "def plot_umap_2d_3d(data, labels, colors, title_prefix=\"\"):\n",
    "    \"\"\"Create interactive 2D and 3D UMAP plots with Plotly\"\"\"\n",
    "    print(f\"Computing UMAP for {len(data)} samples...\")\n",
    "    \n",
    "    # 2D UMAP with faster parameters\n",
    "    umap_2d = umap.UMAP(n_components=2, random_state=42, n_neighbors=min(15, len(data)//3), min_dist=0.1, n_jobs=1)\n",
    "    embedding_2d = umap_2d.fit_transform(data)\n",
    "    \n",
    "    # 3D UMAP with faster parameters  \n",
    "    umap_3d = umap.UMAP(n_components=3, random_state=42, n_neighbors=min(15, len(data)//3), min_dist=0.1, n_jobs=1)\n",
    "    embedding_3d = umap_3d.fit_transform(data)\n",
    "    \n",
    "    # Create color mapping\n",
    "    color_map = {'Negative': 'red', 'Positive': 'green', 'Transition': 'blue'}\n",
    "    \n",
    "    # Create 2D plot\n",
    "    fig_2d = go.Figure()\n",
    "    \n",
    "    for label in ['Negative', 'Positive', 'Transition']:\n",
    "        mask = [l == label for l in labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            fig_2d.add_trace(go.Scatter(\n",
    "                x=embedding_2d[indices, 0],\n",
    "                y=embedding_2d[indices, 1],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=color_map[label],\n",
    "                    size=4,\n",
    "                    opacity=0.7\n",
    "                ),\n",
    "                name=label,\n",
    "                hovertemplate=f'<b>{label}</b><br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_2d.update_layout(\n",
    "        title=f'{title_prefix}2D UMAP - Interactive Visualization',\n",
    "        xaxis_title='UMAP 1',\n",
    "        yaxis_title='UMAP 2',\n",
    "        width=800,\n",
    "        height=600,\n",
    "        showlegend=True,\n",
    "        hovermode='closest'\n",
    "    )\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig_3d = go.Figure()\n",
    "    \n",
    "    for label in ['Negative', 'Positive', 'Transition']:\n",
    "        mask = [l == label for l in labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            fig_3d.add_trace(go.Scatter3d(\n",
    "                x=embedding_3d[indices, 0],\n",
    "                y=embedding_3d[indices, 1],\n",
    "                z=embedding_3d[indices, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=color_map[label],\n",
    "                    size=3,\n",
    "                    opacity=0.7\n",
    "                ),\n",
    "                name=label,\n",
    "                hovertemplate=f'<b>{label}</b><br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<br>UMAP 3: %{{z:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_3d.update_layout(\n",
    "        title=f'{title_prefix}3D UMAP - Interactive Visualization',\n",
    "        scene=dict(\n",
    "            xaxis_title='UMAP 1',\n",
    "            yaxis_title='UMAP 2',\n",
    "            zaxis_title='UMAP 3'\n",
    "        ),\n",
    "        width=800,\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Save and open plots in new browser tabs\n",
    "    safe_title = title_prefix.replace(\" \", \"_\").replace(\"-\", \"\").strip(\"_\")\n",
    "    \n",
    "    # Save 2D plot\n",
    "    filename_2d = f\"umap_2d_{safe_title}_{hash(str(embedding_2d.tolist())) % 10000}.html\"\n",
    "    fig_2d.write_html(filename_2d, auto_open=False)\n",
    "    \n",
    "    # Save 3D plot  \n",
    "    filename_3d = f\"umap_3d_{safe_title}_{hash(str(embedding_3d.tolist())) % 10000}.html\"\n",
    "    fig_3d.write_html(filename_3d, auto_open=False)\n",
    "    \n",
    "    # Open in new browser tabs\n",
    "    abs_path_2d = os.path.abspath(filename_2d)\n",
    "    abs_path_3d = os.path.abspath(filename_3d)\n",
    "    \n",
    "    print(f\"Opening 2D plot: {filename_2d}\")\n",
    "    webbrowser.open(f'file://{abs_path_2d}', new=2)  # new=2 opens in new tab\n",
    "    \n",
    "    print(f\"Opening 3D plot: {filename_3d}\")  \n",
    "    webbrowser.open(f'file://{abs_path_3d}', new=2)  # new=2 opens in new tab\n",
    "    \n",
    "    # Also display inline for Jupyter\n",
    "    fig_2d.show()\n",
    "    fig_3d.show()\n",
    "    \n",
    "    return embedding_2d, embedding_3d\n",
    "\n",
    "def plot_depressive_only_umap(layer=17, max_samples=2000):\n",
    "    \"\"\"Visualize only depressive (negative) tokens across all cognitive patterns\"\"\"\n",
    "    print(f\"\\nüî¥ Depressive Dataset UMAP (all patterns, negative tokens only)\")\n",
    "    \n",
    "    all_indices = [i for indices_list in pattern_indices.values() for i in indices_list]\n",
    "    neg_all = negative_activations[f'negative_layer_{layer}'][all_indices]\n",
    "    \n",
    "    print(f\"Depressive data shape: {neg_all.shape}\")\n",
    "    \n",
    "    # Prepare data - only negative, but we'll create dummy pos/trans for consistency\n",
    "    if max_samples and neg_all.shape[0] * neg_all.shape[1] > max_samples:\n",
    "        # Subsample tokens more aggressively\n",
    "        neg_flat = neg_all[:, ::12, :].reshape(-1, neg_all.shape[-1])\n",
    "    else:\n",
    "        neg_flat = neg_all.reshape(-1, neg_all.shape[-1])\n",
    "    \n",
    "    if len(neg_flat) > max_samples:\n",
    "        indices = torch.randperm(len(neg_flat))[:max_samples]\n",
    "        neg_flat = neg_flat[indices]\n",
    "    \n",
    "    # Create data with only negatives\n",
    "    combined_data = neg_flat.cpu().numpy()\n",
    "    labels = ['Depressive'] * len(neg_flat)\n",
    "    colors = ['darkred'] * len(neg_flat)\n",
    "    \n",
    "    print(f\"Combined depressive data shape: {combined_data.shape}\")\n",
    "    \n",
    "    # Compute UMAP\n",
    "    print(f\"Computing UMAP for {len(combined_data)} depressive samples...\")\n",
    "    umap_2d = umap.UMAP(n_components=2, random_state=42, n_neighbors=min(15, len(combined_data)//3), min_dist=0.1, n_jobs=1)\n",
    "    embedding_2d = umap_2d.fit_transform(combined_data)\n",
    "    \n",
    "    umap_3d = umap.UMAP(n_components=3, random_state=42, n_neighbors=min(15, len(combined_data)//3), min_dist=0.1, n_jobs=1)\n",
    "    embedding_3d = umap_3d.fit_transform(combined_data)\n",
    "    \n",
    "    # Create 2D plot\n",
    "    fig_2d = go.Figure()\n",
    "    fig_2d.add_trace(go.Scatter(\n",
    "        x=embedding_2d[:, 0],\n",
    "        y=embedding_2d[:, 1],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color='darkred',\n",
    "            size=4,\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        name='Depressive',\n",
    "        hovertemplate='<b>Depressive</b><br>UMAP 1: %{x:.2f}<br>UMAP 2: %{y:.2f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig_2d.update_layout(\n",
    "        title='Depressive Dataset Only - 2D UMAP',\n",
    "        xaxis_title='UMAP 1',\n",
    "        yaxis_title='UMAP 2',\n",
    "        width=800,\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig_3d = go.Figure()\n",
    "    fig_3d.add_trace(go.Scatter3d(\n",
    "        x=embedding_3d[:, 0],\n",
    "        y=embedding_3d[:, 1],\n",
    "        z=embedding_3d[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color='darkred',\n",
    "            size=3,\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        name='Depressive',\n",
    "        hovertemplate='<b>Depressive</b><br>UMAP 1: %{x:.2f}<br>UMAP 2: %{y:.2f}<br>UMAP 3: %{z:.2f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig_3d.update_layout(\n",
    "        title='Depressive Dataset Only - 3D UMAP',\n",
    "        scene=dict(\n",
    "            xaxis_title='UMAP 1',\n",
    "            yaxis_title='UMAP 2',\n",
    "            zaxis_title='UMAP 3'\n",
    "        ),\n",
    "        width=800,\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Save and open plots\n",
    "    filename_2d = f\"umap_2d_depressive_only_{hash(str(embedding_2d.tolist())) % 10000}.html\"\n",
    "    filename_3d = f\"umap_3d_depressive_only_{hash(str(embedding_3d.tolist())) % 10000}.html\"\n",
    "    \n",
    "    fig_2d.write_html(filename_2d, auto_open=False)\n",
    "    fig_3d.write_html(filename_3d, auto_open=False)\n",
    "    \n",
    "    print(f\"Opening depressive 2D plot: {filename_2d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_2d)}', new=2)\n",
    "    \n",
    "    print(f\"Opening depressive 3D plot: {filename_3d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_3d)}', new=2)\n",
    "    \n",
    "    fig_2d.show()\n",
    "    fig_3d.show()\n",
    "    \n",
    "    return embedding_2d, embedding_3d\n",
    "\n",
    "def plot_single_pattern_all_examples(pattern_name, layer=17, max_samples=1000):\n",
    "    \"\"\"Visualize all examples (neg, pos, trans) from one specific cognitive pattern\"\"\"\n",
    "    print(f\"\\nüéØ Single Pattern UMAP: {pattern_name} (all examples)\")\n",
    "    \n",
    "    if pattern_name not in pattern_indices:\n",
    "        print(f\"Pattern '{pattern_name}' not found. Available patterns:\")\n",
    "        for p in list(pattern_indices.keys())[:5]:\n",
    "            print(f\"  - {p}\")\n",
    "        return None, None\n",
    "    \n",
    "    indices = pattern_indices[pattern_name]\n",
    "    neg_single = negative_activations[f'negative_layer_{layer}'][indices]\n",
    "    pos_single = positive_activations[f'positive_layer_{layer}'][indices]\n",
    "    trans_single = transition_activations[f'transition_layer_{layer}'][indices]\n",
    "    \n",
    "    print(f\"Pattern data shapes - Neg: {neg_single.shape}, Pos: {pos_single.shape}, Trans: {trans_single.shape}\")\n",
    "    \n",
    "    data_single, labels_single, colors_single = prepare_data_for_umap(neg_single, pos_single, trans_single, max_samples=max_samples)\n",
    "    embedding_2d, embedding_3d = plot_umap_2d_3d(data_single, labels_single, colors_single, f\"{pattern_name}_AllExamples_\")\n",
    "    \n",
    "    return embedding_2d, embedding_3d\n",
    "\n",
    "def plot_single_example(pattern_name, example_idx=0, layer=17):\n",
    "    \"\"\"Visualize just one example from one cognitive pattern (all its tokens)\"\"\"\n",
    "    print(f\"\\nüî¨ Single Example UMAP: {pattern_name} (example {example_idx})\")\n",
    "    \n",
    "    if pattern_name not in pattern_indices:\n",
    "        print(f\"Pattern '{pattern_name}' not found. Available patterns:\")\n",
    "        for p in list(pattern_indices.keys())[:5]:\n",
    "            print(f\"  - {p}\")\n",
    "        return None, None\n",
    "    \n",
    "    indices = pattern_indices[pattern_name]\n",
    "    if example_idx >= len(indices):\n",
    "        print(f\"Example index {example_idx} out of range. Pattern has {len(indices)} examples.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Get single example\n",
    "    single_idx = indices[example_idx]\n",
    "    neg_example = negative_activations[f'negative_layer_{layer}'][single_idx:single_idx+1]\n",
    "    pos_example = positive_activations[f'positive_layer_{layer}'][single_idx:single_idx+1]\n",
    "    trans_example = transition_activations[f'transition_layer_{layer}'][single_idx:single_idx+1]\n",
    "    \n",
    "    print(f\"Single example shapes - Neg: {neg_example.shape}, Pos: {pos_example.shape}, Trans: {trans_example.shape}\")\n",
    "    \n",
    "    # Flatten to get all tokens from this single example\n",
    "    neg_flat = neg_example.reshape(-1, neg_example.shape[-1])\n",
    "    pos_flat = pos_example.reshape(-1, pos_example.shape[-1])\n",
    "    trans_flat = trans_example.reshape(-1, trans_example.shape[-1])\n",
    "    \n",
    "    # Combine data\n",
    "    combined_data = torch.cat([neg_flat, pos_flat, trans_flat], dim=0).cpu().numpy()\n",
    "    labels = (['Negative'] * len(neg_flat) + \n",
    "              ['Positive'] * len(pos_flat) + \n",
    "              ['Transition'] * len(trans_flat))\n",
    "    \n",
    "    print(f\"Combined single example data shape: {combined_data.shape}\")\n",
    "    \n",
    "    if len(combined_data) < 10:\n",
    "        print(\"‚ö†Ô∏è  Very few tokens in this example - UMAP may not be meaningful\")\n",
    "    \n",
    "    # Compute UMAP with adjusted parameters for small datasets\n",
    "    n_neighbors = min(5, len(combined_data)//2) if len(combined_data) < 50 else min(15, len(combined_data)//3)\n",
    "    \n",
    "    print(f\"Computing UMAP for {len(combined_data)} tokens from single example...\")\n",
    "    umap_2d = umap.UMAP(n_components=2, random_state=42, n_neighbors=n_neighbors, min_dist=0.1, n_jobs=1)\n",
    "    embedding_2d = umap_2d.fit_transform(combined_data)\n",
    "    \n",
    "    umap_3d = umap.UMAP(n_components=3, random_state=42, n_neighbors=n_neighbors, min_dist=0.1, n_jobs=1)\n",
    "    embedding_3d = umap_3d.fit_transform(combined_data)\n",
    "    \n",
    "    # Create color mapping\n",
    "    color_map = {'Negative': 'red', 'Positive': 'green', 'Transition': 'blue'}\n",
    "    \n",
    "    # Create 2D plot\n",
    "    fig_2d = go.Figure()\n",
    "    for label in ['Negative', 'Positive', 'Transition']:\n",
    "        mask = [l == label for l in labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            fig_2d.add_trace(go.Scatter(\n",
    "                x=embedding_2d[indices, 0],\n",
    "                y=embedding_2d[indices, 1],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=color_map[label],\n",
    "                    size=6,\n",
    "                    opacity=0.8\n",
    "                ),\n",
    "                name=f'{label} (tokens)',\n",
    "                hovertemplate=f'<b>{label} Token</b><br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_2d.update_layout(\n",
    "        title=f'Single Example: {pattern_name} (Example {example_idx}) - 2D UMAP',\n",
    "        xaxis_title='UMAP 1',\n",
    "        yaxis_title='UMAP 2',\n",
    "        width=800,\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig_3d = go.Figure()\n",
    "    for label in ['Negative', 'Positive', 'Transition']:\n",
    "        mask = [l == label for l in labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            fig_3d.add_trace(go.Scatter3d(\n",
    "                x=embedding_3d[indices, 0],\n",
    "                y=embedding_3d[indices, 1],\n",
    "                z=embedding_3d[indices, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=color_map[label],\n",
    "                    size=4,\n",
    "                    opacity=0.8\n",
    "                ),\n",
    "                name=f'{label} (tokens)',\n",
    "                hovertemplate=f'<b>{label} Token</b><br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<br>UMAP 3: %{{z:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_3d.update_layout(\n",
    "        title=f'Single Example: {pattern_name} (Example {example_idx}) - 3D UMAP',\n",
    "        scene=dict(\n",
    "            xaxis_title='UMAP 1',\n",
    "            yaxis_title='UMAP 2',\n",
    "            zaxis_title='UMAP 3'\n",
    "        ),\n",
    "        width=800,\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Save and open plots\n",
    "    safe_pattern = pattern_name.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "    filename_2d = f\"umap_2d_single_example_{safe_pattern}_{example_idx}_{hash(str(embedding_2d.tolist())) % 10000}.html\"\n",
    "    filename_3d = f\"umap_3d_single_example_{safe_pattern}_{example_idx}_{hash(str(embedding_3d.tolist())) % 10000}.html\"\n",
    "    \n",
    "    fig_2d.write_html(filename_2d, auto_open=False)\n",
    "    fig_3d.write_html(filename_3d, auto_open=False)\n",
    "    \n",
    "    print(f\"Opening single example 2D plot: {filename_2d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_2d)}', new=2)\n",
    "    \n",
    "    print(f\"Opening single example 3D plot: {filename_3d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_3d)}', new=2)\n",
    "    \n",
    "    fig_2d.show()\n",
    "    fig_3d.show()\n",
    "    \n",
    "    return embedding_2d, embedding_3d\n",
    "\n",
    "def perform_clustering_analysis(neg_data, pos_data, trans_data, layer=17, n_clusters=3, max_samples=1500):\n",
    "    \"\"\"\n",
    "    Perform K-means clustering on each cognitive state separately and create UMAP visualization\n",
    "    \"\"\"\n",
    "    print(f\"\\nüî¨ CLUSTERING ANALYSIS (K-means with {n_clusters} clusters per state)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Prepare data for each state\n",
    "    def prepare_state_data(data, state_name, max_samples):\n",
    "        # Subsample tokens if needed\n",
    "        if data.shape[0] * data.shape[1] > max_samples:\n",
    "            data_flat = data[:, ::8, :].reshape(-1, data.shape[-1])\n",
    "        else:\n",
    "            data_flat = data.reshape(-1, data.shape[-1])\n",
    "        \n",
    "        if len(data_flat) > max_samples:\n",
    "            indices = torch.randperm(len(data_flat))[:max_samples]\n",
    "            data_flat = data_flat[indices]\n",
    "            \n",
    "        return data_flat.cpu().numpy()\n",
    "    \n",
    "    # Prepare data for each cognitive state\n",
    "    neg_flat = prepare_state_data(neg_data, \"Negative\", max_samples)\n",
    "    pos_flat = prepare_state_data(pos_data, \"Positive\", max_samples)\n",
    "    trans_flat = prepare_state_data(trans_data, \"Transition\", max_samples)\n",
    "    \n",
    "    print(f\"Data shapes - Neg: {neg_flat.shape}, Pos: {pos_flat.shape}, Trans: {trans_flat.shape}\")\n",
    "    \n",
    "    # Standardize data for better clustering\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Perform clustering on each state separately\n",
    "    states_data = {\n",
    "        'Negative': neg_flat,\n",
    "        'Positive': pos_flat, \n",
    "        'Transition': trans_flat\n",
    "    }\n",
    "    \n",
    "    clustered_data = {}\n",
    "    cluster_results = {}\n",
    "    \n",
    "    for state_name, data in states_data.items():\n",
    "        print(f\"\\nüéØ Clustering {state_name} state ({data.shape[0]} samples)...\")\n",
    "        \n",
    "        # Standardize the data\n",
    "        data_scaled = scaler.fit_transform(data)\n",
    "        \n",
    "        # Perform K-means clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        cluster_labels = kmeans.fit_predict(data_scaled)\n",
    "        \n",
    "        # Store results\n",
    "        clustered_data[state_name] = {\n",
    "            'data': data,\n",
    "            'data_scaled': data_scaled,\n",
    "            'cluster_labels': cluster_labels,\n",
    "            'kmeans_model': kmeans\n",
    "        }\n",
    "        \n",
    "        # Print cluster statistics\n",
    "        unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "        print(f\"  Cluster distribution: {dict(zip(unique_labels, counts))}\")\n",
    "        \n",
    "        cluster_results[state_name] = {\n",
    "            'cluster_labels': cluster_labels,\n",
    "            'cluster_centers': kmeans.cluster_centers_,\n",
    "            'inertia': kmeans.inertia_\n",
    "        }\n",
    "    \n",
    "    # Compute UMAP on combined data but keep cluster info\n",
    "    combined_data = np.vstack([neg_flat, pos_flat, trans_flat])\n",
    "    combined_labels = (['Negative'] * len(neg_flat) + \n",
    "                      ['Positive'] * len(pos_flat) + \n",
    "                      ['Transition'] * len(trans_flat))\n",
    "    \n",
    "    # Create detailed cluster labels combining state and cluster\n",
    "    detailed_labels = []\n",
    "    cluster_colors = []\n",
    "    \n",
    "    # Color palettes for each state\n",
    "    neg_colors = ['#8B0000', '#DC143C', '#B22222']  # Dark red shades\n",
    "    pos_colors = ['#006400', '#228B22', '#32CD32']  # Dark green shades  \n",
    "    trans_colors = ['#00008B', '#4169E1', '#1E90FF']  # Blue shades\n",
    "    \n",
    "    color_maps = {\n",
    "        'Negative': neg_colors,\n",
    "        'Positive': pos_colors,\n",
    "        'Transition': trans_colors\n",
    "    }\n",
    "    \n",
    "    # Build combined labels and colors\n",
    "    for state_name in ['Negative', 'Positive', 'Transition']:\n",
    "        state_clusters = clustered_data[state_name]['cluster_labels']\n",
    "        state_colors = color_maps[state_name]\n",
    "        \n",
    "        for cluster_id in state_clusters:\n",
    "            detailed_labels.append(f\"{state_name}_Cluster_{cluster_id}\")\n",
    "            cluster_colors.append(state_colors[cluster_id % len(state_colors)])\n",
    "    \n",
    "    print(f\"\\nüó∫Ô∏è  Computing UMAP for {len(combined_data)} total samples...\")\n",
    "    \n",
    "    # Compute UMAP\n",
    "    umap_2d = umap.UMAP(n_components=2, random_state=42, \n",
    "                       n_neighbors=min(15, len(combined_data)//3), \n",
    "                       min_dist=0.1, n_jobs=1)\n",
    "    embedding_2d = umap_2d.fit_transform(combined_data)\n",
    "    \n",
    "    umap_3d = umap.UMAP(n_components=3, random_state=42,\n",
    "                       n_neighbors=min(15, len(combined_data)//3),\n",
    "                       min_dist=0.1, n_jobs=1)\n",
    "    embedding_3d = umap_3d.fit_transform(combined_data)\n",
    "    \n",
    "    return {\n",
    "        'embedding_2d': embedding_2d,\n",
    "        'embedding_3d': embedding_3d,\n",
    "        'combined_data': combined_data,\n",
    "        'detailed_labels': detailed_labels,\n",
    "        'cluster_colors': cluster_colors,\n",
    "        'clustered_data': clustered_data,\n",
    "        'cluster_results': cluster_results,\n",
    "        'state_labels': combined_labels\n",
    "    }\n",
    "\n",
    "def plot_clustered_umap(clustering_results, title_prefix=\"Clustered\"):\n",
    "    \"\"\"\n",
    "    Create UMAP plots showing cluster assignments for each cognitive state\n",
    "    \"\"\"\n",
    "    embedding_2d = clustering_results['embedding_2d']\n",
    "    embedding_3d = clustering_results['embedding_3d']\n",
    "    detailed_labels = clustering_results['detailed_labels']\n",
    "    cluster_colors = clustering_results['cluster_colors']\n",
    "    state_labels = clustering_results['state_labels']\n",
    "    \n",
    "    print(f\"\\nüé® Creating clustered UMAP visualizations...\")\n",
    "    \n",
    "    # Create 2D plot\n",
    "    fig_2d = go.Figure()\n",
    "    \n",
    "    # Group by detailed cluster labels for legend\n",
    "    unique_detailed_labels = list(set(detailed_labels))\n",
    "    \n",
    "    for label in unique_detailed_labels:\n",
    "        mask = [l == label for l in detailed_labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            \n",
    "            # Extract state and cluster info for hover\n",
    "            state = label.split('_')[0]\n",
    "            cluster_id = label.split('_')[-1]\n",
    "            \n",
    "            fig_2d.add_trace(go.Scatter(\n",
    "                x=embedding_2d[indices, 0],\n",
    "                y=embedding_2d[indices, 1],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=cluster_colors[indices[0]],  # Use the assigned color\n",
    "                    size=4,\n",
    "                    opacity=0.7,\n",
    "                    line=dict(width=0.5, color='white')\n",
    "                ),\n",
    "                name=f\"{state} C{cluster_id}\",\n",
    "                hovertemplate=f'<b>{state} Cluster {cluster_id}</b><br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_2d.update_layout(\n",
    "        title=f'{title_prefix} - 2D UMAP with K-means Clusters',\n",
    "        xaxis_title='UMAP 1',\n",
    "        yaxis_title='UMAP 2',\n",
    "        width=900,\n",
    "        height=700,\n",
    "        showlegend=True,\n",
    "        hovermode='closest',\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\",\n",
    "            y=1,\n",
    "            xanchor=\"left\",\n",
    "            x=1.02\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig_3d = go.Figure()\n",
    "    \n",
    "    for label in unique_detailed_labels:\n",
    "        mask = [l == label for l in detailed_labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            \n",
    "            state = label.split('_')[0]\n",
    "            cluster_id = label.split('_')[-1]\n",
    "            \n",
    "            fig_3d.add_trace(go.Scatter3d(\n",
    "                x=embedding_3d[indices, 0],\n",
    "                y=embedding_3d[indices, 1],\n",
    "                z=embedding_3d[indices, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=cluster_colors[indices[0]],\n",
    "                    size=3,\n",
    "                    opacity=0.7,\n",
    "                    line=dict(width=0.5, color='white')\n",
    "                ),\n",
    "                name=f\"{state} C{cluster_id}\",\n",
    "                hovertemplate=f'<b>{state} Cluster {cluster_id}</b><br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<br>UMAP 3: %{{z:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_3d.update_layout(\n",
    "        title=f'{title_prefix} - 3D UMAP with K-means Clusters',\n",
    "        scene=dict(\n",
    "            xaxis_title='UMAP 1',\n",
    "            yaxis_title='UMAP 2',\n",
    "            zaxis_title='UMAP 3'\n",
    "        ),\n",
    "        width=900,\n",
    "        height=700,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Save and open plots\n",
    "    safe_title = title_prefix.replace(\" \", \"_\").replace(\"-\", \"\").strip(\"_\")\n",
    "    filename_2d = f\"umap_2d_clustered_{safe_title}_{hash(str(embedding_2d.tolist())) % 10000}.html\"\n",
    "    filename_3d = f\"umap_3d_clustered_{safe_title}_{hash(str(embedding_3d.tolist())) % 10000}.html\"\n",
    "    \n",
    "    fig_2d.write_html(filename_2d, auto_open=False)\n",
    "    fig_3d.write_html(filename_3d, auto_open=False)\n",
    "    \n",
    "    print(f\"Opening clustered 2D plot: {filename_2d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_2d)}', new=2)\n",
    "    \n",
    "    print(f\"Opening clustered 3D plot: {filename_3d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_3d)}', new=2)\n",
    "    \n",
    "    fig_2d.show()\n",
    "    fig_3d.show()\n",
    "    \n",
    "    return fig_2d, fig_3d\n",
    "\n",
    "def analyze_cluster_characteristics(clustering_results):\n",
    "    \"\"\"\n",
    "    Analyze and print characteristics of each cluster\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìä CLUSTER ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    clustered_data = clustering_results['clustered_data']\n",
    "    cluster_results = clustering_results['cluster_results']\n",
    "    \n",
    "    for state_name, data_info in clustered_data.items():\n",
    "        print(f\"\\nüîç {state_name.upper()} STATE CLUSTERS:\")\n",
    "        \n",
    "        cluster_labels = data_info['cluster_labels']\n",
    "        unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "        \n",
    "        total_samples = len(cluster_labels)\n",
    "        \n",
    "        for cluster_id, count in zip(unique_labels, counts):\n",
    "            percentage = (count / total_samples) * 100\n",
    "            print(f\"  Cluster {cluster_id}: {count:4d} samples ({percentage:5.1f}%)\")\n",
    "        \n",
    "        print(f\"  Total inertia (within-cluster sum of squares): {cluster_results[state_name]['inertia']:.2f}\")\n",
    "    \n",
    "    print(f\"\\nüí° INTERPRETATION GUIDE:\")\n",
    "    print(\"‚Ä¢ Each cognitive state (Negative/Positive/Transition) has 3 distinct clusters\")\n",
    "    print(\"‚Ä¢ Clusters represent different 'subtypes' or 'patterns' within each state\")\n",
    "    print(\"‚Ä¢ Lower inertia = more compact, well-separated clusters\")\n",
    "    print(\"‚Ä¢ In UMAP plots, look for:\")\n",
    "    print(\"  - Tight clusters = consistent activation patterns\")  \n",
    "    print(\"  - Scattered points = diverse activation patterns\")\n",
    "    print(\"  - Cluster separation = how distinct the subtypes are\")\n",
    "\n",
    "def perform_hdbscan_analysis(neg_data, pos_data, trans_data, layer=17, min_cluster_size=50, max_samples=1500):\n",
    "    \"\"\"\n",
    "    Perform HDBSCAN clustering on each cognitive state separately\n",
    "    \"\"\"\n",
    "    print(f\"\\nüå≥ HDBSCAN ANALYSIS (Hierarchical density-based clustering)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Parameters: min_cluster_size={min_cluster_size}, max_samples={max_samples}\")\n",
    "    \n",
    "    # Prepare data for each state (same as K-means)\n",
    "    def prepare_state_data(data, state_name, max_samples):\n",
    "        if data.shape[0] * data.shape[1] > max_samples:\n",
    "            data_flat = data[:, ::8, :].reshape(-1, data.shape[-1])\n",
    "        else:\n",
    "            data_flat = data.reshape(-1, data.shape[-1])\n",
    "        \n",
    "        if len(data_flat) > max_samples:\n",
    "            indices = torch.randperm(len(data_flat))[:max_samples]\n",
    "            data_flat = data_flat[indices]\n",
    "            \n",
    "        return data_flat.cpu().numpy()\n",
    "    \n",
    "    # Prepare data for each cognitive state\n",
    "    neg_flat = prepare_state_data(neg_data, \"Negative\", max_samples)\n",
    "    pos_flat = prepare_state_data(pos_data, \"Positive\", max_samples)\n",
    "    trans_flat = prepare_state_data(trans_data, \"Transition\", max_samples)\n",
    "    \n",
    "    print(f\"Data shapes - Neg: {neg_flat.shape}, Pos: {pos_flat.shape}, Trans: {trans_flat.shape}\")\n",
    "    \n",
    "    # Standardize data\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Perform HDBSCAN on each state separately\n",
    "    states_data = {\n",
    "        'Negative': neg_flat,\n",
    "        'Positive': pos_flat, \n",
    "        'Transition': trans_flat\n",
    "    }\n",
    "    \n",
    "    clustered_data = {}\n",
    "    cluster_results = {}\n",
    "    \n",
    "    for state_name, data in states_data.items():\n",
    "        print(f\"\\nüéØ HDBSCAN clustering {state_name} state ({data.shape[0]} samples)...\")\n",
    "        \n",
    "        # Standardize the data\n",
    "        data_scaled = scaler.fit_transform(data)\n",
    "        \n",
    "        # Perform HDBSCAN clustering\n",
    "        hdbscan_model = hdbscan.HDBSCAN(\n",
    "            min_cluster_size=min_cluster_size,\n",
    "            min_samples=10,\n",
    "            cluster_selection_epsilon=0.0,\n",
    "            metric='euclidean',\n",
    "            cluster_selection_method='eom'  # Excess of Mass\n",
    "        )\n",
    "        \n",
    "        cluster_labels = hdbscan_model.fit_predict(data_scaled)\n",
    "        \n",
    "        # Store results\n",
    "        clustered_data[state_name] = {\n",
    "            'data': data,\n",
    "            'data_scaled': data_scaled,\n",
    "            'cluster_labels': cluster_labels,\n",
    "            'hdbscan_model': hdbscan_model\n",
    "        }\n",
    "        \n",
    "        # Print cluster statistics\n",
    "        unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "        n_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)\n",
    "        n_noise = counts[unique_labels == -1][0] if -1 in unique_labels else 0\n",
    "        \n",
    "        print(f\"  Found {n_clusters} clusters\")\n",
    "        print(f\"  Noise points: {n_noise} ({n_noise/len(cluster_labels)*100:.1f}%)\")\n",
    "        \n",
    "        for cluster_id, count in zip(unique_labels, counts):\n",
    "            if cluster_id == -1:\n",
    "                print(f\"  Noise: {count:4d} samples ({count/len(cluster_labels)*100:5.1f}%)\")\n",
    "            else:\n",
    "                print(f\"  Cluster {cluster_id}: {count:4d} samples ({count/len(cluster_labels)*100:5.1f}%)\")\n",
    "        \n",
    "        # Calculate silhouette score (excluding noise points)\n",
    "        if n_clusters > 1:\n",
    "            non_noise_mask = cluster_labels != -1\n",
    "            if np.sum(non_noise_mask) > 1:\n",
    "                silhouette_avg = silhouette_score(data_scaled[non_noise_mask], \n",
    "                                                cluster_labels[non_noise_mask])\n",
    "                print(f\"  Silhouette score: {silhouette_avg:.3f}\")\n",
    "        \n",
    "        cluster_results[state_name] = {\n",
    "            'cluster_labels': cluster_labels,\n",
    "            'n_clusters': n_clusters,\n",
    "            'n_noise': n_noise,\n",
    "            'cluster_probabilities': hdbscan_model.probabilities_ if hasattr(hdbscan_model, 'probabilities_') else None\n",
    "        }\n",
    "    \n",
    "    # Compute UMAP on combined data\n",
    "    combined_data = np.vstack([neg_flat, pos_flat, trans_flat])\n",
    "    combined_labels = (['Negative'] * len(neg_flat) + \n",
    "                      ['Positive'] * len(pos_flat) + \n",
    "                      ['Transition'] * len(trans_flat))\n",
    "    \n",
    "    # Create detailed cluster labels and colors for HDBSCAN\n",
    "    detailed_labels = []\n",
    "    cluster_colors = []\n",
    "    \n",
    "    # Generate colors dynamically based on number of clusters found\n",
    "    def generate_colors(n_clusters, base_color):\n",
    "        \"\"\"Generate n_clusters different shades of base_color\"\"\"\n",
    "        import colorsys\n",
    "        colors = []\n",
    "        if base_color == 'red':\n",
    "            base_hue = 0.0\n",
    "        elif base_color == 'green':\n",
    "            base_hue = 0.33\n",
    "        else:  # blue\n",
    "            base_hue = 0.67\n",
    "        \n",
    "        for i in range(n_clusters):\n",
    "            # Vary saturation and lightness\n",
    "            sat = 0.7 + 0.3 * (i / max(1, n_clusters-1))\n",
    "            light = 0.3 + 0.4 * (i / max(1, n_clusters-1))\n",
    "            rgb = colorsys.hsv_to_rgb(base_hue, sat, light)\n",
    "            colors.append(f'rgb({int(rgb[0]*255)},{int(rgb[1]*255)},{int(rgb[2]*255)})')\n",
    "        \n",
    "        # Add noise color (gray)\n",
    "        colors.append('#808080')\n",
    "        return colors\n",
    "    \n",
    "    # Build combined labels and colors\n",
    "    for state_name, base_color in [('Negative', 'red'), ('Positive', 'green'), ('Transition', 'blue')]:\n",
    "        state_clusters = clustered_data[state_name]['cluster_labels']\n",
    "        n_clusters = cluster_results[state_name]['n_clusters']\n",
    "        state_colors = generate_colors(n_clusters, base_color)\n",
    "        \n",
    "        for cluster_id in state_clusters:\n",
    "            if cluster_id == -1:\n",
    "                detailed_labels.append(f\"{state_name}_Noise\")\n",
    "                cluster_colors.append(state_colors[-1])  # Gray for noise\n",
    "            else:\n",
    "                detailed_labels.append(f\"{state_name}_Cluster_{cluster_id}\")\n",
    "                cluster_colors.append(state_colors[cluster_id % len(state_colors)])\n",
    "    \n",
    "    print(f\"\\nüó∫Ô∏è  Computing UMAP for {len(combined_data)} total samples...\")\n",
    "    \n",
    "    # Compute UMAP\n",
    "    umap_2d = umap.UMAP(n_components=2, random_state=42, \n",
    "                       n_neighbors=min(15, len(combined_data)//3), \n",
    "                       min_dist=0.1, n_jobs=1)\n",
    "    embedding_2d = umap_2d.fit_transform(combined_data)\n",
    "    \n",
    "    umap_3d = umap.UMAP(n_components=3, random_state=42,\n",
    "                       n_neighbors=min(15, len(combined_data)//3),\n",
    "                       min_dist=0.1, n_jobs=1)\n",
    "    embedding_3d = umap_3d.fit_transform(combined_data)\n",
    "    \n",
    "    return {\n",
    "        'embedding_2d': embedding_2d,\n",
    "        'embedding_3d': embedding_3d,\n",
    "        'combined_data': combined_data,\n",
    "        'detailed_labels': detailed_labels,\n",
    "        'cluster_colors': cluster_colors,\n",
    "        'clustered_data': clustered_data,\n",
    "        'cluster_results': cluster_results,\n",
    "        'state_labels': combined_labels,\n",
    "        'algorithm': 'HDBSCAN'\n",
    "    }\n",
    "\n",
    "def plot_hdbscan_umap(clustering_results, title_prefix=\"HDBSCAN_Clustered\"):\n",
    "    \"\"\"\n",
    "    Create UMAP plots showing HDBSCAN cluster assignments\n",
    "    \"\"\"\n",
    "    embedding_2d = clustering_results['embedding_2d']\n",
    "    embedding_3d = clustering_results['embedding_3d']\n",
    "    detailed_labels = clustering_results['detailed_labels']\n",
    "    cluster_colors = clustering_results['cluster_colors']\n",
    "    \n",
    "    print(f\"\\nüé® Creating HDBSCAN UMAP visualizations...\")\n",
    "    \n",
    "    # Create 2D plot\n",
    "    fig_2d = go.Figure()\n",
    "    \n",
    "    # Group by detailed cluster labels for legend\n",
    "    unique_detailed_labels = list(set(detailed_labels))\n",
    "    # Sort to put noise at the end\n",
    "    unique_detailed_labels.sort(key=lambda x: (x.endswith('_Noise'), x))\n",
    "    \n",
    "    for label in unique_detailed_labels:\n",
    "        mask = [l == label for l in detailed_labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            \n",
    "            # Extract state and cluster info for hover\n",
    "            if label.endswith('_Noise'):\n",
    "                state = label.split('_')[0]\n",
    "                display_name = f\"{state} Noise\"\n",
    "                hover_text = f\"<b>{state} Noise Point</b>\"\n",
    "                marker_size = 3\n",
    "                opacity = 0.4\n",
    "            else:\n",
    "                state = label.split('_')[0]\n",
    "                cluster_id = label.split('_')[-1]\n",
    "                display_name = f\"{state} C{cluster_id}\"\n",
    "                hover_text = f\"<b>{state} Cluster {cluster_id}</b>\"\n",
    "                marker_size = 4\n",
    "                opacity = 0.7\n",
    "            \n",
    "            fig_2d.add_trace(go.Scatter(\n",
    "                x=embedding_2d[indices, 0],\n",
    "                y=embedding_2d[indices, 1],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=cluster_colors[indices[0]],\n",
    "                    size=marker_size,\n",
    "                    opacity=opacity,\n",
    "                    line=dict(width=0.5, color='white')\n",
    "                ),\n",
    "                name=display_name,\n",
    "                hovertemplate=f'{hover_text}<br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_2d.update_layout(\n",
    "        title=f'{title_prefix} - 2D UMAP with HDBSCAN Clusters',\n",
    "        xaxis_title='UMAP 1',\n",
    "        yaxis_title='UMAP 2',\n",
    "        width=900,\n",
    "        height=700,\n",
    "        showlegend=True,\n",
    "        hovermode='closest',\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\",\n",
    "            y=1,\n",
    "            xanchor=\"left\",\n",
    "            x=1.02\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig_3d = go.Figure()\n",
    "    \n",
    "    for label in unique_detailed_labels:\n",
    "        mask = [l == label for l in detailed_labels]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            \n",
    "            if label.endswith('_Noise'):\n",
    "                state = label.split('_')[0]\n",
    "                display_name = f\"{state} Noise\"\n",
    "                hover_text = f\"<b>{state} Noise Point</b>\"\n",
    "                marker_size = 2\n",
    "                opacity = 0.4\n",
    "            else:\n",
    "                state = label.split('_')[0]\n",
    "                cluster_id = label.split('_')[-1]\n",
    "                display_name = f\"{state} C{cluster_id}\"\n",
    "                hover_text = f\"<b>{state} Cluster {cluster_id}</b>\"\n",
    "                marker_size = 3\n",
    "                opacity = 0.7\n",
    "            \n",
    "            fig_3d.add_trace(go.Scatter3d(\n",
    "                x=embedding_3d[indices, 0],\n",
    "                y=embedding_3d[indices, 1],\n",
    "                z=embedding_3d[indices, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=cluster_colors[indices[0]],\n",
    "                    size=marker_size,\n",
    "                    opacity=opacity,\n",
    "                    line=dict(width=0.5, color='white')\n",
    "                ),\n",
    "                name=display_name,\n",
    "                hovertemplate=f'{hover_text}<br>UMAP 1: %{{x:.2f}}<br>UMAP 2: %{{y:.2f}}<br>UMAP 3: %{{z:.2f}}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    fig_3d.update_layout(\n",
    "        title=f'{title_prefix} - 3D UMAP with HDBSCAN Clusters',\n",
    "        scene=dict(\n",
    "            xaxis_title='UMAP 1',\n",
    "            yaxis_title='UMAP 2',\n",
    "            zaxis_title='UMAP 3'\n",
    "        ),\n",
    "        width=900,\n",
    "        height=700,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Save and open plots\n",
    "    safe_title = title_prefix.replace(\" \", \"_\").replace(\"-\", \"\").strip(\"_\")\n",
    "    filename_2d = f\"umap_2d_hdbscan_{safe_title}_{hash(str(embedding_2d.tolist())) % 10000}.html\"\n",
    "    filename_3d = f\"umap_3d_hdbscan_{safe_title}_{hash(str(embedding_3d.tolist())) % 10000}.html\"\n",
    "    \n",
    "    fig_2d.write_html(filename_2d, auto_open=False)\n",
    "    fig_3d.write_html(filename_3d, auto_open=False)\n",
    "    \n",
    "    print(f\"Opening HDBSCAN 2D plot: {filename_2d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_2d)}', new=2)\n",
    "    \n",
    "    print(f\"Opening HDBSCAN 3D plot: {filename_3d}\")\n",
    "    webbrowser.open(f'file://{os.path.abspath(filename_3d)}', new=2)\n",
    "    \n",
    "    fig_2d.show()\n",
    "    fig_3d.show()\n",
    "    \n",
    "    return fig_2d, fig_3d\n",
    "\n",
    "def analyze_hdbscan_characteristics(clustering_results):\n",
    "    \"\"\"\n",
    "    Analyze and print characteristics of HDBSCAN clusters\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìä HDBSCAN CLUSTER ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    clustered_data = clustering_results['clustered_data']\n",
    "    cluster_results = clustering_results['cluster_results']\n",
    "    \n",
    "    for state_name, data_info in clustered_data.items():\n",
    "        print(f\"\\nüîç {state_name.upper()} STATE HDBSCAN CLUSTERS:\")\n",
    "        \n",
    "        cluster_labels = data_info['cluster_labels']\n",
    "        n_clusters = cluster_results[state_name]['n_clusters']\n",
    "        n_noise = cluster_results[state_name]['n_noise']\n",
    "        \n",
    "        print(f\"  Found {n_clusters} natural clusters\")\n",
    "        print(f\"  Noise points: {n_noise} ({n_noise/len(cluster_labels)*100:.1f}%)\")\n",
    "        \n",
    "        unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "        total_samples = len(cluster_labels)\n",
    "        \n",
    "        for cluster_id, count in zip(unique_labels, counts):\n",
    "            percentage = (count / total_samples) * 100\n",
    "            if cluster_id == -1:\n",
    "                print(f\"    Noise: {count:4d} samples ({percentage:5.1f}%)\")\n",
    "            else:\n",
    "                print(f\"    Cluster {cluster_id}: {count:4d} samples ({percentage:5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüí° HDBSCAN INTERPRETATION GUIDE:\")\n",
    "    print(\"‚Ä¢ HDBSCAN finds natural clusters without pre-specifying the number\")\n",
    "    print(\"‚Ä¢ Noise points = outliers that don't belong to any cluster\")\n",
    "    print(\"‚Ä¢ Varying cluster sizes = different cognitive patterns have different prevalence\")\n",
    "    print(\"‚Ä¢ Hierarchical structure = clusters can have sub-clusters\")\n",
    "    print(\"‚Ä¢ In UMAP plots, look for:\")\n",
    "    print(\"  - Dense clusters = strong, consistent patterns\")\n",
    "    print(\"  - Noise points (gray) = unique or transitional states\")\n",
    "    print(\"  - Cluster boundaries = natural separations in the data\")\n",
    "\n",
    "print(\"üîç UMAP Analysis of Cognitive Transformations\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "699c4d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Full Dataset UMAP (all patterns)\n",
      "Full data shapes - Neg: torch.Size([520, 208, 2304]), Pos: torch.Size([520, 261, 2304]), Trans: torch.Size([520, 311, 2304])\n",
      "Combined data shape: (3000, 2304)\n",
      "Computing UMAP for 3000 samples...\n",
      "Opening 2D plot: umap_2d_Full_Dataset_9021.html\n",
      "Opening 3D plot: umap_3d_Full_Dataset_7055.html\n"
     ]
    }
   ],
   "source": [
    "# 1. Full dataset UMAP (all patterns, all tokens subsampled)\n",
    "print(\"\\n1. Full Dataset UMAP (all patterns)\")\n",
    "all_indices = [i for indices_list in pattern_indices.values() for i in indices_list]\n",
    "neg_all = negative_activations[f'negative_layer_{layer}'][all_indices]\n",
    "pos_all = positive_activations[f'positive_layer_{layer}'][all_indices]\n",
    "trans_all = transition_activations[f'transition_layer_{layer}'][all_indices]\n",
    "\n",
    "print(f\"Full data shapes - Neg: {neg_all.shape}, Pos: {pos_all.shape}, Trans: {trans_all.shape}\")\n",
    "\n",
    "data_all, labels_all, colors_all = prepare_data_for_umap(neg_all, pos_all, trans_all)\n",
    "print(f\"Combined data shape: {data_all.shape}\")\n",
    "\n",
    "embedding_2d_all, embedding_3d_all = plot_umap_2d_3d(data_all, labels_all, colors_all, \"Full Dataset - \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde4b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Single Pattern UMAP: Executive Fatigue & Avolition\n",
      "Single pattern data shapes - Neg: torch.Size([40, 208, 2304]), Pos: torch.Size([40, 261, 2304]), Trans: torch.Size([40, 311, 2304])\n",
      "Computing UMAP for 3000 samples...\n",
      "Opening 2D plot: umap_2d_Executive_Fatigue_&_Avolition_3466.html\n",
      "Opening 3D plot: umap_3d_Executive_Fatigue_&_Avolition_2827.html\n"
     ]
    }
   ],
   "source": [
    "# 2. Single cognitive pattern UMAP\n",
    "print(f\"\\n2. Single Pattern UMAP: {first_pattern}\")\n",
    "indices = pattern_indices[first_pattern]\n",
    "neg_single = negative_activations[f'negative_layer_{layer}'][indices]\n",
    "pos_single = positive_activations[f'positive_layer_{layer}'][indices]\n",
    "trans_single = transition_activations[f'transition_layer_{layer}'][indices]\n",
    "\n",
    "print(f\"Single pattern data shapes - Neg: {neg_single.shape}, Pos: {pos_single.shape}, Trans: {trans_single.shape}\")\n",
    "\n",
    "data_single, labels_single, colors_single = prepare_data_for_umap(neg_single, pos_single, trans_single)\n",
    "embedding_2d_single, embedding_3d_single = plot_umap_2d_3d(data_single, labels_single, colors_single, f\"{first_pattern} - \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48028e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Last Token Only UMAP: Executive Fatigue & Avolition\n",
      "Last token shapes - Neg: torch.Size([40, 1, 2304]), Pos: torch.Size([40, 1, 2304]), Trans: torch.Size([40, 1, 2304])\n",
      "Computing UMAP for 120 samples...\n",
      "Opening 2D plot: umap_2d_Last_Token_Only_7531.html\n",
      "Opening 3D plot: umap_3d_Last_Token_Only_3571.html\n",
      "\n",
      "‚úÖ UMAP Analysis Complete!\n",
      "üìä Analyzed 520 total samples across 13 cognitive patterns\n",
      "üéØ Single pattern 'Executive Fatigue & Avolition' had 40 samples\n",
      "üî¨ Layer 17 activations visualized in 2D and 3D space\n"
     ]
    }
   ],
   "source": [
    "# 3. Last token only UMAP (single pattern)\n",
    "print(f\"\\n3. Last Token Only UMAP: {first_pattern}\")\n",
    "neg_last = neg_single[:, -1, :].unsqueeze(1)  # Keep token dimension\n",
    "pos_last = pos_single[:, -1, :].unsqueeze(1)\n",
    "trans_last = trans_single[:, -1, :].unsqueeze(1)\n",
    "\n",
    "print(f\"Last token shapes - Neg: {neg_last.shape}, Pos: {pos_last.shape}, Trans: {trans_last.shape}\")\n",
    "\n",
    "data_last, labels_last, colors_last = prepare_data_for_umap(neg_last, pos_last, trans_last, subsample_tokens=False)\n",
    "embedding_2d_last, embedding_3d_last = plot_umap_2d_3d(data_last, labels_last, colors_last, \"Last Token Only - \")\n",
    "\n",
    "print(\"\\n‚úÖ UMAP Analysis Complete!\")\n",
    "print(f\"üìä Analyzed {len(all_indices)} total samples across {len(pattern_indices)} cognitive patterns\")\n",
    "print(f\"üéØ Single pattern '{first_pattern}' had {len(indices)} samples\")\n",
    "print(f\"üî¨ Layer {layer} activations visualized in 2D and 3D space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c60f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Depressive Dataset Only UMAP (all cognitive patterns, negative tokens only)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî¥ FILTERED VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show available patterns first\n",
    "print(f\"\\nüìã Available Cognitive Patterns ({len(pattern_indices)} total):\")\n",
    "for i, pattern in enumerate(list(pattern_indices.keys())[:8]):  # Show first 8\n",
    "    count = len(pattern_indices[pattern])\n",
    "    print(f\"  {i+1}. {pattern} ({count} examples)\")\n",
    "if len(pattern_indices) > 8:\n",
    "    print(f\"  ... and {len(pattern_indices) - 8} more patterns\")\n",
    "\n",
    "# Visualize only depressive (negative) tokens across all patterns\n",
    "embedding_2d_depressive, embedding_3d_depressive = plot_depressive_only_umap(layer=layer, max_samples=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3060214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Analyzing single pattern: 'Executive Fatigue & Avolition'\n",
      "\n",
      "üéØ Single Pattern UMAP: Executive Fatigue & Avolition (all examples)\n",
      "Pattern data shapes - Neg: torch.Size([40, 208, 2304]), Pos: torch.Size([40, 261, 2304]), Trans: torch.Size([40, 311, 2304])\n",
      "Computing UMAP for 3000 samples...\n",
      "Opening 2D plot: umap_2d_Executive_Fatigue_&_Avolition_AllExamples_7854.html\n",
      "Opening 3D plot: umap_3d_Executive_Fatigue_&_Avolition_AllExamples_4865.html\n"
     ]
    }
   ],
   "source": [
    "# 5. Single Cognitive Pattern UMAP (all examples: negative, positive, transition)\n",
    "selected_pattern = list(pattern_indices.keys())[0]  # Use first pattern\n",
    "print(f\"\\nüéØ Analyzing single pattern: '{selected_pattern}'\")\n",
    "\n",
    "# You can change this to any pattern name from the list above\n",
    "# selected_pattern = \"catastrophizing\"  # Example: uncomment and change to analyze a specific pattern\n",
    "\n",
    "embedding_2d_pattern, embedding_3d_pattern = plot_single_pattern_all_examples(\n",
    "    pattern_name=selected_pattern, \n",
    "    layer=layer, \n",
    "    max_samples=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9289322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¨ Analyzing single example from 'Executive Fatigue & Avolition' (example 0)\n",
      "\n",
      "üî¨ Single Example UMAP: Executive Fatigue & Avolition (example 0)\n",
      "Single example shapes - Neg: torch.Size([1, 208, 2304]), Pos: torch.Size([1, 261, 2304]), Trans: torch.Size([1, 311, 2304])\n",
      "Combined single example data shape: (780, 2304)\n",
      "Computing UMAP for 780 tokens from single example...\n",
      "Opening single example 2D plot: umap_2d_single_example_Executive_Fatigue_&_Avolition_0_5260.html\n",
      "Opening single example 3D plot: umap_3d_single_example_Executive_Fatigue_&_Avolition_0_9102.html\n"
     ]
    }
   ],
   "source": [
    "# 6. Single Example UMAP (just one example from one pattern - all its tokens)\n",
    "example_idx = 0  # First example\n",
    "print(f\"\\nüî¨ Analyzing single example from '{selected_pattern}' (example {example_idx})\")\n",
    "\n",
    "# This shows how tokens flow through the transformation within a single narrative\n",
    "# You can change example_idx to analyze different examples (0, 1, 2, etc.)\n",
    "\n",
    "embedding_2d_example, embedding_3d_example = plot_single_example(\n",
    "    pattern_name=selected_pattern,\n",
    "    example_idx=example_idx,\n",
    "    layer=layer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e04040e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä ANALYSIS COMPLETE - INTERPRETATION GUIDE\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'selected_pattern' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìä ANALYSIS COMPLETE - INTERPRETATION GUIDE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33müîç **What You\u001b[39m\u001b[33m'\u001b[39m\u001b[33mve Visualized:**\u001b[39m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[33m1. **Full Dataset UMAP** - Overview of all cognitive patterns\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m   - Shows general clustering of negative vs positive vs transition states\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m   - Reveals global structure across all \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pattern_indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cognitive patterns\u001b[39m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[33m2. **Depressive Dataset Only** - Pure negative emotional states  \u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m   - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_2d_depressive.shape[\u001b[32m0\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33membedding_2d_depressive\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlocals\u001b[39m()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m depressive tokens visualized\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m   - Shows internal structure of negative thought patterns\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m   - Look for clusters that might represent different types of depressive thinking\u001b[39m\n\u001b[32m     17\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[33m3. **Single Pattern Analysis** - Focus on \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mselected_pattern\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[33m   - All examples of this specific cognitive pattern\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[33m   - Shows how this pattern manifests across negative ‚Üí positive ‚Üí transition\u001b[39m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[33m4. **Single Example Analysis** - Micro-level view\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m   - Individual narrative token progression  \u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m   - Shows the transformation journey within one story\u001b[39m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33müéØ **How to Use These Visualizations:**\u001b[39m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[33m‚Ä¢ **Clusters** = Similar activation patterns (similar \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthoughts\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33m‚Ä¢ **Distance** = How different the neural representations are  \u001b[39m\n\u001b[32m     30\u001b[39m \u001b[33m‚Ä¢ **Transitions** = Look for paths between negative and positive regions\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[33m‚Ä¢ **Outliers** = Unusual or unique activation patterns\u001b[39m\n\u001b[32m     32\u001b[39m \n\u001b[32m     33\u001b[39m \u001b[33müîß **Customization Options:**\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m# To analyze a different pattern:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m# selected_pattern = \u001b[39m\u001b[33m'\u001b[39m\u001b[33myour_pattern_name_here\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'selected_pattern' is not defined"
     ]
    }
   ],
   "source": [
    "# 7. Summary and Analysis Guide\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä ANALYSIS COMPLETE - INTERPRETATION GUIDE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "üîç **What You've Visualized:**\n",
    "\n",
    "1. **Full Dataset UMAP** - Overview of all cognitive patterns\n",
    "   - Shows general clustering of negative vs positive vs transition states\n",
    "   - Reveals global structure across all {len(pattern_indices)} cognitive patterns\n",
    "\n",
    "2. **Depressive Dataset Only** - Pure negative emotional states  \n",
    "   - {embedding_2d_depressive.shape[0] if 'embedding_2d_depressive' in locals() else 'N/A'} depressive tokens visualized\n",
    "   - Shows internal structure of negative thought patterns\n",
    "   - Look for clusters that might represent different types of depressive thinking\n",
    "\n",
    "3. **Single Pattern Analysis** - Focus on '{selected_pattern}'\n",
    "   - All examples of this specific cognitive pattern\n",
    "   - Shows how this pattern manifests across negative ‚Üí positive ‚Üí transition\n",
    "\n",
    "4. **Single Example Analysis** - Micro-level view\n",
    "   - Individual narrative token progression  \n",
    "   - Shows the transformation journey within one story\n",
    "\n",
    "üéØ **How to Use These Visualizations:**\n",
    "\n",
    "‚Ä¢ **Clusters** = Similar activation patterns (similar \"thoughts\")\n",
    "‚Ä¢ **Distance** = How different the neural representations are  \n",
    "‚Ä¢ **Transitions** = Look for paths between negative and positive regions\n",
    "‚Ä¢ **Outliers** = Unusual or unique activation patterns\n",
    "\n",
    "üîß **Customization Options:**\n",
    "\"\"\")\n",
    "\n",
    "print(\"# To analyze a different pattern:\")\n",
    "print(\"# selected_pattern = 'your_pattern_name_here'\")\n",
    "print(\"# embedding_2d, embedding_3d = plot_single_pattern_all_examples(selected_pattern)\")\n",
    "print()\n",
    "print(\"# To analyze a different example:\")  \n",
    "print(\"# embedding_2d, embedding_3d = plot_single_example('pattern_name', example_idx=5)\")\n",
    "print()\n",
    "print(\"# To focus on a different layer:\")\n",
    "print(\"# plot_depressive_only_umap(layer=15)  # Try layers 10-20\")\n",
    "\n",
    "print(f\"\\n‚úÖ All visualizations saved as HTML files and opened in browser tabs!\")\n",
    "print(f\"üìÅ Check your current directory for the generated .html files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cabb14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üî¨ CLUSTERING ANALYSIS - Finding Subtypes Within Each Cognitive State\n",
      "======================================================================\n",
      "üîç Performing K-means clustering (3 clusters per cognitive state)\n",
      "Data shapes - Neg: torch.Size([520, 208, 2304]), Pos: torch.Size([520, 261, 2304]), Trans: torch.Size([520, 311, 2304])\n",
      "\n",
      "üî¨ CLUSTERING ANALYSIS (K-means with 3 clusters per state)\n",
      "======================================================================\n",
      "Data shapes - Neg: (1500, 2304), Pos: (1500, 2304), Trans: (1500, 2304)\n",
      "\n",
      "üéØ Clustering Negative state (1500 samples)...\n",
      "  Cluster distribution: {0: 1079, 1: 58, 2: 363}\n",
      "\n",
      "üéØ Clustering Positive state (1500 samples)...\n",
      "  Cluster distribution: {0: 946, 1: 534, 2: 20}\n",
      "\n",
      "üéØ Clustering Transition state (1500 samples)...\n",
      "  Cluster distribution: {0: 394, 1: 1104, 2: 2}\n",
      "\n",
      "üó∫Ô∏è  Computing UMAP for 4500 total samples...\n"
     ]
    }
   ],
   "source": [
    "# 8. K-MEANS CLUSTERING ANALYSIS\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üî¨ CLUSTERING ANALYSIS - Finding Subtypes Within Each Cognitive State\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Perform clustering analysis on full dataset\n",
    "all_indices = [i for indices_list in pattern_indices.values() for i in indices_list]\n",
    "neg_all_cluster = negative_activations[f'negative_layer_{layer}'][all_indices]\n",
    "pos_all_cluster = positive_activations[f'positive_layer_{layer}'][all_indices]\n",
    "trans_all_cluster = transition_activations[f'transition_layer_{layer}'][all_indices]\n",
    "\n",
    "print(f\"üîç Performing K-means clustering (3 clusters per cognitive state)\")\n",
    "print(f\"Data shapes - Neg: {neg_all_cluster.shape}, Pos: {pos_all_cluster.shape}, Trans: {trans_all_cluster.shape}\")\n",
    "\n",
    "# Perform clustering analysis\n",
    "clustering_results = perform_clustering_analysis(\n",
    "    neg_all_cluster, \n",
    "    pos_all_cluster, \n",
    "    trans_all_cluster,\n",
    "    layer=layer,\n",
    "    n_clusters=3,\n",
    "    max_samples=1500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "300b4303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé® Creating interactive UMAP plots with cluster assignments...\n",
      "\n",
      "üé® Creating clustered UMAP visualizations...\n",
      "Opening clustered 2D plot: umap_2d_clustered_Full_Dataset_Clustered_5680.html\n",
      "Opening clustered 3D plot: umap_3d_clustered_Full_Dataset_Clustered_4791.html\n",
      "\n",
      "üìä CLUSTER ANALYSIS SUMMARY\n",
      "==================================================\n",
      "\n",
      "üîç NEGATIVE STATE CLUSTERS:\n",
      "  Cluster 0: 1079 samples ( 71.9%)\n",
      "  Cluster 1:   58 samples (  3.9%)\n",
      "  Cluster 2:  363 samples ( 24.2%)\n",
      "  Total inertia (within-cluster sum of squares): 3086096.75\n",
      "\n",
      "üîç POSITIVE STATE CLUSTERS:\n",
      "  Cluster 0:  946 samples ( 63.1%)\n",
      "  Cluster 1:  534 samples ( 35.6%)\n",
      "  Cluster 2:   20 samples (  1.3%)\n",
      "  Total inertia (within-cluster sum of squares): 3213893.00\n",
      "\n",
      "üîç TRANSITION STATE CLUSTERS:\n",
      "  Cluster 0:  394 samples ( 26.3%)\n",
      "  Cluster 1: 1104 samples ( 73.6%)\n",
      "  Cluster 2:    2 samples (  0.1%)\n",
      "  Total inertia (within-cluster sum of squares): 3274455.00\n",
      "\n",
      "üí° INTERPRETATION GUIDE:\n",
      "‚Ä¢ Each cognitive state (Negative/Positive/Transition) has 3 distinct clusters\n",
      "‚Ä¢ Clusters represent different 'subtypes' or 'patterns' within each state\n",
      "‚Ä¢ Lower inertia = more compact, well-separated clusters\n",
      "‚Ä¢ In UMAP plots, look for:\n",
      "  - Tight clusters = consistent activation patterns\n",
      "  - Scattered points = diverse activation patterns\n",
      "  - Cluster separation = how distinct the subtypes are\n"
     ]
    }
   ],
   "source": [
    "# 9. Visualize Clustered Results\n",
    "print(\"\\nüé® Creating interactive UMAP plots with cluster assignments...\")\n",
    "\n",
    "# Create clustered UMAP plots\n",
    "fig_2d_clustered, fig_3d_clustered = plot_clustered_umap(\n",
    "    clustering_results, \n",
    "    title_prefix=\"Full_Dataset_Clustered\"\n",
    ")\n",
    "\n",
    "# Analyze cluster characteristics\n",
    "analyze_cluster_characteristics(clustering_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e26265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ SINGLE PATTERN CLUSTERING ANALYSIS\n",
      "============================================================\n",
      "Analyzing clustering within pattern: 'Executive Fatigue & Avolition'\n",
      "Single pattern data shapes - Neg: torch.Size([40, 208, 2304]), Pos: torch.Size([40, 261, 2304]), Trans: torch.Size([40, 311, 2304])\n",
      "\n",
      "üî¨ CLUSTERING ANALYSIS (K-means with 3 clusters per state)\n",
      "======================================================================\n",
      "Data shapes - Neg: (800, 2304), Pos: (800, 2304), Trans: (800, 2304)\n",
      "\n",
      "üéØ Clustering Negative state (800 samples)...\n",
      "  Cluster distribution: {0: 16, 1: 752, 2: 32}\n",
      "\n",
      "üéØ Clustering Positive state (800 samples)...\n",
      "  Cluster distribution: {0: 159, 1: 538, 2: 103}\n",
      "\n",
      "üéØ Clustering Transition state (800 samples)...\n",
      "  Cluster distribution: {0: 776, 1: 23, 2: 1}\n",
      "\n",
      "üó∫Ô∏è  Computing UMAP for 2400 total samples...\n",
      "\n",
      "üé® Creating clustered UMAP visualizations...\n",
      "Opening clustered 2D plot: umap_2d_clustered_Executive_Fatigue_&_Avolition_Clustered_3477.html\n",
      "Opening clustered 3D plot: umap_3d_clustered_Executive_Fatigue_&_Avolition_Clustered_3949.html\n",
      "\n",
      "üìä CLUSTER ANALYSIS SUMMARY\n",
      "==================================================\n",
      "\n",
      "üîç NEGATIVE STATE CLUSTERS:\n",
      "  Cluster 0:   16 samples (  2.0%)\n",
      "  Cluster 1:  752 samples ( 94.0%)\n",
      "  Cluster 2:   32 samples (  4.0%)\n",
      "  Total inertia (within-cluster sum of squares): 1648803.88\n",
      "\n",
      "üîç POSITIVE STATE CLUSTERS:\n",
      "  Cluster 0:  159 samples ( 19.9%)\n",
      "  Cluster 1:  538 samples ( 67.2%)\n",
      "  Cluster 2:  103 samples ( 12.9%)\n",
      "  Total inertia (within-cluster sum of squares): 1633632.88\n",
      "\n",
      "üîç TRANSITION STATE CLUSTERS:\n",
      "  Cluster 0:  776 samples ( 97.0%)\n",
      "  Cluster 1:   23 samples (  2.9%)\n",
      "  Cluster 2:    1 samples (  0.1%)\n",
      "  Total inertia (within-cluster sum of squares): 1765807.75\n",
      "\n",
      "üí° INTERPRETATION GUIDE:\n",
      "‚Ä¢ Each cognitive state (Negative/Positive/Transition) has 3 distinct clusters\n",
      "‚Ä¢ Clusters represent different 'subtypes' or 'patterns' within each state\n",
      "‚Ä¢ Lower inertia = more compact, well-separated clusters\n",
      "‚Ä¢ In UMAP plots, look for:\n",
      "  - Tight clusters = consistent activation patterns\n",
      "  - Scattered points = diverse activation patterns\n",
      "  - Cluster separation = how distinct the subtypes are\n"
     ]
    }
   ],
   "source": [
    "# 10. Single Pattern Clustering Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ SINGLE PATTERN CLUSTERING ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze clustering within a specific cognitive pattern\n",
    "selected_pattern_cluster = list(pattern_indices.keys())[0]\n",
    "print(f\"Analyzing clustering within pattern: '{selected_pattern_cluster}'\")\n",
    "\n",
    "indices_cluster = pattern_indices[selected_pattern_cluster]\n",
    "neg_single_cluster = negative_activations[f'negative_layer_{layer}'][indices_cluster]\n",
    "pos_single_cluster = positive_activations[f'positive_layer_{layer}'][indices_cluster]\n",
    "trans_single_cluster = transition_activations[f'transition_layer_{layer}'][indices_cluster]\n",
    "\n",
    "print(f\"Single pattern data shapes - Neg: {neg_single_cluster.shape}, Pos: {pos_single_cluster.shape}, Trans: {trans_single_cluster.shape}\")\n",
    "\n",
    "# Perform clustering on single pattern\n",
    "single_pattern_clustering = perform_clustering_analysis(\n",
    "    neg_single_cluster,\n",
    "    pos_single_cluster, \n",
    "    trans_single_cluster,\n",
    "    layer=layer,\n",
    "    n_clusters=3,\n",
    "    max_samples=800\n",
    ")\n",
    "\n",
    "# Visualize single pattern clustering\n",
    "fig_2d_single_clustered, fig_3d_single_clustered = plot_clustered_umap(\n",
    "    single_pattern_clustering,\n",
    "    title_prefix=f\"{selected_pattern_cluster}_Clustered\"\n",
    ")\n",
    "\n",
    "# Analyze single pattern clusters\n",
    "analyze_cluster_characteristics(single_pattern_clustering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb03b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Final Summary - Clustering Analysis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä CLUSTERING ANALYSIS COMPLETE - RESEARCH INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "üî¨ **What the Clustering Analysis Reveals:**\n",
    "\n",
    "1. **Subtype Discovery**: Each cognitive state (Negative, Positive, Transition) contains 3 distinct subtypes\n",
    "   - These represent different neural \"flavors\" or patterns within each emotional state\n",
    "   - E.g., different types of negative thinking, different positive emotions, different transition mechanisms\n",
    "\n",
    "2. **Cluster Characteristics**:\n",
    "   - **Tight clusters** = Consistent, well-defined activation patterns\n",
    "   - **Scattered clusters** = More variable activation patterns  \n",
    "   - **Separated clusters** = Distinct neural mechanisms\n",
    "\n",
    "3. **Research Applications**:\n",
    "   - **Therapeutic targeting**: Different subtypes might need different interventions\n",
    "   - **Individual differences**: People might predominantly use certain cluster patterns\n",
    "   - **Transition pathways**: Understand how specific negative subtypes transform to specific positive subtypes\n",
    "\n",
    "üé® **Visualization Features**:\n",
    "‚Ä¢ **Color coding**: Each state has 3 shades (dark‚Üílight) for its 3 clusters\n",
    "‚Ä¢ **Interactive plots**: Hover to see which cluster each point belongs to\n",
    "‚Ä¢ **Legend**: \"Negative C0\", \"Positive C1\", etc. for easy identification\n",
    "‚Ä¢ **Browser tabs**: All plots automatically open for detailed exploration\n",
    "\n",
    "üîß **Customization Options:**\n",
    "\"\"\")\n",
    "\n",
    "print(\"# To change number of clusters:\")\n",
    "print(\"# clustering_results = perform_clustering_analysis(neg_data, pos_data, trans_data, n_clusters=5)\")\n",
    "print()\n",
    "print(\"# To analyze different layer:\")\n",
    "print(\"# clustering_results = perform_clustering_analysis(neg_data, pos_data, trans_data, layer=15)\")\n",
    "print()\n",
    "print(\"# To cluster only one cognitive state:\")\n",
    "print(\"# from sklearn.cluster import KMeans\")\n",
    "print(\"# neg_flat = neg_data.reshape(-1, neg_data.shape[-1]).cpu().numpy()\")\n",
    "print(\"# kmeans = KMeans(n_clusters=3).fit(neg_flat)\")\n",
    "print(\"# labels = kmeans.labels_\")\n",
    "\n",
    "print(f\"\\nüéØ **Next Steps for Research:**\")\n",
    "print(\"‚Ä¢ Examine what makes each cluster unique (feature analysis)\")\n",
    "print(\"‚Ä¢ Study transition patterns between specific clusters\")\n",
    "print(\"‚Ä¢ Correlate clusters with therapeutic outcomes\")\n",
    "print(\"‚Ä¢ Investigate individual differences in cluster usage\")\n",
    "\n",
    "print(f\"\\n‚úÖ Clustering analysis complete! Check browser tabs for interactive exploration.\")\n",
    "print(f\"üìÅ HTML files saved in current directory for future reference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d532c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üå≥ HDBSCAN ANALYSIS - Hierarchical Density-Based Clustering\n",
      "======================================================================\n",
      "\n",
      "üîç **HDBSCAN vs K-means Comparison:**\n",
      "‚Ä¢ **K-means**: Forces exactly 3 clusters per state (pre-specified)\n",
      "‚Ä¢ **HDBSCAN**: Discovers natural clusters automatically (data-driven)\n",
      "‚Ä¢ **HDBSCAN**: Identifies outliers as \"noise points\"\n",
      "‚Ä¢ **HDBSCAN**: Can find clusters of varying shapes and densities\n",
      "\n",
      "üîç Performing HDBSCAN clustering (automatic cluster discovery)\n",
      "Data shapes - Neg: torch.Size([520, 208, 2304]), Pos: torch.Size([520, 261, 2304]), Trans: torch.Size([520, 311, 2304])\n",
      "\n",
      "üå≥ HDBSCAN ANALYSIS (Hierarchical density-based clustering)\n",
      "======================================================================\n",
      "Parameters: min_cluster_size=50, max_samples=1500\n",
      "Data shapes - Neg: (1500, 2304), Pos: (1500, 2304), Trans: (1500, 2304)\n",
      "\n",
      "üéØ HDBSCAN clustering Negative state (1500 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 2 clusters\n",
      "  Noise points: 384 (25.6%)\n",
      "  Noise:  384 samples ( 25.6%)\n",
      "  Cluster 0: 1049 samples ( 69.9%)\n",
      "  Cluster 1:   67 samples (  4.5%)\n",
      "  Silhouette score: 1.000\n",
      "\n",
      "üéØ HDBSCAN clustering Positive state (1500 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 0 clusters\n",
      "  Noise points: 1500 (100.0%)\n",
      "  Noise: 1500 samples (100.0%)\n",
      "\n",
      "üéØ HDBSCAN clustering Transition state (1500 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 0 clusters\n",
      "  Noise points: 1500 (100.0%)\n",
      "  Noise: 1500 samples (100.0%)\n",
      "\n",
      "üó∫Ô∏è  Computing UMAP for 4500 total samples...\n"
     ]
    }
   ],
   "source": [
    "# 12. HDBSCAN CLUSTERING ANALYSIS\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üå≥ HDBSCAN ANALYSIS - Hierarchical Density-Based Clustering\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "üîç **HDBSCAN vs K-means Comparison:**\n",
    "‚Ä¢ **K-means**: Forces exactly 3 clusters per state (pre-specified)\n",
    "‚Ä¢ **HDBSCAN**: Discovers natural clusters automatically (data-driven)\n",
    "‚Ä¢ **HDBSCAN**: Identifies outliers as \"noise points\"\n",
    "‚Ä¢ **HDBSCAN**: Can find clusters of varying shapes and densities\n",
    "\"\"\")\n",
    "\n",
    "# Perform HDBSCAN analysis on full dataset\n",
    "print(f\"üîç Performing HDBSCAN clustering (automatic cluster discovery)\")\n",
    "print(f\"Data shapes - Neg: {neg_all_cluster.shape}, Pos: {pos_all_cluster.shape}, Trans: {trans_all_cluster.shape}\")\n",
    "\n",
    "# Perform HDBSCAN analysis\n",
    "hdbscan_results = perform_hdbscan_analysis(\n",
    "    neg_all_cluster, \n",
    "    pos_all_cluster, \n",
    "    trans_all_cluster,\n",
    "    layer=layer,\n",
    "    min_cluster_size=50,  # Minimum points needed to form a cluster\n",
    "    max_samples=1500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe38acf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé® Creating HDBSCAN UMAP plots with noise point detection...\n",
      "\n",
      "üé® Creating HDBSCAN UMAP visualizations...\n",
      "Opening HDBSCAN 2D plot: umap_2d_hdbscan_Full_Dataset_HDBSCAN_9059.html\n",
      "Opening HDBSCAN 3D plot: umap_3d_hdbscan_Full_Dataset_HDBSCAN_4004.html\n",
      "\n",
      "üìä HDBSCAN CLUSTER ANALYSIS SUMMARY\n",
      "==================================================\n",
      "\n",
      "üîç NEGATIVE STATE HDBSCAN CLUSTERS:\n",
      "  Found 2 natural clusters\n",
      "  Noise points: 399 (26.6%)\n",
      "    Noise:  399 samples ( 26.6%)\n",
      "    Cluster 0: 1048 samples ( 69.9%)\n",
      "    Cluster 1:   53 samples (  3.5%)\n",
      "\n",
      "üîç POSITIVE STATE HDBSCAN CLUSTERS:\n",
      "  Found 0 natural clusters\n",
      "  Noise points: 1500 (100.0%)\n",
      "    Noise: 1500 samples (100.0%)\n",
      "\n",
      "üîç TRANSITION STATE HDBSCAN CLUSTERS:\n",
      "  Found 0 natural clusters\n",
      "  Noise points: 1500 (100.0%)\n",
      "    Noise: 1500 samples (100.0%)\n",
      "\n",
      "üí° HDBSCAN INTERPRETATION GUIDE:\n",
      "‚Ä¢ HDBSCAN finds natural clusters without pre-specifying the number\n",
      "‚Ä¢ Noise points = outliers that don't belong to any cluster\n",
      "‚Ä¢ Varying cluster sizes = different cognitive patterns have different prevalence\n",
      "‚Ä¢ Hierarchical structure = clusters can have sub-clusters\n",
      "‚Ä¢ In UMAP plots, look for:\n",
      "  - Dense clusters = strong, consistent patterns\n",
      "  - Noise points (gray) = unique or transitional states\n",
      "  - Cluster boundaries = natural separations in the data\n"
     ]
    }
   ],
   "source": [
    "# 13. Visualize HDBSCAN Results\n",
    "print(\"\\nüé® Creating HDBSCAN UMAP plots with noise point detection...\")\n",
    "\n",
    "# Create HDBSCAN UMAP plots\n",
    "fig_2d_hdbscan, fig_3d_hdbscan = plot_hdbscan_umap(\n",
    "    hdbscan_results, \n",
    "    title_prefix=\"Full_Dataset_HDBSCAN\"\n",
    ")\n",
    "\n",
    "# Analyze HDBSCAN cluster characteristics\n",
    "analyze_hdbscan_characteristics(hdbscan_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceb9f48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ SINGLE PATTERN HDBSCAN ANALYSIS\n",
      "============================================================\n",
      "Analyzing HDBSCAN clustering within pattern: 'Executive Fatigue & Avolition'\n",
      "\n",
      "üå≥ HDBSCAN ANALYSIS (Hierarchical density-based clustering)\n",
      "======================================================================\n",
      "Parameters: min_cluster_size=60, max_samples=2000\n",
      "Data shapes - Neg: (1040, 2304), Pos: (1320, 2304), Trans: (1560, 2304)\n",
      "\n",
      "üéØ HDBSCAN clustering Negative state (1040 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 0 clusters\n",
      "  Noise points: 1040 (100.0%)\n",
      "  Noise: 1040 samples (100.0%)\n",
      "\n",
      "üéØ HDBSCAN clustering Positive state (1320 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 0 clusters\n",
      "  Noise points: 1320 (100.0%)\n",
      "  Noise: 1320 samples (100.0%)\n",
      "\n",
      "üéØ HDBSCAN clustering Transition state (1560 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivanculo/Desktop/Projects/turn_point/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 0 clusters\n",
      "  Noise points: 1560 (100.0%)\n",
      "  Noise: 1560 samples (100.0%)\n",
      "\n",
      "üó∫Ô∏è  Computing UMAP for 3920 total samples...\n",
      "\n",
      "üé® Creating HDBSCAN UMAP visualizations...\n",
      "Opening HDBSCAN 2D plot: umap_2d_hdbscan_Executive_Fatigue_&_Avolition_HDBSCAN_7835.html\n",
      "Opening HDBSCAN 3D plot: umap_3d_hdbscan_Executive_Fatigue_&_Avolition_HDBSCAN_7776.html\n",
      "\n",
      "üìä HDBSCAN CLUSTER ANALYSIS SUMMARY\n",
      "==================================================\n",
      "\n",
      "üîç NEGATIVE STATE HDBSCAN CLUSTERS:\n",
      "  Found 0 natural clusters\n",
      "  Noise points: 1040 (100.0%)\n",
      "    Noise: 1040 samples (100.0%)\n",
      "\n",
      "üîç POSITIVE STATE HDBSCAN CLUSTERS:\n",
      "  Found 0 natural clusters\n",
      "  Noise points: 1320 (100.0%)\n",
      "    Noise: 1320 samples (100.0%)\n",
      "\n",
      "üîç TRANSITION STATE HDBSCAN CLUSTERS:\n",
      "  Found 0 natural clusters\n",
      "  Noise points: 1560 (100.0%)\n",
      "    Noise: 1560 samples (100.0%)\n",
      "\n",
      "üí° HDBSCAN INTERPRETATION GUIDE:\n",
      "‚Ä¢ HDBSCAN finds natural clusters without pre-specifying the number\n",
      "‚Ä¢ Noise points = outliers that don't belong to any cluster\n",
      "‚Ä¢ Varying cluster sizes = different cognitive patterns have different prevalence\n",
      "‚Ä¢ Hierarchical structure = clusters can have sub-clusters\n",
      "‚Ä¢ In UMAP plots, look for:\n",
      "  - Dense clusters = strong, consistent patterns\n",
      "  - Noise points (gray) = unique or transitional states\n",
      "  - Cluster boundaries = natural separations in the data\n"
     ]
    }
   ],
   "source": [
    "# 14. Single Pattern HDBSCAN Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ SINGLE PATTERN HDBSCAN ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze HDBSCAN clustering within a specific cognitive pattern\n",
    "print(f\"Analyzing HDBSCAN clustering within pattern: '{selected_pattern_cluster}'\")\n",
    "\n",
    "# Perform HDBSCAN on single pattern\n",
    "single_pattern_hdbscan = perform_hdbscan_analysis(\n",
    "    neg_single_cluster,\n",
    "    pos_single_cluster, \n",
    "    trans_single_cluster,\n",
    "    layer=layer,\n",
    "    min_cluster_size=60,  # Smaller min_cluster_size for single pattern\n",
    "    max_samples=2000\n",
    ")\n",
    "\n",
    "# Visualize single pattern HDBSCAN\n",
    "fig_2d_single_hdbscan, fig_3d_single_hdbscan = plot_hdbscan_umap(\n",
    "    single_pattern_hdbscan,\n",
    "    title_prefix=f\"{selected_pattern_cluster}_HDBSCAN\"\n",
    ")\n",
    "\n",
    "# Analyze single pattern HDBSCAN clusters\n",
    "analyze_hdbscan_characteristics(single_pattern_hdbscan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ec059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. K-means vs HDBSCAN Comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚öñÔ∏è  CLUSTERING ALGORITHM COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def compare_clustering_results(kmeans_results, hdbscan_results):\n",
    "    \"\"\"Compare K-means and HDBSCAN clustering results\"\"\"\n",
    "    \n",
    "    print(f\"\"\"\n",
    "üî¨ **ALGORITHM COMPARISON SUMMARY:**\n",
    "\n",
    "üìä **K-MEANS RESULTS:**\"\"\")\n",
    "    \n",
    "    for state_name in ['Negative', 'Positive', 'Transition']:\n",
    "        kmeans_labels = kmeans_results['clustered_data'][state_name]['cluster_labels']\n",
    "        unique_labels, counts = np.unique(kmeans_labels, return_counts=True)\n",
    "        print(f\"  {state_name}: {len(unique_labels)} clusters, sizes: {counts}\")\n",
    "    \n",
    "    print(f\"\"\"\n",
    "üå≥ **HDBSCAN RESULTS:**\"\"\")\n",
    "    \n",
    "    for state_name in ['Negative', 'Positive', 'Transition']:\n",
    "        hdbscan_labels = hdbscan_results['clustered_data'][state_name]['cluster_labels']\n",
    "        n_clusters = hdbscan_results['cluster_results'][state_name]['n_clusters']\n",
    "        n_noise = hdbscan_results['cluster_results'][state_name]['n_noise']\n",
    "        unique_labels, counts = np.unique(hdbscan_labels, return_counts=True)\n",
    "        cluster_counts = counts[unique_labels != -1] if -1 in unique_labels else counts\n",
    "        print(f\"  {state_name}: {n_clusters} clusters, {n_noise} noise points\")\n",
    "        print(f\"    Cluster sizes: {cluster_counts}\")\n",
    "    \n",
    "    print(f\"\"\"\n",
    "üí° **KEY DIFFERENCES:**\n",
    "\n",
    "üéØ **Cluster Discovery:**\n",
    "‚Ä¢ K-means: Fixed 3 clusters per state (forced partitioning)\n",
    "‚Ä¢ HDBSCAN: Variable clusters per state (natural discovery)\n",
    "\n",
    "üîç **Outlier Handling:**\n",
    "‚Ä¢ K-means: All points assigned to clusters (even outliers)\n",
    "‚Ä¢ HDBSCAN: Outliers identified as noise points (more realistic)\n",
    "\n",
    "üìè **Cluster Shapes:**\n",
    "‚Ä¢ K-means: Assumes spherical clusters\n",
    "‚Ä¢ HDBSCAN: Finds clusters of any shape and varying density\n",
    "\n",
    "üé® **Visualization Differences:**\n",
    "‚Ä¢ K-means: Uniform 3-color scheme per state\n",
    "‚Ä¢ HDBSCAN: Dynamic colors + gray noise points\n",
    "\n",
    "üî¨ **Research Implications:**\n",
    "‚Ä¢ K-means: Good for comparing fixed number of subtypes\n",
    "‚Ä¢ HDBSCAN: Better for discovering natural cognitive structure\n",
    "‚Ä¢ Noise points may represent transitional or unique mental states\n",
    "‚Ä¢ Different algorithms may reveal different aspects of cognition\n",
    "\"\"\")\n",
    "\n",
    "# Perform the comparison\n",
    "compare_clustering_results(clustering_results, hdbscan_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ebe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Final Summary - Complete Clustering Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ COMPLETE CLUSTERING ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "üî¨ **What You've Discovered:**\n",
    "\n",
    "1. **Multiple Clustering Perspectives**:\n",
    "   - **K-means**: Structured 3-cluster analysis per cognitive state\n",
    "   - **HDBSCAN**: Natural cluster discovery with outlier detection\n",
    "\n",
    "2. **Cognitive State Structure**:\n",
    "   - **Negative states**: Multiple subtypes of depressive thinking\n",
    "   - **Positive states**: Different flavors of positive emotions  \n",
    "   - **Transition states**: Various transformation mechanisms\n",
    "   - **Noise points**: Unique or transitional mental states\n",
    "\n",
    "3. **Research Insights**:\n",
    "   - Not all cognitive patterns fit into neat categories\n",
    "   - Some mental states are truly unique (noise points)\n",
    "   - Natural clustering reveals the true structure of cognition\n",
    "   - Different algorithms highlight different aspects\n",
    "\n",
    "üé® **Visualization Arsenal Created:**\n",
    "‚Ä¢ Original UMAP plots (cognitive state overview)\n",
    "‚Ä¢ Filtered visualizations (depressive-only, single patterns, single examples)  \n",
    "‚Ä¢ K-means clustered plots (structured subtype analysis)\n",
    "‚Ä¢ HDBSCAN clustered plots (natural cluster discovery)\n",
    "‚Ä¢ All plots interactive and saved as HTML files\n",
    "\n",
    "üîß **Customization Examples:**\n",
    "\"\"\")\n",
    "\n",
    "print(\"# Try different HDBSCAN parameters:\")\n",
    "print(\"# hdbscan_results = perform_hdbscan_analysis(neg_data, pos_data, trans_data, min_cluster_size=30)\")\n",
    "print()\n",
    "print(\"# Compare different layers:\")\n",
    "print(\"# layer_15_results = perform_hdbscan_analysis(neg_data, pos_data, trans_data, layer=15)\")\n",
    "print()\n",
    "print(\"# Focus on specific cognitive states:\")\n",
    "print(\"# neg_only_hdbscan = hdbscan.HDBSCAN(min_cluster_size=50).fit_predict(neg_flat)\")\n",
    "\n",
    "print(f\"\"\"\n",
    "üéØ **Next Research Directions:**\n",
    "‚Ä¢ Investigate what makes noise points unique\n",
    "‚Ä¢ Study cluster transitions across layers\n",
    "‚Ä¢ Correlate clusters with clinical outcomes\n",
    "‚Ä¢ Examine individual differences in cluster membership\n",
    "‚Ä¢ Use clusters to guide therapeutic interventions\n",
    "\n",
    "üèÜ **Achievement Unlocked:**\n",
    "‚úÖ Multi-algorithm clustering analysis complete!\n",
    "‚úÖ Natural cognitive structure discovered!\n",
    "‚úÖ Outlier detection implemented!\n",
    "‚úÖ Interactive visualizations created!\n",
    "‚úÖ Research insights generated!\n",
    "\n",
    "üìÅ Check your directory for all the generated HTML visualization files!\n",
    "üåê All plots are now open in your browser for detailed exploration!\n",
    "\"\"\")\n",
    "\n",
    "print(f\"üéâ Total analysis complete! You now have comprehensive insights into the\")\n",
    "print(f\"   neural structure of cognitive transformations using multiple clustering approaches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc20d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
